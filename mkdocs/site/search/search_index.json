{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Course Notes Documentation Please find all the documentations available: Documentaion categories FreeCodeCamp NPTEL Office PluralSight Self Development Books","title":"Home"},{"location":"#welcome-to-course-notes-documentation","text":"Please find all the documentations available:","title":"Welcome to Course Notes Documentation"},{"location":"#documentaion-categories","text":"FreeCodeCamp NPTEL Office PluralSight Self Development Books","title":"Documentaion categories"},{"location":"booksNovels/atomicHabits/","text":"Atomic Habits: An Easy & Proven Way to Build Good Habits & Break Bad Ones Author : James Clear The Fundamentals : Why Tiny Changes Make a Big Difference The Surprising Power of Atomic Habits Habits are the compound interest of self-improvement. Getting 1 percent better every daycounts for a lot in the long run Habits are a double-edged sword. They can work for you or against you, which is whyunderstanding the details is essential. Small changes often appear to make no difference until you cross a critical threshold. Themost powerful outcomes of any compounding process are delayed. You need to be patient. An atomic habit is a little habit that is part of a larger system. Just as atoms are thebuilding blocks of molecules, atomic habits are the building blocks of remarkable results. If you want better results, then forget about setting goals. Focus on your system instead. You do not rise to the level of your goals. You fall to the level of you systems. How Your Habits Shape Your Identity (and Vice Versa) There are three levels of change : outcome change, process change, and identity change. The most effective way to change your habits is to focus not on what you want to achieve, buton who you wish to become. Your identity emerges out of your habits. Every action is a vote for the type of person youwish to become. Becoming the best version of yourself requires you to continuously edit your beliefs, and toupgrade and expand your identity. The real reason habits matter is not because they can get you better results (although theycan do that), but because they can change your beliefs about yourself. How to Build Better Habits in 4 Simple Steps A habit is a behaviour that has been repeated enough times to become automatic. The ultimate purpose of habits is to solve the problems of life with as little energy andeffort as possible. Any habit can be broken down into a feedback loop that involves four steps : Cue Craving Response Reward The Four Laws of Behaviour Change are a simple set of rules we can use to build betterhabits. They are: Make it obvious Make it attractive Make it easy Make it satisfying The 1st Law : Make It Obvious The Man Who Didn\u2019t Look Right With enough practice, your brain will pick up on the cues that predict certain outcomeswithout consciously thinking about it. Once our habits become automatic, we stop paying attention to what we are doing. The process of behavious change always starts with awareness. You need to be aware of yourhabits before you can change them. Pointing-and-calling raises your level of awareness from a nonconsious habit to a moreconscious level by verbalizing your actions. The Habits Scorecard is a simple exercise you can use to become more aware of your behaviour The Best Way to Start a New Habit The first law of behavious change is make it obvious The two most common cues are time and location Creating an implementation intention is a strategy you can use to pair a new habit with aspecific time and location. The implementation intention formula is : \"I will [BEHAVIOUR] at [TIME] in [LOCATION]\". Habit stacking is a strategy you can use to pair a new habit with a current habit The habit stacking formula is : \"After [CURRENT HABIT], i will [NEW HABIT]\". Motivation Is Overrated; Environment Often Matters More Small changes in context can lead to large changes in behaviour over time Every habit is initiated by a cue. We are more likely to notice cues that stand out. Make the cues of good habits obvious in you environment Gradually, your habits become associated not with a single trigger but with the entire context surrounding the behaviour. The context becomes the cue. It is easier to build new habits in a new environment because you are not fighting against old cues. The Secret to Self-Control The inversion of the 1st Law of Behaviour Change is make it invisible. Once a habit is formed, it is unlikely to be forgotten. People with high self-control tend to spend less time in tempting situations. It's easier to avoid temptation that resist it. One of the most practical ways to eliminate a bad habit is to reduce exposure to the cue thatcauses it. Self-control is a short-term strategy, not a long-term one. The 2nd Law : Make It Attractive How to Make a Habit Irresistible The 2nd Law of Behaviour Change is make it attractive The more attractive an opportunity is, the more likely it is to become habit-forming Habits are a dopamine-driven feedback loop. When dopamine rises, so does our motivation to act. It is the anticipation of a reward - not the fulfillment of it - that gets us to take action. The greater the anticipation, the greater the dopamine spike. Temptation bundling is one way to make your habits more attractive. The strategy is to pair an action you want to do with an action you need to do The Role of Family and Friends in Shaping Your Habits The culture we live in determines which behaviours are attractive to us. We tend to adopt habits that are praised and approved of by our culture because we have a strong desire to fit in and belong to the tribe We tend to imitate the habits of three social groups : the close (family and friends), the many (tribe), and the powerful(those with status and prestige) One of the most effective things you can do to build better habits is to join a culture where Your desired behaviour is the normal behaviour You already have something in common with the group The normal behaviour of the tribe often overpowers the desired behaviour of the individual. Most days, we'd rather be wrong with the crowd than be right by ourselves If a behaviour can get us approval, respect, and praise, we find it attractive How to Find and Fix the Causes of Your Bad Habits The inversion of the 2nd Law of Behaviour Change is make it unattractive Every behaviour has a surface level craving and a deeper underlying motive Your habits are modern-day solutions to ancient desires. The cause of your habits is actually the prediction that precedes them. The prediction leads to a feeling Highlight the benefits of avoiding a bad habit to make it seem unattractive Habits are attractive when we associate them with positive feelings and unattractive when we associate them with negative feelings. Create a motivation ritual by doing something you enjoy immediately before a difficult habit The 3nd Law : Make it Easy Walk Slowly, but Never Backward The 3rd Law of Behaviour Change is make it easy The most effective form of learning is practice, not planning Focus on taking action, not being in motion Habit formation is the process by which a behaviour becomes progressively more automatic through repetition The amount of time you have been performing a habit is not as important as the number of times you have performed it The Law of Least Effort Human behaviour follows the Law of Least Effort. We will naturally gravitate toward the option that requires the least amount of work Create an environment where doing the right thing is as easy as possible Reduce the friction associated with good behaviours. When friction is low, habits are easy. Increase the friction associated with bad behaviours. When frictionis high, habits are difficult Prime your environment to make future actions easier How to Stop Procrastinating by Using the Two-Minute Rule Habits are completed in a few seconds but continue to impact your behaviour for minutes or hours afterwards Many habits occur at decisive moments - choices that are like a fork in the road - and either send you in a direction of a productive day or an unproductive one The Two-Minute Rule states, \"When you start a new habit, it should take less that 2 minutes to do\" The more you ritualize the beginning of a process, the more likely it becomes that you can slip into the state of deep focus that is required to do great things Standardize before you optimize. You can't improve a habit that doesn't exist How to Make Good Habits Inevitable and Bad Habits Impossible The inversion of the 3rd Law of Behaviour Change is make it difficult A commitment device is a choice you make in the present that locks in better behaviour in thefuture The ultimate way to lock in future behaviour is to automate your habits Onetime choices - like buying a better mattress or enrolling in an automatic savings plan - are single actions that automate your future habits and deliver increasing returns over time Using technology to automate your habits is the most reliable and effective way to guarantee the right Behaviour The 4th Law : Make It Satisfying The Cardinal Rule of Behaviour Change The 4th Law of Behaviour Change is make it satisfying We are more likely to repeat a behaviour when the experience is satisfying The human brain evolved to prioritize immediate rewards over delayed rewards The Cardinal Rule of Behaviour Change : What is immediately rewarded is repeated. What is immediately punished is avoided To get a habit to stick you need to feel immediately successful - even if it's in a small way The first three laws of behaviour change - make it obvious, make it attractive, and make it easy increase the odds that a behaviour will be performed this time. The fourth law of behaviourn change - make it satisfying - increases the odds that a behaviour will be repeated next time How to Stick with Good Habits Every Day One of the most satisfying feelings is the feeling of making progress A habit tracker is a simple way to measure whether you did a habit - like marking an X on a calendar Habit trackers and other visual forms of measurement can make your habits satisfying by providing clear evidence of your progress Don't break the chain. Try to keep you habit streak alive Never miss twice. If you miss one day, try to get back on track as quickly as possible. Just because you can measure something doesn't mean it's the most important thing How an Accountability Partner Can Change Everything The inversion of the 4th Law of Behaviour Change is make it unsatisfying We are less likely to repeat a bad habit if it is painful or unsatisfying An accountability partner can create an immediate cost to inaction. We care deeply about what others think of us, and we do not want others to have a lesser opinion of us A habit contract can be used to add a social cost to any behaviour. It makes the costs of violating your promises public and painful Knowing that someone else is watching you can be a powerful motivator Advanced tactics : How to Go from Being Merely Good to Being Truly Great The Truth About Talent (When Genes Matter and When They Don\u2019t) The secret of maximizing your odds of success is to choose the right field of competition Pick the right habit and progress is easy. Pick the wrong habit and life is a struggle Genes cannot be easily changed, which means they provide a powerful advantage in favourable circumstances and a serious disadvantage in unfavourable circumstances Habits are easier when they align with your natural abilities. Choose the habits that best suits you Play a game that favors your strengths. If you can't find a game that favors you, create one Genes do not eliminate the need for hard work. They clarify it. They tell us what to work hard on The Goldilocks Rule: How to Stay Motivated in Life and Work The Goldilocks Rule states that humans experience peak motivation when working on tasks that are right on the edge of their current abilities The greatest threat to success is not failure but boredom As habits become routine, they become less interesting and less satisfying. We get bored Anyone can work hard when they feel motivated. It's the ability to keep going when work isn't exciting that makes the difference Professionals stick to the schedule, amateurs let life get in the way The Downside of Creating Good Habits The upside of habits is that we can do things without thinking. The downside is that we stop paying attention to little errors Habits + Deliberate Practice = Mastery Reflection and review is a process that allows you to maintain conscious of your performace over time The tighter we cling to an identity, the harder it becomes to grow beyond it","title":"Atomic Habits"},{"location":"booksNovels/atomicHabits/#atomic-habits-an-easy-proven-way-to-build-good-habits-break-bad-ones","text":"Author : James Clear","title":"Atomic Habits: An Easy &amp; Proven Way to Build Good Habits &amp; Break Bad Ones"},{"location":"booksNovels/atomicHabits/#the-fundamentals-why-tiny-changes-make-a-big-difference","text":"","title":"The Fundamentals : Why Tiny Changes Make a Big Difference"},{"location":"booksNovels/atomicHabits/#the-surprising-power-of-atomic-habits","text":"Habits are the compound interest of self-improvement. Getting 1 percent better every daycounts for a lot in the long run Habits are a double-edged sword. They can work for you or against you, which is whyunderstanding the details is essential. Small changes often appear to make no difference until you cross a critical threshold. Themost powerful outcomes of any compounding process are delayed. You need to be patient. An atomic habit is a little habit that is part of a larger system. Just as atoms are thebuilding blocks of molecules, atomic habits are the building blocks of remarkable results. If you want better results, then forget about setting goals. Focus on your system instead. You do not rise to the level of your goals. You fall to the level of you systems.","title":"The Surprising Power of Atomic Habits"},{"location":"booksNovels/atomicHabits/#how-your-habits-shape-your-identity-and-vice-versa","text":"There are three levels of change : outcome change, process change, and identity change. The most effective way to change your habits is to focus not on what you want to achieve, buton who you wish to become. Your identity emerges out of your habits. Every action is a vote for the type of person youwish to become. Becoming the best version of yourself requires you to continuously edit your beliefs, and toupgrade and expand your identity. The real reason habits matter is not because they can get you better results (although theycan do that), but because they can change your beliefs about yourself.","title":"How Your Habits Shape Your Identity (and Vice Versa)"},{"location":"booksNovels/atomicHabits/#how-to-build-better-habits-in-4-simple-steps","text":"A habit is a behaviour that has been repeated enough times to become automatic. The ultimate purpose of habits is to solve the problems of life with as little energy andeffort as possible. Any habit can be broken down into a feedback loop that involves four steps : Cue Craving Response Reward The Four Laws of Behaviour Change are a simple set of rules we can use to build betterhabits. They are: Make it obvious Make it attractive Make it easy Make it satisfying","title":"How to Build Better Habits in 4 Simple Steps"},{"location":"booksNovels/atomicHabits/#the-1st-law-make-it-obvious","text":"","title":"The 1st Law : Make It Obvious"},{"location":"booksNovels/atomicHabits/#the-man-who-didnt-look-right","text":"With enough practice, your brain will pick up on the cues that predict certain outcomeswithout consciously thinking about it. Once our habits become automatic, we stop paying attention to what we are doing. The process of behavious change always starts with awareness. You need to be aware of yourhabits before you can change them. Pointing-and-calling raises your level of awareness from a nonconsious habit to a moreconscious level by verbalizing your actions. The Habits Scorecard is a simple exercise you can use to become more aware of your behaviour","title":"The Man Who Didn\u2019t Look Right"},{"location":"booksNovels/atomicHabits/#the-best-way-to-start-a-new-habit","text":"The first law of behavious change is make it obvious The two most common cues are time and location Creating an implementation intention is a strategy you can use to pair a new habit with aspecific time and location. The implementation intention formula is : \"I will [BEHAVIOUR] at [TIME] in [LOCATION]\". Habit stacking is a strategy you can use to pair a new habit with a current habit The habit stacking formula is : \"After [CURRENT HABIT], i will [NEW HABIT]\".","title":"The Best Way to Start a New Habit"},{"location":"booksNovels/atomicHabits/#motivation-is-overrated-environment-often-matters-more","text":"Small changes in context can lead to large changes in behaviour over time Every habit is initiated by a cue. We are more likely to notice cues that stand out. Make the cues of good habits obvious in you environment Gradually, your habits become associated not with a single trigger but with the entire context surrounding the behaviour. The context becomes the cue. It is easier to build new habits in a new environment because you are not fighting against old cues.","title":"Motivation Is Overrated; Environment Often Matters More"},{"location":"booksNovels/atomicHabits/#the-secret-to-self-control","text":"The inversion of the 1st Law of Behaviour Change is make it invisible. Once a habit is formed, it is unlikely to be forgotten. People with high self-control tend to spend less time in tempting situations. It's easier to avoid temptation that resist it. One of the most practical ways to eliminate a bad habit is to reduce exposure to the cue thatcauses it. Self-control is a short-term strategy, not a long-term one.","title":"The Secret to Self-Control"},{"location":"booksNovels/atomicHabits/#the-2nd-law-make-it-attractive","text":"","title":"The 2nd Law : Make It Attractive"},{"location":"booksNovels/atomicHabits/#how-to-make-a-habit-irresistible","text":"The 2nd Law of Behaviour Change is make it attractive The more attractive an opportunity is, the more likely it is to become habit-forming Habits are a dopamine-driven feedback loop. When dopamine rises, so does our motivation to act. It is the anticipation of a reward - not the fulfillment of it - that gets us to take action. The greater the anticipation, the greater the dopamine spike. Temptation bundling is one way to make your habits more attractive. The strategy is to pair an action you want to do with an action you need to do","title":"How to Make a Habit Irresistible"},{"location":"booksNovels/atomicHabits/#the-role-of-family-and-friends-in-shaping-your-habits","text":"The culture we live in determines which behaviours are attractive to us. We tend to adopt habits that are praised and approved of by our culture because we have a strong desire to fit in and belong to the tribe We tend to imitate the habits of three social groups : the close (family and friends), the many (tribe), and the powerful(those with status and prestige) One of the most effective things you can do to build better habits is to join a culture where Your desired behaviour is the normal behaviour You already have something in common with the group The normal behaviour of the tribe often overpowers the desired behaviour of the individual. Most days, we'd rather be wrong with the crowd than be right by ourselves If a behaviour can get us approval, respect, and praise, we find it attractive","title":"The Role of Family and Friends in Shaping Your Habits"},{"location":"booksNovels/atomicHabits/#how-to-find-and-fix-the-causes-of-your-bad-habits","text":"The inversion of the 2nd Law of Behaviour Change is make it unattractive Every behaviour has a surface level craving and a deeper underlying motive Your habits are modern-day solutions to ancient desires. The cause of your habits is actually the prediction that precedes them. The prediction leads to a feeling Highlight the benefits of avoiding a bad habit to make it seem unattractive Habits are attractive when we associate them with positive feelings and unattractive when we associate them with negative feelings. Create a motivation ritual by doing something you enjoy immediately before a difficult habit","title":"How to Find and Fix the Causes of Your Bad Habits"},{"location":"booksNovels/atomicHabits/#the-3nd-law-make-it-easy","text":"","title":"The 3nd Law : Make it Easy"},{"location":"booksNovels/atomicHabits/#walk-slowly-but-never-backward","text":"The 3rd Law of Behaviour Change is make it easy The most effective form of learning is practice, not planning Focus on taking action, not being in motion Habit formation is the process by which a behaviour becomes progressively more automatic through repetition The amount of time you have been performing a habit is not as important as the number of times you have performed it","title":"Walk Slowly, but Never Backward"},{"location":"booksNovels/atomicHabits/#the-law-of-least-effort","text":"Human behaviour follows the Law of Least Effort. We will naturally gravitate toward the option that requires the least amount of work Create an environment where doing the right thing is as easy as possible Reduce the friction associated with good behaviours. When friction is low, habits are easy. Increase the friction associated with bad behaviours. When frictionis high, habits are difficult Prime your environment to make future actions easier","title":"The Law of Least Effort"},{"location":"booksNovels/atomicHabits/#how-to-stop-procrastinating-by-using-the-two-minute-rule","text":"Habits are completed in a few seconds but continue to impact your behaviour for minutes or hours afterwards Many habits occur at decisive moments - choices that are like a fork in the road - and either send you in a direction of a productive day or an unproductive one The Two-Minute Rule states, \"When you start a new habit, it should take less that 2 minutes to do\" The more you ritualize the beginning of a process, the more likely it becomes that you can slip into the state of deep focus that is required to do great things Standardize before you optimize. You can't improve a habit that doesn't exist","title":"How to Stop Procrastinating by Using the Two-Minute Rule"},{"location":"booksNovels/atomicHabits/#how-to-make-good-habits-inevitable-and-bad-habits-impossible","text":"The inversion of the 3rd Law of Behaviour Change is make it difficult A commitment device is a choice you make in the present that locks in better behaviour in thefuture The ultimate way to lock in future behaviour is to automate your habits Onetime choices - like buying a better mattress or enrolling in an automatic savings plan - are single actions that automate your future habits and deliver increasing returns over time Using technology to automate your habits is the most reliable and effective way to guarantee the right Behaviour","title":"How to Make Good Habits Inevitable and Bad Habits Impossible"},{"location":"booksNovels/atomicHabits/#the-4th-law-make-it-satisfying","text":"","title":"The 4th Law : Make It Satisfying"},{"location":"booksNovels/atomicHabits/#the-cardinal-rule-of-behaviour-change","text":"The 4th Law of Behaviour Change is make it satisfying We are more likely to repeat a behaviour when the experience is satisfying The human brain evolved to prioritize immediate rewards over delayed rewards The Cardinal Rule of Behaviour Change : What is immediately rewarded is repeated. What is immediately punished is avoided To get a habit to stick you need to feel immediately successful - even if it's in a small way The first three laws of behaviour change - make it obvious, make it attractive, and make it easy increase the odds that a behaviour will be performed this time. The fourth law of behaviourn change - make it satisfying - increases the odds that a behaviour will be repeated next time","title":"The Cardinal Rule of Behaviour Change"},{"location":"booksNovels/atomicHabits/#how-to-stick-with-good-habits-every-day","text":"One of the most satisfying feelings is the feeling of making progress A habit tracker is a simple way to measure whether you did a habit - like marking an X on a calendar Habit trackers and other visual forms of measurement can make your habits satisfying by providing clear evidence of your progress Don't break the chain. Try to keep you habit streak alive Never miss twice. If you miss one day, try to get back on track as quickly as possible. Just because you can measure something doesn't mean it's the most important thing","title":"How to Stick with Good Habits Every Day"},{"location":"booksNovels/atomicHabits/#how-an-accountability-partner-can-change-everything","text":"The inversion of the 4th Law of Behaviour Change is make it unsatisfying We are less likely to repeat a bad habit if it is painful or unsatisfying An accountability partner can create an immediate cost to inaction. We care deeply about what others think of us, and we do not want others to have a lesser opinion of us A habit contract can be used to add a social cost to any behaviour. It makes the costs of violating your promises public and painful Knowing that someone else is watching you can be a powerful motivator","title":"How an Accountability Partner Can Change Everything"},{"location":"booksNovels/atomicHabits/#advanced-tactics-how-to-go-from-being-merely-good-to-being-truly-great","text":"","title":"Advanced tactics : How to Go from Being Merely Good to Being Truly Great"},{"location":"booksNovels/atomicHabits/#the-truth-about-talent-when-genes-matter-and-when-they-dont","text":"The secret of maximizing your odds of success is to choose the right field of competition Pick the right habit and progress is easy. Pick the wrong habit and life is a struggle Genes cannot be easily changed, which means they provide a powerful advantage in favourable circumstances and a serious disadvantage in unfavourable circumstances Habits are easier when they align with your natural abilities. Choose the habits that best suits you Play a game that favors your strengths. If you can't find a game that favors you, create one Genes do not eliminate the need for hard work. They clarify it. They tell us what to work hard on","title":"The Truth About Talent (When Genes Matter and When They Don\u2019t)"},{"location":"booksNovels/atomicHabits/#the-goldilocks-rule-how-to-stay-motivated-in-life-and-work","text":"The Goldilocks Rule states that humans experience peak motivation when working on tasks that are right on the edge of their current abilities The greatest threat to success is not failure but boredom As habits become routine, they become less interesting and less satisfying. We get bored Anyone can work hard when they feel motivated. It's the ability to keep going when work isn't exciting that makes the difference Professionals stick to the schedule, amateurs let life get in the way","title":"The Goldilocks Rule: How to Stay Motivated in Life and Work"},{"location":"booksNovels/atomicHabits/#the-downside-of-creating-good-habits","text":"The upside of habits is that we can do things without thinking. The downside is that we stop paying attention to little errors Habits + Deliberate Practice = Mastery Reflection and review is a process that allows you to maintain conscious of your performace over time The tighter we cling to an identity, the harder it becomes to grow beyond it","title":"The Downside of Creating Good Habits"},{"location":"booksNovels/selfDevelopmentBooks/","text":"Self Development Books This documentation contains the links to Self Development Books notes. List of Self Development Books: Atomic Habits","title":"Self Development Books list"},{"location":"booksNovels/selfDevelopmentBooks/#self-development-books","text":"This documentation contains the links to Self Development Books notes.","title":"Self Development Books"},{"location":"booksNovels/selfDevelopmentBooks/#list-of-self-development-books","text":"Atomic Habits","title":"List of Self Development Books:"},{"location":"freeCodeCamp/freeCodeCamp/","text":"FreeCodeCamp courses This documentation contains the links to FreeCodeCamp course. List of FreeCodeCamp courses: SQL Database Course","title":"Free Code Camp Contents"},{"location":"freeCodeCamp/freeCodeCamp/#freecodecamp-courses","text":"This documentation contains the links to FreeCodeCamp course.","title":"FreeCodeCamp courses"},{"location":"freeCodeCamp/freeCodeCamp/#list-of-freecodecamp-courses","text":"SQL Database Course","title":"List of FreeCodeCamp courses:"},{"location":"freeCodeCamp/youtube/sqlDatabaseCourse/","text":"SQL Tutorial Full Database Course Source : Youtube Video What is a Database (DB)? Any collection related information Phone Book Shopping List Todo List Your 5 best friends Facebook's User Base Databases can be stored in different ways On paper In your mind On a computer This powerpoint Comments section Database Management Systems (DBMS) A special software program that helps user create and maintain a database Makes it easier to manage large amounts of information Handles security Backups Importing/exporting data Concurrency Interacts with software applications Programming languages C.R.U.D C -- Create R -- Read U -- Update D -- Delete Two types of databases Relational Databases (SQL) Organize data into one or more tables Each table has columns and rows A unique key identifies each row Non-Relational (noSql / not just SQL) Organize data is anything but a traditional table Key-value stores Documents (JSON, XML, etc.) Graphs Flexible Tables Relational Databases (SQL) Relational Database Management Systems (RDBMS) Help users create and maintain a relational database mySQL Oracle postgreSQL mariaDB Structured Query Language (SQL) Stardardized language for interacting with RDBMS Used to perform C.R.U.D operations, as well as other administrative tasks (user management, security, backups, etc.) Used to define tables and structures SQL code used on one RDBMS is not always protable to another without modification Non-Relational Databases (noSQL) Non-Relational Database Management Systems (NRDBMS) Help users create and maintain a non-relational database mongoDB dynamoDB apache cassandra firebase, etc. Implementation Specific Any non-relational database falls under this category, so there's no set language standard Most NRCBMS will implement their own language for performing C.R.U.D and administrative operations on the database Database Queries Queries are requests made to the database management system for specific information As the database's structure become more and more complex it becomes more difficult to get the specific pieces of information we want A google search is a Query Summary Database is any collection of related information Computer are great for storing databases DBMS make it easy to create, maintain, and secure a database DBMS allow you to perform the C.R.U.D operations and other administrative tasks Two types of Databases : Relational and Non-Relational Relational databses use SQL and store data in tables with rows and columns Non-Relational data store data using other data structures Tables and Keys Tables are made of rows and columns Types of Keys Primary Key Foreign Key Composite Key SQL Basics SQL SQL is a language used for interacting with RDBMS You can use SQL to get the RDBMS to do things for you Create, retrieve, update and delete data Create and manage databases Design and create database tables Perform administration tasks (securit, user management, import/export. etc.) SQL implementations vary between systems Not all RDBMS' follow the SQL standard to a 'T' The concepts are the same but the implementation may vary SQL is actaully a hybrid language, it's basically 4 types of languages in one Data Query Language (DQL) Used to query the database for information Get information that is already stored there Data Definition Language (DDL) Used for controlling access to the data in the database User and permissions management Data Manipulation Language (DML) used for inserting, updating and deleting data from the database Queries A query is a set of instructions given to the RDBMS (written in SQL) that tell the RDBMS what information you want it to retrieve for you Tons of data in a DB Often hidden in a complex schema Goal is to only get the data you need Creating Tables Data types in SQL INT DECIMAL(M,N) VARCAHR(1) BLOB DATE TIMESTAMP Create table syntax CREATE TABLE table_name( column1 datatype, column2 datatype, column3 datatype, ..... columnN datatype, PRIMARY KEY( one or more columns ) ); Drop table syntax DROP TABLE table_name; Inserting Data Insert data syntax INSERT INTO TABLE_NAME (column1, column2, column3,...columnN) VALUES (value1, value2, value3,...valueN); INSERT INTO TABLE_NAME VALUES (value1,value2,value3,...valueN); Constraints The following are commonly used constraints available in PostgreSQL: NOT NULL Constraint Ensures that a column cannot have NULL value. UNIQUE Constraint Ensures that all values in a column are different. PRIMARY Key Uniquely identifies each row/record in a database table. FOREIGN Key Constrains data based on columns in other tables. CHECK Constraint The CHECK constraint ensures that all values in a column satisfy certain conditions. EXCLUSION Constraint The EXCLUDE constraint ensures that if any two rows are compared on the specified column(s) or expression(s) using the specified operator(s), not all of these comparisons will return TRUE. DEFAULT Constraint If nothing is provided the default value is taken as the column value Update and Delete Update query syntax UPDATE table_name SET column1 = value1, column2 = value2...., columnN = valueN WHERE [condition]; Delete query syntax DELETE FROM table_name WHERE [condition]; Basic Queries Select query syntax SELECT column1, column2, columnN FROM table_name; SELECT * FROM table_name; SELECT * FROM table_name WHERE [condition]; More Basic Queries LIMIT clause The PostgreSQL LIMIT clause is used to limit the data amount returned by the SELECT statement. SELECT column1, column2, columnN FROM table_name LIMIT [no of rows] SELECT column1, column2, columnN FROM table_name LIMIT [no of rows] OFFSET [row num] ORDER BY clause The PostgreSQL ORDER BY clause is used to sort the data in ascending or descending order, based on one or more columns. SELECT column-list FROM table_name [WHERE condition] [ORDER BY column1, column2, .. columnN] [ASC | DESC]; GROUP BY clause The PostgreSQL GROUP BY clause is used in collaboration with the SELECT statement to group together those rows in a table that have identical data. This is done to eliminate redundancy in the output and/or compute aggregates that apply to these groups. The GROUP BY clause follows the WHERE clause in a SELECT statement and precedes the ORDER BY clause. SELECT column-list FROM table_name WHERE [ conditions ] GROUP BY column1, column2....columnN ORDER BY column1, column2....columnN WITH clause In PostgreSQL, the WITH query provides a way to write auxiliary statements for use in a larger query. It helps in breaking down complicated and large queries into simpler forms, which are easily readable. These statements often referred to as Common Table Expressions or CTEs, can be thought of as defining temporary tables that exist just for one query. WITH name_for_summary_data AS ( SELECT Statement) SELECT columns FROM name_for_summary_data WHERE conditions <=> ( SELECT column FROM name_for_summary_data) [ORDER BY columns] HAVING clause The HAVING clause allows us to pick out particular rows where the function's result meets some condition. SELECT column1, column2 FROM table1, table2 WHERE [ conditions ] GROUP BY column1, column2 HAVING [ conditions ] ORDER BY column1, column2 DISTINCT keyword The PostgreSQL DISTINCT keyword is used in conjunction with SELECT statement to eliminate all the duplicate records and fetching only unique records. SELECT DISTINCT column1, column2,.....columnN FROM table_name WHERE [condition] Wildcards SQL LIKE operator is used to compare a value to similar values using the wildcard operators. SQL supports two wildcard operators in conjunction with the LIKE operator The percent sign (%) Matches one or more characters. The underscore (_) Matches one character. Unions The PostgreSQL UNION clause/operator is used to combine the results of two or more SELECT statements without returning any duplicate rows. To use UNION, each SELECT must have the same number of columns selected, the same number of column expressions, the same data type, and have them in the same order but they do not have to be the same length. SELECT column1 [, column2 ] FROM table1 [, table2 ] [WHERE condition] UNION SELECT column1 [, column2 ] FROM table1 [, table2 ] [WHERE condition] Joins The PostgreSQL Joins clause is used to combine records from two or more tables in a database. A JOIN is a means for combining fields from two tables by using values common to each. Join Types in PostgreSQL are \u2212 The CROSS JOIN The INNER JOIN The LEFT OUTER JOIN The RIGHT OUTER JOIN The FULL OUTER JOIN The CROSS JOIN A CROSS JOIN matches every row of the first table with every row of the second table. If the input tables have x and y columns, respectively, the resulting table will have x+y columns. Because CROSS JOINs have the potential to generate extremely large tables, care must be taken to use them only when appropriate. SELECT ... FROM table1 CROSS JOIN table2 ... The INNER JOIN A INNER JOIN creates a new result table by combining column values of two tables (table1 and table2) based upon the join-predicate. The query compares each row of table1 with each row of table2 to find all pairs of rows, which satisfy the join-predicate. When the join-predicate is satisfied, column values for each matched pair of rows of table1 and table2 are combined into a result row. SELECT table1.column1, table2.column2... FROM table1 INNER JOIN table2 ON table1.common_filed = table2.common_field; The LEFT OUTER JOIN In case of LEFT OUTER JOIN, an inner join is performed first. Then, for each row in table T1 that does not satisfy the join condition with any row in table T2, a joined row is added with null values in columns of T2. Thus, the joined table always has at least one row for each row in T1. SELECT ... FROM table1 LEFT OUTER JOIN table2 ON conditional_expression ... The RIGHT OUTER JOIN First, an inner join is performed. Then, for each row in table T2 that does not satisfy the join condition with any row in table T1, a joined row is added with null values in columns of T1. This is the converse of a left join; the result table will always have a row for each row in T2. SELECT ... FROM table1 RIGHT OUTER JOIN table2 ON conditional_expression ... The FULL OUTER JOIN First, an inner join is performed. Then, for each row in table T1 that does not satisfy the join condition with any row in table T2, a joined row is added with null values in columns of T2. In addition, for each row of T2 that does not satisfy the join condition with any row in T1, a joined row with null values in the columns of T1 is added. name_for_summary_data. SELECT ... FROM table1 FULL OUTER JOIN table2 ON conditional_expression ... Nested query A subquery is used to return data that will be used in the main query as a condition to further restrict the data to be retrieved. Subqueries with the SELECT Statement SELECT column_name [, column_name ] FROM table1 [, table2 ] WHERE column_name OPERATOR (SELECT column_name [, column_name ] FROM table1 [, table2 ] [WHERE]) Subqueries with the INSERT Statement INSERT INTO table_name [ (column1 [, column2 ]) ] SELECT [ *|column1 [, column2 ] ] FROM table1 [, table2 ] [ WHERE VALUE OPERATOR ] Subqueries with the UPDATE Statement UPDATE table SET column_name = new_value [ WHERE OPERATOR [ VALUE ] (SELECT COLUMN_NAME FROM TABLE_NAME) [ WHERE) ] Subqueries with the DELETE Statement DELETE FROM TABLE_NAME [ WHERE OPERATOR [ VALUE ] (SELECT COLUMN_NAME FROM TABLE_NAME) [ WHERE) ] Triggers PostgreSQL Triggers are database callback functions, which are automatically performed/invoked when a specified database event occurs. CREATE TRIGGER trigger_name [BEFORE|AFTER|INSTEAD OF] event_name ON table_name [ -- Trigger logic goes here.... ]; ER Diagram Entity An object we want to model and store information about Attributes Specific pieces of information about an entity Primary Key An attribute that uniquely identify an entry in the database table Composite attribute An attribute that can be broken into sub-attributes Multi-valued attribute An attribute that can have more than one value Derived attribute An attribute that can be derived from the other attributes Multiple entities You can define more than one entity in the diagram Relationships Defines a relationship between two entities Total participation All members must participate in the relationship Relationship Attribute An attribute about the relationship Relationship Cardinality The number of instances of an entity from a relation that can be associated with the relation Weak entity An entity that cannot be uniquely identified by its attributes alone Identifying relationship A relationship that serves to uniquely identify the weak entity","title":"Sql Database Course"},{"location":"freeCodeCamp/youtube/sqlDatabaseCourse/#sql-tutorial-full-database-course","text":"Source : Youtube Video","title":"SQL Tutorial Full Database Course"},{"location":"freeCodeCamp/youtube/sqlDatabaseCourse/#what-is-a-database-db","text":"Any collection related information Phone Book Shopping List Todo List Your 5 best friends Facebook's User Base Databases can be stored in different ways On paper In your mind On a computer This powerpoint Comments section Database Management Systems (DBMS) A special software program that helps user create and maintain a database Makes it easier to manage large amounts of information Handles security Backups Importing/exporting data Concurrency Interacts with software applications Programming languages C.R.U.D C -- Create R -- Read U -- Update D -- Delete Two types of databases Relational Databases (SQL) Organize data into one or more tables Each table has columns and rows A unique key identifies each row Non-Relational (noSql / not just SQL) Organize data is anything but a traditional table Key-value stores Documents (JSON, XML, etc.) Graphs Flexible Tables Relational Databases (SQL) Relational Database Management Systems (RDBMS) Help users create and maintain a relational database mySQL Oracle postgreSQL mariaDB Structured Query Language (SQL) Stardardized language for interacting with RDBMS Used to perform C.R.U.D operations, as well as other administrative tasks (user management, security, backups, etc.) Used to define tables and structures SQL code used on one RDBMS is not always protable to another without modification Non-Relational Databases (noSQL) Non-Relational Database Management Systems (NRDBMS) Help users create and maintain a non-relational database mongoDB dynamoDB apache cassandra firebase, etc. Implementation Specific Any non-relational database falls under this category, so there's no set language standard Most NRCBMS will implement their own language for performing C.R.U.D and administrative operations on the database Database Queries Queries are requests made to the database management system for specific information As the database's structure become more and more complex it becomes more difficult to get the specific pieces of information we want A google search is a Query Summary Database is any collection of related information Computer are great for storing databases DBMS make it easy to create, maintain, and secure a database DBMS allow you to perform the C.R.U.D operations and other administrative tasks Two types of Databases : Relational and Non-Relational Relational databses use SQL and store data in tables with rows and columns Non-Relational data store data using other data structures","title":"What is a Database (DB)?"},{"location":"freeCodeCamp/youtube/sqlDatabaseCourse/#tables-and-keys","text":"Tables are made of rows and columns Types of Keys Primary Key Foreign Key Composite Key","title":"Tables and Keys"},{"location":"freeCodeCamp/youtube/sqlDatabaseCourse/#sql-basics","text":"SQL SQL is a language used for interacting with RDBMS You can use SQL to get the RDBMS to do things for you Create, retrieve, update and delete data Create and manage databases Design and create database tables Perform administration tasks (securit, user management, import/export. etc.) SQL implementations vary between systems Not all RDBMS' follow the SQL standard to a 'T' The concepts are the same but the implementation may vary SQL is actaully a hybrid language, it's basically 4 types of languages in one Data Query Language (DQL) Used to query the database for information Get information that is already stored there Data Definition Language (DDL) Used for controlling access to the data in the database User and permissions management Data Manipulation Language (DML) used for inserting, updating and deleting data from the database Queries A query is a set of instructions given to the RDBMS (written in SQL) that tell the RDBMS what information you want it to retrieve for you Tons of data in a DB Often hidden in a complex schema Goal is to only get the data you need","title":"SQL Basics"},{"location":"freeCodeCamp/youtube/sqlDatabaseCourse/#creating-tables","text":"Data types in SQL INT DECIMAL(M,N) VARCAHR(1) BLOB DATE TIMESTAMP Create table syntax CREATE TABLE table_name( column1 datatype, column2 datatype, column3 datatype, ..... columnN datatype, PRIMARY KEY( one or more columns ) ); Drop table syntax DROP TABLE table_name;","title":"Creating Tables"},{"location":"freeCodeCamp/youtube/sqlDatabaseCourse/#inserting-data","text":"Insert data syntax INSERT INTO TABLE_NAME (column1, column2, column3,...columnN) VALUES (value1, value2, value3,...valueN); INSERT INTO TABLE_NAME VALUES (value1,value2,value3,...valueN);","title":"Inserting Data"},{"location":"freeCodeCamp/youtube/sqlDatabaseCourse/#constraints","text":"The following are commonly used constraints available in PostgreSQL: NOT NULL Constraint Ensures that a column cannot have NULL value. UNIQUE Constraint Ensures that all values in a column are different. PRIMARY Key Uniquely identifies each row/record in a database table. FOREIGN Key Constrains data based on columns in other tables. CHECK Constraint The CHECK constraint ensures that all values in a column satisfy certain conditions. EXCLUSION Constraint The EXCLUDE constraint ensures that if any two rows are compared on the specified column(s) or expression(s) using the specified operator(s), not all of these comparisons will return TRUE. DEFAULT Constraint If nothing is provided the default value is taken as the column value","title":"Constraints"},{"location":"freeCodeCamp/youtube/sqlDatabaseCourse/#update-and-delete","text":"Update query syntax UPDATE table_name SET column1 = value1, column2 = value2...., columnN = valueN WHERE [condition]; Delete query syntax DELETE FROM table_name WHERE [condition];","title":"Update and Delete"},{"location":"freeCodeCamp/youtube/sqlDatabaseCourse/#basic-queries","text":"Select query syntax SELECT column1, column2, columnN FROM table_name; SELECT * FROM table_name; SELECT * FROM table_name WHERE [condition];","title":"Basic Queries"},{"location":"freeCodeCamp/youtube/sqlDatabaseCourse/#more-basic-queries","text":"LIMIT clause The PostgreSQL LIMIT clause is used to limit the data amount returned by the SELECT statement. SELECT column1, column2, columnN FROM table_name LIMIT [no of rows] SELECT column1, column2, columnN FROM table_name LIMIT [no of rows] OFFSET [row num] ORDER BY clause The PostgreSQL ORDER BY clause is used to sort the data in ascending or descending order, based on one or more columns. SELECT column-list FROM table_name [WHERE condition] [ORDER BY column1, column2, .. columnN] [ASC | DESC]; GROUP BY clause The PostgreSQL GROUP BY clause is used in collaboration with the SELECT statement to group together those rows in a table that have identical data. This is done to eliminate redundancy in the output and/or compute aggregates that apply to these groups. The GROUP BY clause follows the WHERE clause in a SELECT statement and precedes the ORDER BY clause. SELECT column-list FROM table_name WHERE [ conditions ] GROUP BY column1, column2....columnN ORDER BY column1, column2....columnN WITH clause In PostgreSQL, the WITH query provides a way to write auxiliary statements for use in a larger query. It helps in breaking down complicated and large queries into simpler forms, which are easily readable. These statements often referred to as Common Table Expressions or CTEs, can be thought of as defining temporary tables that exist just for one query. WITH name_for_summary_data AS ( SELECT Statement) SELECT columns FROM name_for_summary_data WHERE conditions <=> ( SELECT column FROM name_for_summary_data) [ORDER BY columns] HAVING clause The HAVING clause allows us to pick out particular rows where the function's result meets some condition. SELECT column1, column2 FROM table1, table2 WHERE [ conditions ] GROUP BY column1, column2 HAVING [ conditions ] ORDER BY column1, column2 DISTINCT keyword The PostgreSQL DISTINCT keyword is used in conjunction with SELECT statement to eliminate all the duplicate records and fetching only unique records. SELECT DISTINCT column1, column2,.....columnN FROM table_name WHERE [condition]","title":"More Basic Queries"},{"location":"freeCodeCamp/youtube/sqlDatabaseCourse/#wildcards","text":"SQL LIKE operator is used to compare a value to similar values using the wildcard operators. SQL supports two wildcard operators in conjunction with the LIKE operator The percent sign (%) Matches one or more characters. The underscore (_) Matches one character.","title":"Wildcards"},{"location":"freeCodeCamp/youtube/sqlDatabaseCourse/#unions","text":"The PostgreSQL UNION clause/operator is used to combine the results of two or more SELECT statements without returning any duplicate rows. To use UNION, each SELECT must have the same number of columns selected, the same number of column expressions, the same data type, and have them in the same order but they do not have to be the same length. SELECT column1 [, column2 ] FROM table1 [, table2 ] [WHERE condition] UNION SELECT column1 [, column2 ] FROM table1 [, table2 ] [WHERE condition]","title":"Unions"},{"location":"freeCodeCamp/youtube/sqlDatabaseCourse/#joins","text":"The PostgreSQL Joins clause is used to combine records from two or more tables in a database. A JOIN is a means for combining fields from two tables by using values common to each. Join Types in PostgreSQL are \u2212 The CROSS JOIN The INNER JOIN The LEFT OUTER JOIN The RIGHT OUTER JOIN The FULL OUTER JOIN The CROSS JOIN A CROSS JOIN matches every row of the first table with every row of the second table. If the input tables have x and y columns, respectively, the resulting table will have x+y columns. Because CROSS JOINs have the potential to generate extremely large tables, care must be taken to use them only when appropriate. SELECT ... FROM table1 CROSS JOIN table2 ... The INNER JOIN A INNER JOIN creates a new result table by combining column values of two tables (table1 and table2) based upon the join-predicate. The query compares each row of table1 with each row of table2 to find all pairs of rows, which satisfy the join-predicate. When the join-predicate is satisfied, column values for each matched pair of rows of table1 and table2 are combined into a result row. SELECT table1.column1, table2.column2... FROM table1 INNER JOIN table2 ON table1.common_filed = table2.common_field; The LEFT OUTER JOIN In case of LEFT OUTER JOIN, an inner join is performed first. Then, for each row in table T1 that does not satisfy the join condition with any row in table T2, a joined row is added with null values in columns of T2. Thus, the joined table always has at least one row for each row in T1. SELECT ... FROM table1 LEFT OUTER JOIN table2 ON conditional_expression ... The RIGHT OUTER JOIN First, an inner join is performed. Then, for each row in table T2 that does not satisfy the join condition with any row in table T1, a joined row is added with null values in columns of T1. This is the converse of a left join; the result table will always have a row for each row in T2. SELECT ... FROM table1 RIGHT OUTER JOIN table2 ON conditional_expression ... The FULL OUTER JOIN First, an inner join is performed. Then, for each row in table T1 that does not satisfy the join condition with any row in table T2, a joined row is added with null values in columns of T2. In addition, for each row of T2 that does not satisfy the join condition with any row in T1, a joined row with null values in the columns of T1 is added. name_for_summary_data. SELECT ... FROM table1 FULL OUTER JOIN table2 ON conditional_expression ...","title":"Joins"},{"location":"freeCodeCamp/youtube/sqlDatabaseCourse/#nested-query","text":"A subquery is used to return data that will be used in the main query as a condition to further restrict the data to be retrieved. Subqueries with the SELECT Statement SELECT column_name [, column_name ] FROM table1 [, table2 ] WHERE column_name OPERATOR (SELECT column_name [, column_name ] FROM table1 [, table2 ] [WHERE]) Subqueries with the INSERT Statement INSERT INTO table_name [ (column1 [, column2 ]) ] SELECT [ *|column1 [, column2 ] ] FROM table1 [, table2 ] [ WHERE VALUE OPERATOR ] Subqueries with the UPDATE Statement UPDATE table SET column_name = new_value [ WHERE OPERATOR [ VALUE ] (SELECT COLUMN_NAME FROM TABLE_NAME) [ WHERE) ] Subqueries with the DELETE Statement DELETE FROM TABLE_NAME [ WHERE OPERATOR [ VALUE ] (SELECT COLUMN_NAME FROM TABLE_NAME) [ WHERE) ]","title":"Nested query"},{"location":"freeCodeCamp/youtube/sqlDatabaseCourse/#triggers","text":"PostgreSQL Triggers are database callback functions, which are automatically performed/invoked when a specified database event occurs. CREATE TRIGGER trigger_name [BEFORE|AFTER|INSTEAD OF] event_name ON table_name [ -- Trigger logic goes here.... ];","title":"Triggers"},{"location":"freeCodeCamp/youtube/sqlDatabaseCourse/#er-diagram","text":"Entity An object we want to model and store information about Attributes Specific pieces of information about an entity Primary Key An attribute that uniquely identify an entry in the database table Composite attribute An attribute that can be broken into sub-attributes Multi-valued attribute An attribute that can have more than one value Derived attribute An attribute that can be derived from the other attributes Multiple entities You can define more than one entity in the diagram Relationships Defines a relationship between two entities Total participation All members must participate in the relationship Relationship Attribute An attribute about the relationship Relationship Cardinality The number of instances of an entity from a relation that can be associated with the relation Weak entity An entity that cannot be uniquely identified by its attributes alone Identifying relationship A relationship that serves to uniquely identify the weak entity","title":"ER Diagram"},{"location":"nptel/nptel/","text":"Nptel courses This documentation contains the links to Nptel course. List of Nptel courses: System Analysis and Design Information for management","title":"Nptel"},{"location":"nptel/nptel/#nptel-courses","text":"This documentation contains the links to Nptel course.","title":"Nptel courses"},{"location":"nptel/nptel/#list-of-nptel-courses","text":"System Analysis and Design Information for management","title":"List of Nptel courses:"},{"location":"nptel/systemAnalysisAndDesign/module1/","text":"Information for management Module contents Data and information, types of information : Operational Tactical Strategic Statutory Why do we need information systems, management structure, requirements of information atdifferent levels of management Functional allocation of management requirements of information for various functions Qualities of information Varieties of information system Motivation Large number of jobs today for computer science and engineering graduates is in creatinginformation systems for managing organizations Students should know what is information and how it is different from data Should know types of information needed to manage organizations Should know nature of organizations and their structure to design appropriate information system Learning Goals Distinction between data and information Description of types of information Tactical Operational Strategic Statutory Division of management into different hierarchical levels Types of information needed at different levels of management Division of organizations into several functional areas and their information requirements Attributes of information Data and information Data : Raw material Data collection costs money Collect only necessary and sufficient data Data is generally used by machines Data is useless unless it is processed to create information Information : Processed data Data processed by machines giving information Information is used to run an organisation efficiently Information used by managers to initiate actions Example of information needed by a shopkeeper Operational Information Daily sales account List of low stock items to be re-ordered List of overstock items Long overdue payments Profit and loss account * Used to streamline day to day operations called Operational information Tactical Information Slow or fast moving items Reliable supplier of items Sales trends * Used to improve profitability of shop called Tactical Information Strategic Information Whether to stock different varieties of items Whether to diversify Whether to start a new branch in a different locality Whether to start an e-shop Information to expand business and explore new opportunities Known as Strategic Information Statutory Information Income tax account Sales tax account Used to provide information to the government Known as Statutory Information Summary Strategic Needed for long range planning and directions. This is less structured. Tactical Needed to take short range decisions to improve profitability and performance Operational Needed for day to day operations of the organization Statutory Needed by law to be sent to government authorities Management hierarchy and information needs Line managers Volume of information : Large detailed reports Type of information : Highly structured Operational : Day to day policies Middle managers Volume of information : Medium moderately processed Type of information : Moderately structured Tactical : Short range improvement Top managers Volume of information : Low condensed Type of information : Unstructured Strategic : Long range planning Need for information systems Increasing size of organizations thus data volume increases Timely processing for fast action Better competitiveness with better information Increasing of complexity of organizations require innovative processing Distributed organizations Same data can be processed in different ways Management structure Top management Chief Executive known as CEO Executive Directors for each functional areas such as Production, Finance, HRD,etc. Take strategic decisions Middle management General managers, divisional managers, vice presidents, etc. Each functional area may have 2 or 3 middle level managers reporting to topmanagement Take tactical decisions Line managers Group managers, Assistant Group managers, Assistant managers Each functional area may have several line managers reporting to middle levclmanagers Take operational decisions Functional areas All organizations need not have identical functional areas However some are common such as Marketing Finance Human Resource Development (HRD) Production management Strategic information Yearly and monthly production quotes and alternate schedules Policies on machine replacement, augmentation, and modernization Identifying best product mix Tactical information Identifying and controlling areas of high costs Identifying critical bottlenecks in production Identifying alternate production schedules based on tools, machines, etc. Performace measures of machines to decide replacement Operational information Monitoring up to date production information by examining assemblies, detectinglikely shortages and giving early warning. Scheduling better production dynamically Preventive maintenance schedules Monitoring tool, machine and personnel availability Marketing management Strategic information Search new markets and marketing strategies Analysis of competitors strategy Technology and demographic forecasts and product changes Tactical information Advertising techniques and analysis of their impact Customer preference surveys Correlation of prices and sales Sales force deployment and targets Exploring alternate marketing channels Timing of special sales campaigns Operational information Sales analysis by regions, customer class, sales person Sales target versus achievement Market share and trends Seasonal variations Effect of model changes Performance of sales outlets Costs of campaigns and benefit Material management Strategic information Developing vendors for critical items Determining optimal levels of inventory Determining porportion of material needed Reducing varieties of inventory Tactical information Developing vendor performance measures Determining optimal reorder levels Determining issues of items to shops versus standard needs Controlling high value of inventory Determining impact on material cost and procurement with design changes and newproduct information Operational information List of excess and deficient items received List of items rejected Critical items received Stores in transit and in inspection Value of inventory in hand Goods received, rejected and issued Finance management Strategic information Methods of financing Pricing policies Tax planning Tactical information Variation between buidget and expenses Large outstanding payments/receipts Credit and payment status Operational information Periodic financial report Budget status to all functional managers Tax returns Share transfers Profit and loss account Payments and receipts Payroll, provident fund accounts Human resource management Strategic information Long range human resource requirements at different levels Policies on human resource development and training Policies on personnel welfare and facilities Tactical information Performace appraisal Demographic make-up of personnel and its impact on retirement Production incentives Morale of personnel Absentee reduction Leave and overtime policies Personnel deployment policies Operational information Routine assessment Skills inventory Loan/advances and recoveries Leave record Research design and development management Strategic information Which products are to be developed? What types of improvements are required? What long range research is more promising? What technical collaboration would be appropriate? Tactical information Setting intermediate goals Checking availability of equipment and appropriate selection Determining proportions of resources to be allocated to different projects Deployment of personnel to projects Information on similar and related research projects undertaken by other companies Operational information Progress against goals Budgeted expenses versus actual expenses Status of outstanding orders for equipment and components","title":"Information for Management"},{"location":"nptel/systemAnalysisAndDesign/module1/#information-for-management","text":"","title":"Information for management"},{"location":"nptel/systemAnalysisAndDesign/module1/#module-contents","text":"Data and information, types of information : Operational Tactical Strategic Statutory Why do we need information systems, management structure, requirements of information atdifferent levels of management Functional allocation of management requirements of information for various functions Qualities of information Varieties of information system","title":"Module contents"},{"location":"nptel/systemAnalysisAndDesign/module1/#motivation","text":"Large number of jobs today for computer science and engineering graduates is in creatinginformation systems for managing organizations Students should know what is information and how it is different from data Should know types of information needed to manage organizations Should know nature of organizations and their structure to design appropriate information system","title":"Motivation"},{"location":"nptel/systemAnalysisAndDesign/module1/#learning-goals","text":"Distinction between data and information Description of types of information Tactical Operational Strategic Statutory Division of management into different hierarchical levels Types of information needed at different levels of management Division of organizations into several functional areas and their information requirements Attributes of information","title":"Learning Goals"},{"location":"nptel/systemAnalysisAndDesign/module1/#data-and-information","text":"Data : Raw material Data collection costs money Collect only necessary and sufficient data Data is generally used by machines Data is useless unless it is processed to create information Information : Processed data Data processed by machines giving information Information is used to run an organisation efficiently Information used by managers to initiate actions Example of information needed by a shopkeeper Operational Information Daily sales account List of low stock items to be re-ordered List of overstock items Long overdue payments Profit and loss account * Used to streamline day to day operations called Operational information Tactical Information Slow or fast moving items Reliable supplier of items Sales trends * Used to improve profitability of shop called Tactical Information Strategic Information Whether to stock different varieties of items Whether to diversify Whether to start a new branch in a different locality Whether to start an e-shop Information to expand business and explore new opportunities Known as Strategic Information Statutory Information Income tax account Sales tax account Used to provide information to the government Known as Statutory Information Summary Strategic Needed for long range planning and directions. This is less structured. Tactical Needed to take short range decisions to improve profitability and performance Operational Needed for day to day operations of the organization Statutory Needed by law to be sent to government authorities Management hierarchy and information needs Line managers Volume of information : Large detailed reports Type of information : Highly structured Operational : Day to day policies Middle managers Volume of information : Medium moderately processed Type of information : Moderately structured Tactical : Short range improvement Top managers Volume of information : Low condensed Type of information : Unstructured Strategic : Long range planning Need for information systems Increasing size of organizations thus data volume increases Timely processing for fast action Better competitiveness with better information Increasing of complexity of organizations require innovative processing Distributed organizations Same data can be processed in different ways Management structure Top management Chief Executive known as CEO Executive Directors for each functional areas such as Production, Finance, HRD,etc. Take strategic decisions Middle management General managers, divisional managers, vice presidents, etc. Each functional area may have 2 or 3 middle level managers reporting to topmanagement Take tactical decisions Line managers Group managers, Assistant Group managers, Assistant managers Each functional area may have several line managers reporting to middle levclmanagers Take operational decisions Functional areas All organizations need not have identical functional areas However some are common such as Marketing Finance Human Resource Development (HRD) Production management Strategic information Yearly and monthly production quotes and alternate schedules Policies on machine replacement, augmentation, and modernization Identifying best product mix Tactical information Identifying and controlling areas of high costs Identifying critical bottlenecks in production Identifying alternate production schedules based on tools, machines, etc. Performace measures of machines to decide replacement Operational information Monitoring up to date production information by examining assemblies, detectinglikely shortages and giving early warning. Scheduling better production dynamically Preventive maintenance schedules Monitoring tool, machine and personnel availability Marketing management Strategic information Search new markets and marketing strategies Analysis of competitors strategy Technology and demographic forecasts and product changes Tactical information Advertising techniques and analysis of their impact Customer preference surveys Correlation of prices and sales Sales force deployment and targets Exploring alternate marketing channels Timing of special sales campaigns Operational information Sales analysis by regions, customer class, sales person Sales target versus achievement Market share and trends Seasonal variations Effect of model changes Performance of sales outlets Costs of campaigns and benefit Material management Strategic information Developing vendors for critical items Determining optimal levels of inventory Determining porportion of material needed Reducing varieties of inventory Tactical information Developing vendor performance measures Determining optimal reorder levels Determining issues of items to shops versus standard needs Controlling high value of inventory Determining impact on material cost and procurement with design changes and newproduct information Operational information List of excess and deficient items received List of items rejected Critical items received Stores in transit and in inspection Value of inventory in hand Goods received, rejected and issued Finance management Strategic information Methods of financing Pricing policies Tax planning Tactical information Variation between buidget and expenses Large outstanding payments/receipts Credit and payment status Operational information Periodic financial report Budget status to all functional managers Tax returns Share transfers Profit and loss account Payments and receipts Payroll, provident fund accounts Human resource management Strategic information Long range human resource requirements at different levels Policies on human resource development and training Policies on personnel welfare and facilities Tactical information Performace appraisal Demographic make-up of personnel and its impact on retirement Production incentives Morale of personnel Absentee reduction Leave and overtime policies Personnel deployment policies Operational information Routine assessment Skills inventory Loan/advances and recoveries Leave record Research design and development management Strategic information Which products are to be developed? What types of improvements are required? What long range research is more promising? What technical collaboration would be appropriate? Tactical information Setting intermediate goals Checking availability of equipment and appropriate selection Determining proportions of resources to be allocated to different projects Deployment of personnel to projects Information on similar and related research projects undertaken by other companies Operational information Progress against goals Budgeted expenses versus actual expenses Status of outstanding orders for equipment and components","title":"Data and information"},{"location":"office/office/","text":"Office courses This documentation contains the links to Nptel course. List of Office courses: Cloud Platform Professional Services Beginner Go to Cloud Platform GTS 2020 Cloud Strategy Processes and Operations in SG Cloud Platform Intermediate Cloud Platform Delivery Deep Dive into Service Catalog DoItNow Services Cloud Platform Use Cloud Native Architecture Introduction to Cloud Architecture Core Services Discovery Block Storage Service Certificate Service Cloud Orchestration Service Cloud Platform Compute Service File Storage Service IAM Service IPAM-DNS Service OS Factory Service OS Configuration Service Object Storage Service Security Group Service Advanced Data Persistence in Cloud Platform Cloud Native Architecture Patterns My Learning Basics of Level 1 Permanent Control Sustainable IT Awareness Protection Against Corruption Protection of Personal Data Prevention of Sexual Harassment CSR: History, Standards and Opportunities","title":"Office contents"},{"location":"office/office/#office-courses","text":"This documentation contains the links to Nptel course.","title":"Office courses"},{"location":"office/office/#list-of-office-courses","text":"Cloud Platform Professional Services Beginner Go to Cloud Platform GTS 2020 Cloud Strategy Processes and Operations in SG Cloud Platform Intermediate Cloud Platform Delivery Deep Dive into Service Catalog DoItNow Services Cloud Platform Use Cloud Native Architecture Introduction to Cloud Architecture Core Services Discovery Block Storage Service Certificate Service Cloud Orchestration Service Cloud Platform Compute Service File Storage Service IAM Service IPAM-DNS Service OS Factory Service OS Configuration Service Object Storage Service Security Group Service Advanced Data Persistence in Cloud Platform Cloud Native Architecture Patterns My Learning Basics of Level 1 Permanent Control Sustainable IT Awareness Protection Against Corruption Protection of Personal Data Prevention of Sexual Harassment CSR: History, Standards and Opportunities","title":"List of Office courses:"},{"location":"office/cloudPlatformProfessionalServices/advanced/dataPersistenceInCloudPlatform/cloudNativeArchitecturesPatterns/","text":"Cloud Native Architecture Patterns Cloud native application definition Reminder of the promises of the Cloud The benefits of the Cloud are organized around 4 main themes Elasticity The Cloud allows infrastructure resources to be automatically adapted to actual needs (eg. increasing processing capacity for end-of-month regulatory reporting). The capabilities of a Cloud seen for an application are 'almost infinite' Agility The Cloud makes it possible to reduce time-to-market through the ability to create or stop technical environments to run applications in minutes Innovation The richness of Cloud providers' catalogs, especially in terms of data science. Artificial intelligence and low-cost pre-packaged sandboxes, allows to accelerate the development of new use cases Cost on demand The Cloud makes it possible to pay only for what is actually used, to adapt infrastructure to real-time needs, to avoid heavy new investments (in particular to absorb load peaks over a short period of time or for deployment of international use cases) To advantage of these benefits your application must be Cloud native Definition of a Cloud Native application A Cloud native application is a distributed, elastic and scalable system Cloud native applications are a composition of various services (applications core, storage, network, authentication, monitoring, orchestration, etc.). These services integrate small components carrying a single process (microservice) - autonomous, stateless and weakly coupled - designed to be scalable. Perennial data is isolated in a so-called persistence zone The microservice communicate with each other being agnostic of the languages used One of the main objectives of a Cloud native application is to use its underlying resources as economically as possible The deployment of a Cloud native application is automated, at each stage and performs technical and functional tests before going into production (CI / CD pipeline) It is of course possible to run an application in the Cloud that does not meet all these criteria. In this case, it would be described as a 'Cloud Hosted' or 'Cloud Ready' application instead of Cloud native and then, would not be able to obtain all the benefits of the Cloud Cloud native application Key characteristics of a Cloud native application (CNA) Infrastructure independent Service-oriented architecture (SOA) Cost and resource consumption aware Location independent Elastically scalable Bandwidth aware Resilient to failure Designed for manageability Secure In order to get the key characteristics of a CNA, the following principles have to be applied API programming Micro-services-oriented architecture (a service should do one thing well) Stateless services Cloud native architecture design pattern 12-Factor application Infrastructure as code API programming and microservices A Cloud Native application exposes the API of each of its services. Calling a given service API triggers asynchronous communications between its microservices which perform tasks Monolithic application Modules based application Services based application Microservices Microservices oriented architecture is Evolving Deployment of functionalities without downtime via CI / CD and versioning management Interoperability of different technologies or development languages in teh same application Modular Each functionality is autonomous, independent, resilient, scalable and elastic Agile Application lifecycle by functionality Lightweight communications mechanisms in asynchronous mode (API) To build an application based on microservices As a input, a stable interface contract must be published. This allows to be autonomous and independent to develop and bring evolutions The output formats must be published so that the next function can evolve in total autonomy There cant be processing without output Component type : stateful vs stateless Stateful A stateful component stores certain data that will be required for further processing For a stateful application, the persistence area is stored locally Stateless A stateless component does not store any data that needs to be kept longer than the transaction time The processing of a transaction will follow the following scenario Identification of information issued by the customer Retrieving additional information in an area external to the component, the 'persistence area' Performing processing Provision of the result for further processing Context cleaning (especially for data confidentiality) Stateful Advantages As the data is stored locally, processing is often faster what with a Stateless architecture Disadvantages In case of interruption of a session, you must have implemented audit trails of fines in order to be able to carry out a recovery (this point is linked to the context at the time of the interruption which is probably different from the initial context) If the component is lost, the data is lost. Often complex mechanisms must therefore be implemented to overcome this If the component is duplicated to bring power, it will be necessary to implement data sharing solutions to ensure consistency Stateless Advantages Each transaction is independent, it has no link with the previous or next transaction. This allows the implementation of the 'elasticity' of these components without any prior modification Disadvantages The treatments are often slightly longer than with a stateful architecture because there can be consultation of external information The 12 Factor Application The origin of the 12-Factor App concept In today's era, software is regularly delivered as a service : the terms web applications (software apps) or software as a service are often used The 12-Factor App is a methodology for designing software as a service that Take advantage of automation to reduce the time and cost of implementing any new service Provide maximum portability between runtime environments Are decoupled from infrastructure to reduce administration tasks for the underlying systems and improve fault tolerance Minimize the gap between development and production, allowing continuous deployment for maximum agility And can grow (scalability) without significant change in tools, architecture, or development practices The 12-Factor application methodology can be applied to applications written in any programming language, and which use any type of external service (database, message, authentication, etc.) What are the 12 factors Codebase : One codebase tracked in revision control, many deploys A version control system A code repository Code base isolation per application Invoicing of 'reusable' code transversally in another code base Dependencies : Explicitly declare and isolate dependencies Explicitly declare and isolate Dependencies No implicit dependency All code useful to the application (no exceptions) must be contained in the deployment package Config : Store config in the environment Separate the code from the configuration Backing services : Treat backing services as attached resources Treat backing services as attached resources Build, release, run : Strictly separate build and run stages Strictly separate build and run stages Processes : Execute the app as one or more stateless processes Run the application as one or more stateless process Each process must be autonomous A process stores its data in a persistent service between each operation Information exchanges between processes are carried out using persistent services Port binding : Export service via port binding Concurrency : Scale out via the process model Disposability : Maximize robustness with fast startup and graceful shutdown Dev / prod parity : Keep development, staging and production as similar as possible Logs : Treat logs as event streams Admin processes : Run admin / management tasks as one-off processes","title":"Cloud Native Architecture Patterns"},{"location":"office/cloudPlatformProfessionalServices/advanced/dataPersistenceInCloudPlatform/cloudNativeArchitecturesPatterns/#cloud-native-architecture-patterns","text":"","title":"Cloud Native Architecture Patterns"},{"location":"office/cloudPlatformProfessionalServices/advanced/dataPersistenceInCloudPlatform/cloudNativeArchitecturesPatterns/#cloud-native-application-definition","text":"Reminder of the promises of the Cloud The benefits of the Cloud are organized around 4 main themes Elasticity The Cloud allows infrastructure resources to be automatically adapted to actual needs (eg. increasing processing capacity for end-of-month regulatory reporting). The capabilities of a Cloud seen for an application are 'almost infinite' Agility The Cloud makes it possible to reduce time-to-market through the ability to create or stop technical environments to run applications in minutes Innovation The richness of Cloud providers' catalogs, especially in terms of data science. Artificial intelligence and low-cost pre-packaged sandboxes, allows to accelerate the development of new use cases Cost on demand The Cloud makes it possible to pay only for what is actually used, to adapt infrastructure to real-time needs, to avoid heavy new investments (in particular to absorb load peaks over a short period of time or for deployment of international use cases) To advantage of these benefits your application must be Cloud native Definition of a Cloud Native application A Cloud native application is a distributed, elastic and scalable system Cloud native applications are a composition of various services (applications core, storage, network, authentication, monitoring, orchestration, etc.). These services integrate small components carrying a single process (microservice) - autonomous, stateless and weakly coupled - designed to be scalable. Perennial data is isolated in a so-called persistence zone The microservice communicate with each other being agnostic of the languages used One of the main objectives of a Cloud native application is to use its underlying resources as economically as possible The deployment of a Cloud native application is automated, at each stage and performs technical and functional tests before going into production (CI / CD pipeline) It is of course possible to run an application in the Cloud that does not meet all these criteria. In this case, it would be described as a 'Cloud Hosted' or 'Cloud Ready' application instead of Cloud native and then, would not be able to obtain all the benefits of the Cloud Cloud native application Key characteristics of a Cloud native application (CNA) Infrastructure independent Service-oriented architecture (SOA) Cost and resource consumption aware Location independent Elastically scalable Bandwidth aware Resilient to failure Designed for manageability Secure In order to get the key characteristics of a CNA, the following principles have to be applied API programming Micro-services-oriented architecture (a service should do one thing well) Stateless services Cloud native architecture design pattern 12-Factor application Infrastructure as code","title":"Cloud native application definition"},{"location":"office/cloudPlatformProfessionalServices/advanced/dataPersistenceInCloudPlatform/cloudNativeArchitecturesPatterns/#api-programming-and-microservices","text":"A Cloud Native application exposes the API of each of its services. Calling a given service API triggers asynchronous communications between its microservices which perform tasks Monolithic application Modules based application Services based application Microservices Microservices oriented architecture is Evolving Deployment of functionalities without downtime via CI / CD and versioning management Interoperability of different technologies or development languages in teh same application Modular Each functionality is autonomous, independent, resilient, scalable and elastic Agile Application lifecycle by functionality Lightweight communications mechanisms in asynchronous mode (API) To build an application based on microservices As a input, a stable interface contract must be published. This allows to be autonomous and independent to develop and bring evolutions The output formats must be published so that the next function can evolve in total autonomy There cant be processing without output Component type : stateful vs stateless Stateful A stateful component stores certain data that will be required for further processing For a stateful application, the persistence area is stored locally Stateless A stateless component does not store any data that needs to be kept longer than the transaction time The processing of a transaction will follow the following scenario Identification of information issued by the customer Retrieving additional information in an area external to the component, the 'persistence area' Performing processing Provision of the result for further processing Context cleaning (especially for data confidentiality) Stateful Advantages As the data is stored locally, processing is often faster what with a Stateless architecture Disadvantages In case of interruption of a session, you must have implemented audit trails of fines in order to be able to carry out a recovery (this point is linked to the context at the time of the interruption which is probably different from the initial context) If the component is lost, the data is lost. Often complex mechanisms must therefore be implemented to overcome this If the component is duplicated to bring power, it will be necessary to implement data sharing solutions to ensure consistency Stateless Advantages Each transaction is independent, it has no link with the previous or next transaction. This allows the implementation of the 'elasticity' of these components without any prior modification Disadvantages The treatments are often slightly longer than with a stateful architecture because there can be consultation of external information","title":"API programming and microservices"},{"location":"office/cloudPlatformProfessionalServices/advanced/dataPersistenceInCloudPlatform/cloudNativeArchitecturesPatterns/#the-12-factor-application","text":"The origin of the 12-Factor App concept In today's era, software is regularly delivered as a service : the terms web applications (software apps) or software as a service are often used The 12-Factor App is a methodology for designing software as a service that Take advantage of automation to reduce the time and cost of implementing any new service Provide maximum portability between runtime environments Are decoupled from infrastructure to reduce administration tasks for the underlying systems and improve fault tolerance Minimize the gap between development and production, allowing continuous deployment for maximum agility And can grow (scalability) without significant change in tools, architecture, or development practices The 12-Factor application methodology can be applied to applications written in any programming language, and which use any type of external service (database, message, authentication, etc.) What are the 12 factors Codebase : One codebase tracked in revision control, many deploys A version control system A code repository Code base isolation per application Invoicing of 'reusable' code transversally in another code base Dependencies : Explicitly declare and isolate dependencies Explicitly declare and isolate Dependencies No implicit dependency All code useful to the application (no exceptions) must be contained in the deployment package Config : Store config in the environment Separate the code from the configuration Backing services : Treat backing services as attached resources Treat backing services as attached resources Build, release, run : Strictly separate build and run stages Strictly separate build and run stages Processes : Execute the app as one or more stateless processes Run the application as one or more stateless process Each process must be autonomous A process stores its data in a persistent service between each operation Information exchanges between processes are carried out using persistent services Port binding : Export service via port binding Concurrency : Scale out via the process model Disposability : Maximize robustness with fast startup and graceful shutdown Dev / prod parity : Keep development, staging and production as similar as possible Logs : Treat logs as event streams Admin processes : Run admin / management tasks as one-off processes","title":"The 12 Factor Application"},{"location":"office/cloudPlatformProfessionalServices/beginner/goToCloudPlatform/","text":"Go to Cloud Platform Business Drivers for a NextGen Cloud Platform Cloud Platform is a pillar of GTS 2020 transformation plan to Cut GTS running costs (around 100 million euros) Enable the bank digital transformation and Cloud journey Improve GTS reactivity, agility, Time-to-Market and alignment with business value Improve and sustain production quality Prepare the revolution of GTS line of work, missions, and shift towards a multi-Cloud service provider And business lines expect relevant benefits from Cloud platform Enable Bank-as-a-Platform model Embrace API economy and Open-Banking(DSP2) Provide capabilities for new banking business models : Bank-as-a-Service, Mobile Banking,etc. Take advantage of best-of-breed cloud services and global coverage Improve business efficiency , scalability, security and innovation Improve TTM, reduce TCO, adopt self-service and increase operational efficiency Answer in an elastic manner to any change in business demands Produce new services with built-in and scalable security Innovate, experiment and deliver value more quickly than competitors Optimize IT costs Core concepts The shift to multi-everything Multi-Cloud Where we are running Massive transition taking place from traditional on-premises data centres into a mix of public and next generation private clouds Multi-Platform Where we are running From physical and virtual machines to containers, serverless capabilities, functions, or higher-level APIs provided on-demand Multi-Architectures Type and style of application architectures From monolithic to microservices and service-oriented architectures What is next generation Provate Cloud It provided Multi-Platform capabilities and allows Multi-Architectures hostings Client-agnostic consumption model : API-first In line with Cloud Service Providers and market standards Suited for Cloud Native Applications and DevSecOps practices Unique and standard service catalog Pay-per-use billing model Relies on Foundation services: Identity and Access Management Metrology Monitoring Alerting Secret Certificate Showback Is deployed in several regions and availability zones What about AWS public cloud? AWS created the cloud IaaS market with the 2006 introduction of its Elastic Compute Cloud(EC2) 69 availability zones within 22 geographical regions Offers the richest suite of public cloud IaaS capabilities, along with deep and broad PaaS-layer capabilities Addresses both ends of the spectrum spanning traditional and cloud-native applications Solid feature set, platform resiliency and maturity Meets most requirements for security and regulatory compliance What about Azure public cloud? Azure was initially a PaaS launched in 2010. IaaS VMs(Azure Virtual Machines) were launched in June 2012 and became generally available in April 2013 54 geographical regions Combines a rich suite of IaaS and PaaS capabilities within an integrated solution portfolio Customers are likely to consider Azure for use cases where the application is Windows-based, written in .NET, developed by a team using Microsoft developer tools like Visual Studio or dependent on Microsoft middleware Microsoft is also increasingly targeting applications that run on Linux and now includes broad support for popular open-source applications Cloud Platform is a Multi-Cloud Platform GTS intends to manage Multiple Clouds with the right level of Hybridization Multiple Clouds Next Gen Private Cloud + AWS + Azure Native public clouds API documentation Public clouds governance and security Workflow portability through infrastructure as code approach Application portability through cross-cloud container orchestration Hybrid services Showback Hybrid Connectivity Service Meshing Hybrid Integration Orchestration How to consume services? Dev, Sec, Fin, Ops Toolchains and Teams 3 ways to interact with the platform Through API CLI DoItNow The platform is a collection of unitary infrastructure services(called XaaS) autonomously developed and maintained by a service producer(Component team) A resource is any infrastructure element that supports a business application (e.g. a VM, database, VIP, DNS record, certificate,...) Cloud platform services are made for cloud native applications API-first design Regions and availability zones(AZ) Global (inter Regions/AZ) and local(AZ) traffic loan balancing OpenStack Compute Orchestrated containers for microservices Messaging and datalakes solutions About delivery organisation and governance GTS teams deliver highest business value in short program increments Principles Alignement Built-in quality Transparency Program execution Strategic themes Adoption and onboarding Production-grade and security Unrivalled customer experience Cloud-Native and Multi-Cloud foundations Finally, you application in cloud platform is Provisioned and maintained through a console or a fully automated CI/CD pipeline Composed of a bunch of Cloud services (Cloud Platform services and native CSP) executed within a Private Cloud, public or hybrid Cloud deployment model Optimized for Cloud Containerized Resilient (AZ or Region loss) Self-monitored Supported by GTS DEVOPS feature-teams and OPM Control Tower Charged on a Pay-per-Use model Service catalog How is organized Cloud Platform service catalog? Service management Proviosion and manage your cloud services through portals, Command Line Interfaces, or direct API calls, get a consistent view on all deployed assets, get visibility on service billing and obtain assistance Operations Monitor your cloud services, be alerted in case of specific events, get all logs and metrics, obtain deep dive analytics (KYC, health,...) througn observability Security Access in a secure manner to you cloud services, manage your certificates and your secrets Infrastructure Services Consume private compute, storage, data protection and network cloud services Platform services Consume private database, messaging, application and analytics cloud services Public cloud Obtain secured training, innovation or production environments for all your public cloud use cases and enjoy CSP service catalogs Hybrid services Build an hybrid application between private and public clouds and guarantee end-to-end security Marketplace Consume value-added services - managed services, automation services - on top of Cloud Platform","title":"Go to Cloud Platform"},{"location":"office/cloudPlatformProfessionalServices/beginner/goToCloudPlatform/#go-to-cloud-platform","text":"","title":"Go to Cloud Platform"},{"location":"office/cloudPlatformProfessionalServices/beginner/goToCloudPlatform/#business-drivers-for-a-nextgen-cloud-platform","text":"Cloud Platform is a pillar of GTS 2020 transformation plan to Cut GTS running costs (around 100 million euros) Enable the bank digital transformation and Cloud journey Improve GTS reactivity, agility, Time-to-Market and alignment with business value Improve and sustain production quality Prepare the revolution of GTS line of work, missions, and shift towards a multi-Cloud service provider And business lines expect relevant benefits from Cloud platform Enable Bank-as-a-Platform model Embrace API economy and Open-Banking(DSP2) Provide capabilities for new banking business models : Bank-as-a-Service, Mobile Banking,etc. Take advantage of best-of-breed cloud services and global coverage Improve business efficiency , scalability, security and innovation Improve TTM, reduce TCO, adopt self-service and increase operational efficiency Answer in an elastic manner to any change in business demands Produce new services with built-in and scalable security Innovate, experiment and deliver value more quickly than competitors Optimize IT costs","title":"Business Drivers for a NextGen Cloud Platform"},{"location":"office/cloudPlatformProfessionalServices/beginner/goToCloudPlatform/#core-concepts","text":"The shift to multi-everything Multi-Cloud Where we are running Massive transition taking place from traditional on-premises data centres into a mix of public and next generation private clouds Multi-Platform Where we are running From physical and virtual machines to containers, serverless capabilities, functions, or higher-level APIs provided on-demand Multi-Architectures Type and style of application architectures From monolithic to microservices and service-oriented architectures What is next generation Provate Cloud It provided Multi-Platform capabilities and allows Multi-Architectures hostings Client-agnostic consumption model : API-first In line with Cloud Service Providers and market standards Suited for Cloud Native Applications and DevSecOps practices Unique and standard service catalog Pay-per-use billing model Relies on Foundation services: Identity and Access Management Metrology Monitoring Alerting Secret Certificate Showback Is deployed in several regions and availability zones What about AWS public cloud? AWS created the cloud IaaS market with the 2006 introduction of its Elastic Compute Cloud(EC2) 69 availability zones within 22 geographical regions Offers the richest suite of public cloud IaaS capabilities, along with deep and broad PaaS-layer capabilities Addresses both ends of the spectrum spanning traditional and cloud-native applications Solid feature set, platform resiliency and maturity Meets most requirements for security and regulatory compliance What about Azure public cloud? Azure was initially a PaaS launched in 2010. IaaS VMs(Azure Virtual Machines) were launched in June 2012 and became generally available in April 2013 54 geographical regions Combines a rich suite of IaaS and PaaS capabilities within an integrated solution portfolio Customers are likely to consider Azure for use cases where the application is Windows-based, written in .NET, developed by a team using Microsoft developer tools like Visual Studio or dependent on Microsoft middleware Microsoft is also increasingly targeting applications that run on Linux and now includes broad support for popular open-source applications Cloud Platform is a Multi-Cloud Platform GTS intends to manage Multiple Clouds with the right level of Hybridization Multiple Clouds Next Gen Private Cloud + AWS + Azure Native public clouds API documentation Public clouds governance and security Workflow portability through infrastructure as code approach Application portability through cross-cloud container orchestration Hybrid services Showback Hybrid Connectivity Service Meshing Hybrid Integration Orchestration How to consume services? Dev, Sec, Fin, Ops Toolchains and Teams 3 ways to interact with the platform Through API CLI DoItNow The platform is a collection of unitary infrastructure services(called XaaS) autonomously developed and maintained by a service producer(Component team) A resource is any infrastructure element that supports a business application (e.g. a VM, database, VIP, DNS record, certificate,...) Cloud platform services are made for cloud native applications API-first design Regions and availability zones(AZ) Global (inter Regions/AZ) and local(AZ) traffic loan balancing OpenStack Compute Orchestrated containers for microservices Messaging and datalakes solutions About delivery organisation and governance GTS teams deliver highest business value in short program increments Principles Alignement Built-in quality Transparency Program execution Strategic themes Adoption and onboarding Production-grade and security Unrivalled customer experience Cloud-Native and Multi-Cloud foundations Finally, you application in cloud platform is Provisioned and maintained through a console or a fully automated CI/CD pipeline Composed of a bunch of Cloud services (Cloud Platform services and native CSP) executed within a Private Cloud, public or hybrid Cloud deployment model Optimized for Cloud Containerized Resilient (AZ or Region loss) Self-monitored Supported by GTS DEVOPS feature-teams and OPM Control Tower Charged on a Pay-per-Use model","title":"Core concepts"},{"location":"office/cloudPlatformProfessionalServices/beginner/goToCloudPlatform/#service-catalog","text":"How is organized Cloud Platform service catalog? Service management Proviosion and manage your cloud services through portals, Command Line Interfaces, or direct API calls, get a consistent view on all deployed assets, get visibility on service billing and obtain assistance Operations Monitor your cloud services, be alerted in case of specific events, get all logs and metrics, obtain deep dive analytics (KYC, health,...) througn observability Security Access in a secure manner to you cloud services, manage your certificates and your secrets Infrastructure Services Consume private compute, storage, data protection and network cloud services Platform services Consume private database, messaging, application and analytics cloud services Public cloud Obtain secured training, innovation or production environments for all your public cloud use cases and enjoy CSP service catalogs Hybrid services Build an hybrid application between private and public clouds and guarantee end-to-end security Marketplace Consume value-added services - managed services, automation services - on top of Cloud Platform","title":"Service catalog"},{"location":"office/cloudPlatformProfessionalServices/beginner/gts2020CloudStrategy/","text":"GTS 2020 Cloud Strategy Business Drivers for a NextGen Cloud Platform Cloud Platform is a pillar of GTS 2020 transformation plan to Cut GTS running costs (around 100 million euros) Enable the bank digital transformation and Cloud journey Improve GTS reactivity, agility, Time-to-Market and alignment with business value Improve and sustain production quality Prepare the revolution of GTS line of work, missions, and shift towards a multi-Cloud service provider And business lines expect relevant benefits from Cloud platform Enable Bank-as-a-Platform model Embrace API economy and Open-Banking(DSP2) Provide capabilities for new banking business models : Bank-as-a-Service, Mobile Banking,etc. Take advantage of best-of-breed cloud services and global coverage Improve business efficiency , scalability, security and innovation Improve TTM, reduce TCO, adopt self-service and increase operational efficiency Answer in an elastic manner to any change in business demands Produce new services with built-in and scalable security Innovate, experiment and deliver value more quickly than competitors Optimize IT costs Core concepts The shift to multi-everything Multi-Cloud Where we are running Massive transition taking place from traditional on-premises data centres into a mix of public and next generation private clouds Multi-Platform Where we are running From physical and virtual machines to containers, serverless capabilities, functions, or higher-level APIs provided on-demand Multi-Architectures Type and style of application architectures From monolithic to microservices and service-oriented architectures What is next generation Provate Cloud It provided Multi-Platform capabilities and allows Multi-Architectures hostings Client-agnostic consumption model : API-first In line with Cloud Service Providers and market standards Suited for Cloud Native Applications and DevSecOps practices Unique and standard service catalog Pay-per-use billing model Relies on Foundation services: Identity and Access Management Metrology Monitoring Alerting Secret Certificate Showback Is deployed in several regions and availability zones What about AWS public cloud? AWS created the cloud IaaS market with the 2006 introduction of its Elastic Compute Cloud(EC2) 69 availability zones within 22 geographical regions Offers the richest suite of public cloud IaaS capabilities, along with deep and broad PaaS-layer capabilities Addresses both ends of the spectrum spanning traditional and cloud-native applications Solid feature set, platform resiliency and maturity Meets most requirements for security and regulatory compliance What about Azure public cloud? Azure was initially a PaaS launched in 2010. IaaS VMs(Azure Virtual Machines) were launched in June 2012 and became generally available in April 2013 54 geographical regions Combines a rich suite of IaaS and PaaS capabilities within an integrated solution portfolio Customers are likely to consider Azure for use cases where the application is Windows-based, written in .NET, developed by a team using Microsoft developer tools like Visual Studio or dependent on Microsoft middleware Microsoft is also increasingly targeting applications that run on Linux and now includes broad support for popular open-source applications Cloud Platform is a Multi-Cloud Platform GTS intends to manage Multiple Clouds with the right level of Hybridization Multiple Clouds Next Gen Private Cloud + AWS + Azure Native public clouds API documentation Public clouds governance and security Workflow portability through infrastructure as code approach Application portability through cross-cloud container orchestration Hybrid services Showback Hybrid Connectivity Service Meshing Hybrid Integration Orchestration How to consume services? Dev, Sec, Fin, Ops Toolchains and Teams 3 ways to interact with the platform Through API CLI DoItNow The platform is a collection of unitary infrastructure services(called XaaS) autonomously developed and maintained by a service producer(Component team) A resource is any infrastructure element that supports a business application (e.g. a VM, database, VIP, DNS record, certificate,...) Cloud platform services are made for cloud native applications API-first design Regions and availability zones(AZ) Global (inter Regions/AZ) and local(AZ) traffic loan balancing OpenStack Compute Orchestrated containers for microservices Messaging and datalakes solutions About delivery organisation and governance GTS teams deliver highest business value in short program increments Principles Alignement Built-in quality Transparency Program execution Strategic themes Adoption and onboarding Production-grade and security Unrivalled customer experience Cloud-Native and Multi-Cloud foundations Finally, you application in cloud platform is Provisioned and maintained through a console or a fully automated CI/CD pipeline Composed of a bunch of Cloud services (Cloud Platform services and native CSP) executed within a Private Cloud, public or hybrid Cloud deployment model Optimized for Cloud Containerized Resilient (AZ or Region loss) Self-monitored Supported by GTS DEVOPS feature-teams and OPM Control Tower Charged on a Pay-per-Use model Service catalog How is organized Cloud Platform service catalog? Service management Proviosion and manage your cloud services through portals, Command Line Interfaces, or direct API calls, get a consistent view on all deployed assets, get visibility on service billing and obtain assistance Operations Monitor your cloud services, be alerted in case of specific events, get all logs and metrics, obtain deep dive analytics (KYC, health,...) througn observability Security Access in a secure manner to you cloud services, manage your certificates and your secrets Infrastructure Services Consume private compute, storage, data protection and network cloud services Platform services Consume private database, messaging, application and analytics cloud services Public cloud Obtain secured training, innovation or production environments for all your public cloud use cases and enjoy CSP service catalogs Hybrid services Build an hybrid application between private and public clouds and guarantee end-to-end security Marketplace Consume value-added services - managed services, automation services - on top of Cloud Platform","title":"GTS 2020 Cloud Strategy"},{"location":"office/cloudPlatformProfessionalServices/beginner/gts2020CloudStrategy/#gts-2020-cloud-strategy","text":"","title":"GTS 2020 Cloud Strategy"},{"location":"office/cloudPlatformProfessionalServices/beginner/gts2020CloudStrategy/#business-drivers-for-a-nextgen-cloud-platform","text":"Cloud Platform is a pillar of GTS 2020 transformation plan to Cut GTS running costs (around 100 million euros) Enable the bank digital transformation and Cloud journey Improve GTS reactivity, agility, Time-to-Market and alignment with business value Improve and sustain production quality Prepare the revolution of GTS line of work, missions, and shift towards a multi-Cloud service provider And business lines expect relevant benefits from Cloud platform Enable Bank-as-a-Platform model Embrace API economy and Open-Banking(DSP2) Provide capabilities for new banking business models : Bank-as-a-Service, Mobile Banking,etc. Take advantage of best-of-breed cloud services and global coverage Improve business efficiency , scalability, security and innovation Improve TTM, reduce TCO, adopt self-service and increase operational efficiency Answer in an elastic manner to any change in business demands Produce new services with built-in and scalable security Innovate, experiment and deliver value more quickly than competitors Optimize IT costs","title":"Business Drivers for a NextGen Cloud Platform"},{"location":"office/cloudPlatformProfessionalServices/beginner/gts2020CloudStrategy/#core-concepts","text":"The shift to multi-everything Multi-Cloud Where we are running Massive transition taking place from traditional on-premises data centres into a mix of public and next generation private clouds Multi-Platform Where we are running From physical and virtual machines to containers, serverless capabilities, functions, or higher-level APIs provided on-demand Multi-Architectures Type and style of application architectures From monolithic to microservices and service-oriented architectures What is next generation Provate Cloud It provided Multi-Platform capabilities and allows Multi-Architectures hostings Client-agnostic consumption model : API-first In line with Cloud Service Providers and market standards Suited for Cloud Native Applications and DevSecOps practices Unique and standard service catalog Pay-per-use billing model Relies on Foundation services: Identity and Access Management Metrology Monitoring Alerting Secret Certificate Showback Is deployed in several regions and availability zones What about AWS public cloud? AWS created the cloud IaaS market with the 2006 introduction of its Elastic Compute Cloud(EC2) 69 availability zones within 22 geographical regions Offers the richest suite of public cloud IaaS capabilities, along with deep and broad PaaS-layer capabilities Addresses both ends of the spectrum spanning traditional and cloud-native applications Solid feature set, platform resiliency and maturity Meets most requirements for security and regulatory compliance What about Azure public cloud? Azure was initially a PaaS launched in 2010. IaaS VMs(Azure Virtual Machines) were launched in June 2012 and became generally available in April 2013 54 geographical regions Combines a rich suite of IaaS and PaaS capabilities within an integrated solution portfolio Customers are likely to consider Azure for use cases where the application is Windows-based, written in .NET, developed by a team using Microsoft developer tools like Visual Studio or dependent on Microsoft middleware Microsoft is also increasingly targeting applications that run on Linux and now includes broad support for popular open-source applications Cloud Platform is a Multi-Cloud Platform GTS intends to manage Multiple Clouds with the right level of Hybridization Multiple Clouds Next Gen Private Cloud + AWS + Azure Native public clouds API documentation Public clouds governance and security Workflow portability through infrastructure as code approach Application portability through cross-cloud container orchestration Hybrid services Showback Hybrid Connectivity Service Meshing Hybrid Integration Orchestration How to consume services? Dev, Sec, Fin, Ops Toolchains and Teams 3 ways to interact with the platform Through API CLI DoItNow The platform is a collection of unitary infrastructure services(called XaaS) autonomously developed and maintained by a service producer(Component team) A resource is any infrastructure element that supports a business application (e.g. a VM, database, VIP, DNS record, certificate,...) Cloud platform services are made for cloud native applications API-first design Regions and availability zones(AZ) Global (inter Regions/AZ) and local(AZ) traffic loan balancing OpenStack Compute Orchestrated containers for microservices Messaging and datalakes solutions About delivery organisation and governance GTS teams deliver highest business value in short program increments Principles Alignement Built-in quality Transparency Program execution Strategic themes Adoption and onboarding Production-grade and security Unrivalled customer experience Cloud-Native and Multi-Cloud foundations Finally, you application in cloud platform is Provisioned and maintained through a console or a fully automated CI/CD pipeline Composed of a bunch of Cloud services (Cloud Platform services and native CSP) executed within a Private Cloud, public or hybrid Cloud deployment model Optimized for Cloud Containerized Resilient (AZ or Region loss) Self-monitored Supported by GTS DEVOPS feature-teams and OPM Control Tower Charged on a Pay-per-Use model","title":"Core concepts"},{"location":"office/cloudPlatformProfessionalServices/beginner/gts2020CloudStrategy/#service-catalog","text":"How is organized Cloud Platform service catalog? Service management Proviosion and manage your cloud services through portals, Command Line Interfaces, or direct API calls, get a consistent view on all deployed assets, get visibility on service billing and obtain assistance Operations Monitor your cloud services, be alerted in case of specific events, get all logs and metrics, obtain deep dive analytics (KYC, health,...) througn observability Security Access in a secure manner to you cloud services, manage your certificates and your secrets Infrastructure Services Consume private compute, storage, data protection and network cloud services Platform services Consume private database, messaging, application and analytics cloud services Public cloud Obtain secured training, innovation or production environments for all your public cloud use cases and enjoy CSP service catalogs Hybrid services Build an hybrid application between private and public clouds and guarantee end-to-end security Marketplace Consume value-added services - managed services, automation services - on top of Cloud Platform","title":"Service catalog"},{"location":"office/cloudPlatformProfessionalServices/beginner/processesAndOperationsInSG/","text":"Processes and Operations in SG Cloud Platform OPM Control Towers Operations are managed by the OPM Control Towers. Changes, incidents and problems are mainly handled based on best practices OPM Control Towers activities Hot production management Steering 24/7 critical incidents resolution, coordination of the different stakeholders and global communication. Global management of production activities. Change management Steering and/or participating to change management communities (CABs, CREC, etc.), defining changes golden rules, managing their evolution on a continuous improvement cycle and ensuring their adoption and application by the technical teams Cold production management Steering post mortem redaction and carrying out their publication, managing problems portfolio and presenting production review committees Operation principles Incident management ITSM tickets are required for all declared incidents The incident ticket could be created through IMPULSE portal or JUMP and assigned to an IMPULSE group Change management Changes are divided into two categories based on their impact Simple changes Without impact on users and without service interruption Disruptive changes With impact on users and/or requires service interruption Disruptive changes could require CIOs implication on impact assessment and approval","title":"Processes and Operations in SG Cloud Platform"},{"location":"office/cloudPlatformProfessionalServices/beginner/processesAndOperationsInSG/#processes-and-operations-in-sg-cloud-platform","text":"","title":"Processes and Operations in SG Cloud Platform"},{"location":"office/cloudPlatformProfessionalServices/beginner/processesAndOperationsInSG/#opm-control-towers","text":"Operations are managed by the OPM Control Towers. Changes, incidents and problems are mainly handled based on best practices OPM Control Towers activities Hot production management Steering 24/7 critical incidents resolution, coordination of the different stakeholders and global communication. Global management of production activities. Change management Steering and/or participating to change management communities (CABs, CREC, etc.), defining changes golden rules, managing their evolution on a continuous improvement cycle and ensuring their adoption and application by the technical teams Cold production management Steering post mortem redaction and carrying out their publication, managing problems portfolio and presenting production review committees","title":"OPM Control Towers"},{"location":"office/cloudPlatformProfessionalServices/beginner/processesAndOperationsInSG/#operation-principles","text":"Incident management ITSM tickets are required for all declared incidents The incident ticket could be created through IMPULSE portal or JUMP and assigned to an IMPULSE group Change management Changes are divided into two categories based on their impact Simple changes Without impact on users and without service interruption Disruptive changes With impact on users and/or requires service interruption Disruptive changes could require CIOs implication on impact assessment and approval","title":"Operation principles"},{"location":"office/cloudPlatformProfessionalServices/intermediate/cloudPlatformDelivery/deepDiveIntoServiceCatalog/","text":"Deep Dive into Service Catalog Cloud Platform service catalog How is organized Cloud Platform service catalog? Service management Provision and manage your cloud services through portals, Command Line interfaces or direct API calls, get a view on all deployed assets, get visibility on service billing and obtain assistance Consume value-added services - managed services, automation services - built on top of Cloud Platform through the Marketplace Operations Monitor your cloud services, be alerted in case of specific events, get all logs and metrics, obtain deep drive analytics (KKYC, health,..) through observability Security Access in a secure manner to your cloud services, manage your certificates and your secrets IaaS Services Consume private compute, storage and network cloud services PaaS Services Consume private database, messaging, application and analytics cloud services Public cloud Obtain secure training, innovation or production environments for all your public cloud use cases and enjoy CSP service catalogs Hybrid services Build an hybrid application between private and public clouds and guarantee end-to-end security Service management Provision and manage your cloud services through portals, Command Line interfaces or direct API calls, get a view on all deployed assets, get visibility on service billing and obtain assistance Consume value-added services - managed services, automation services - built on top of Cloud Platform through the Marketplace Provision and manage your cloud services through DoItNow console Service catalog : provision resources (compute instance, database,..) and realize operations on deployed resources Access to Inventory / Billing information Access to Logs / Metrics on deployed resources Manage Roles and Authorizations Operate cloud services through Command Line Interface Realize operations in your command-line shell Use autocompletion on operation and parameter names Learn how to use cloud services with online documentation Getting started guide Cloud services documentation Concepts, best practices and standards Provision and manage cloud services as code Define infrastructure as code to manage the full lifecycle Create new resources, manage existing ones,and destroy those no longer needed Create reproducible infrastructure Manage Cloud Platform accounts, folders and bundles Realize CRUD operations on Accounts, Folders and Bundles Obtain online assistance Chat with support Get access to online billing information and manage financial quotas Billing per month, per week, per day, per service, per AZ Financial quota management Showback analytics Build and promote value-added services on top of Cloud Platform Managed services Automations services Operations Monitor your cloud services, be alerted in case of specific events, get all logs and metrics, obtain deep drive analytics (KKYC, health,..) through observability Get full visibility on cloud services and applications logs and metrics API logs Cloud resources logs and metrics Application logs and metrics Monitor your cloud services and build event-driven applications Thresholds on resource metrics Rule-based alerting Event-driven applications Configure your alerting system Event templates and catalogs Notification medias (SWS, email, impulse and jump tickets) Get information on service overall quality and usage KYC : cloud services usage analytics Platform Health : cloud service availability and response time Blackbox : quality of experience through end to end tests cloud services Global inventory : inventory and history of consumed resources per Account Security Access in a secure manner to your cloud services, manage your certificates and your secrets Authenticate and get authorization to consume cloud services Based on oAuth2 standards User authorization through SAFE / RTFE Authrorizations provided through access Tokens Manage Unipass certificates List, create, renew server certificates Retrieve certificates authorities Manage and share your secrets CRUD secrets in a safe vault Share secrets Obtain a dedicated vault to manage your secrets and protect sensitive data Secrets engine Dynamic secrets Authentication methods Policies Secure administration of Cloud Platform resources Privileged account security IaaS services Consume private compute, storage and network cloud services Create and manage OpenStack compute resources Create and manage cloud server instances on demand, with an explicit list of flavor (VM, size), images (VM template) and artwork Build customized OS images for OCS virtual servers GTS converged images Image configuration (ansible or puppet) Create and manage VMware compute resources Create and manage cloud server instances on demand, with an explicit list of flavor (VM, size), images (VM template) and network Configure servers by using Puppet modules Puppet-factory for modules development Puppet assign modules Onboard on Docker/Kubernetes platform and manage your orchestrated container infrastructure Onboarding API Routing mesh API Docker/Kubernetes namespace and native Docker/K8S API consumption Create and manage s3 storage buckets Onboarding API to obtain an access key S3 buckets management with native API Replication management Create and manage persistent block storage volumes for OCS virtual servers Create/Delete volume Attach/Setach volume Extend volume size Manage snapshots/clones Create and manage file storage CRUD operations on File-system Access management Snapshot and replication features management Manage your traffic between AZ/Regions Active/Passive traffic management Active/Active traffic management Plan, track and manage IP addresses space Subnet management (CRUD operations) IP addresses management (CRUD operations and subnet relationship) Load balance your traffic in an AZ Load Balancer management (CRUD operations) Load Balancer Type : Network(L4), Application(L7) Manage domain names Define individual hosts within a domain and link them to network IP addresses Define aliases to already defined domain name hosts Apply security rules to your compute instances Security-groups / Security-rules management OCS and VCS virtual servers PaaS services Consume private database, messaging, application and analytics cloud services Create and manage PostGreSQL databases Create/delete clusters, instances and replica Automatic backup Switchover/ Failover management Database management: start / stop, create users,... Create and manage Oracle databases - DEV environments only - Historical Release DBPAAS Create / delete Oracle databases Retrieve information on available databases Export / import schemas Backup / restore management Database management: start / stop, patch,... Create and manage Oracle databases - all environments - New Release Oracle Cloud Platform Create / delete Oracle databases Retrieve information on available databases Export / Import schemas Backup/ restore management Database management : start / stop,... Create and manage RabbitMQ brokers Single (1-node broker) Master / slave (2-node cluster with queue mirroring) Create and manage Openshift projects Project / namespace management Openshift platform management Manage analytics and datalake services - New release LUCID Analytics and datalake infrastructure services Ingestion infrastructure services Restitution infrastructure services Create and manage Hadoop / HDF clusters Big data HDP / HDF clusters management Data Ingestion management Public and hybrid cloud Obtain secured training, innovation or production environments for all your public cloud use cases and enjoy CSP service catalogs Native CSP consoles to manage services in a Societe Generale Public \"Cloud Box\" Training, innovation or production public cloud environments Internet Access Management Shared infrastructure (DNS, SMTP,...), OS / OS patching Trust and control framework, IAM, logs Build a hybrid Application internal IS and public Cloud and guarantee end-to-end security Manage connectivity between internal IS and CSP Instantiate administrative services in a DMZ zone for the public Cloud Share hybrid connectivity and services to / from applications in the cloud Create and manage workflows that connect data, processing, and services across clouds","title":"Deep Dive into Service Catalog"},{"location":"office/cloudPlatformProfessionalServices/intermediate/cloudPlatformDelivery/deepDiveIntoServiceCatalog/#deep-dive-into-service-catalog","text":"","title":"Deep Dive into Service Catalog"},{"location":"office/cloudPlatformProfessionalServices/intermediate/cloudPlatformDelivery/deepDiveIntoServiceCatalog/#cloud-platform-service-catalog","text":"How is organized Cloud Platform service catalog? Service management Provision and manage your cloud services through portals, Command Line interfaces or direct API calls, get a view on all deployed assets, get visibility on service billing and obtain assistance Consume value-added services - managed services, automation services - built on top of Cloud Platform through the Marketplace Operations Monitor your cloud services, be alerted in case of specific events, get all logs and metrics, obtain deep drive analytics (KKYC, health,..) through observability Security Access in a secure manner to your cloud services, manage your certificates and your secrets IaaS Services Consume private compute, storage and network cloud services PaaS Services Consume private database, messaging, application and analytics cloud services Public cloud Obtain secure training, innovation or production environments for all your public cloud use cases and enjoy CSP service catalogs Hybrid services Build an hybrid application between private and public clouds and guarantee end-to-end security","title":"Cloud Platform service catalog"},{"location":"office/cloudPlatformProfessionalServices/intermediate/cloudPlatformDelivery/deepDiveIntoServiceCatalog/#service-management","text":"Provision and manage your cloud services through portals, Command Line interfaces or direct API calls, get a view on all deployed assets, get visibility on service billing and obtain assistance Consume value-added services - managed services, automation services - built on top of Cloud Platform through the Marketplace Provision and manage your cloud services through DoItNow console Service catalog : provision resources (compute instance, database,..) and realize operations on deployed resources Access to Inventory / Billing information Access to Logs / Metrics on deployed resources Manage Roles and Authorizations Operate cloud services through Command Line Interface Realize operations in your command-line shell Use autocompletion on operation and parameter names Learn how to use cloud services with online documentation Getting started guide Cloud services documentation Concepts, best practices and standards Provision and manage cloud services as code Define infrastructure as code to manage the full lifecycle Create new resources, manage existing ones,and destroy those no longer needed Create reproducible infrastructure Manage Cloud Platform accounts, folders and bundles Realize CRUD operations on Accounts, Folders and Bundles Obtain online assistance Chat with support Get access to online billing information and manage financial quotas Billing per month, per week, per day, per service, per AZ Financial quota management Showback analytics Build and promote value-added services on top of Cloud Platform Managed services Automations services","title":"Service management"},{"location":"office/cloudPlatformProfessionalServices/intermediate/cloudPlatformDelivery/deepDiveIntoServiceCatalog/#operations","text":"Monitor your cloud services, be alerted in case of specific events, get all logs and metrics, obtain deep drive analytics (KKYC, health,..) through observability Get full visibility on cloud services and applications logs and metrics API logs Cloud resources logs and metrics Application logs and metrics Monitor your cloud services and build event-driven applications Thresholds on resource metrics Rule-based alerting Event-driven applications Configure your alerting system Event templates and catalogs Notification medias (SWS, email, impulse and jump tickets) Get information on service overall quality and usage KYC : cloud services usage analytics Platform Health : cloud service availability and response time Blackbox : quality of experience through end to end tests cloud services Global inventory : inventory and history of consumed resources per Account","title":"Operations"},{"location":"office/cloudPlatformProfessionalServices/intermediate/cloudPlatformDelivery/deepDiveIntoServiceCatalog/#security","text":"Access in a secure manner to your cloud services, manage your certificates and your secrets Authenticate and get authorization to consume cloud services Based on oAuth2 standards User authorization through SAFE / RTFE Authrorizations provided through access Tokens Manage Unipass certificates List, create, renew server certificates Retrieve certificates authorities Manage and share your secrets CRUD secrets in a safe vault Share secrets Obtain a dedicated vault to manage your secrets and protect sensitive data Secrets engine Dynamic secrets Authentication methods Policies Secure administration of Cloud Platform resources Privileged account security","title":"Security"},{"location":"office/cloudPlatformProfessionalServices/intermediate/cloudPlatformDelivery/deepDiveIntoServiceCatalog/#iaas-services","text":"Consume private compute, storage and network cloud services Create and manage OpenStack compute resources Create and manage cloud server instances on demand, with an explicit list of flavor (VM, size), images (VM template) and artwork Build customized OS images for OCS virtual servers GTS converged images Image configuration (ansible or puppet) Create and manage VMware compute resources Create and manage cloud server instances on demand, with an explicit list of flavor (VM, size), images (VM template) and network Configure servers by using Puppet modules Puppet-factory for modules development Puppet assign modules Onboard on Docker/Kubernetes platform and manage your orchestrated container infrastructure Onboarding API Routing mesh API Docker/Kubernetes namespace and native Docker/K8S API consumption Create and manage s3 storage buckets Onboarding API to obtain an access key S3 buckets management with native API Replication management Create and manage persistent block storage volumes for OCS virtual servers Create/Delete volume Attach/Setach volume Extend volume size Manage snapshots/clones Create and manage file storage CRUD operations on File-system Access management Snapshot and replication features management Manage your traffic between AZ/Regions Active/Passive traffic management Active/Active traffic management Plan, track and manage IP addresses space Subnet management (CRUD operations) IP addresses management (CRUD operations and subnet relationship) Load balance your traffic in an AZ Load Balancer management (CRUD operations) Load Balancer Type : Network(L4), Application(L7) Manage domain names Define individual hosts within a domain and link them to network IP addresses Define aliases to already defined domain name hosts Apply security rules to your compute instances Security-groups / Security-rules management OCS and VCS virtual servers","title":"IaaS services"},{"location":"office/cloudPlatformProfessionalServices/intermediate/cloudPlatformDelivery/deepDiveIntoServiceCatalog/#paas-services","text":"Consume private database, messaging, application and analytics cloud services Create and manage PostGreSQL databases Create/delete clusters, instances and replica Automatic backup Switchover/ Failover management Database management: start / stop, create users,... Create and manage Oracle databases - DEV environments only - Historical Release DBPAAS Create / delete Oracle databases Retrieve information on available databases Export / import schemas Backup / restore management Database management: start / stop, patch,... Create and manage Oracle databases - all environments - New Release Oracle Cloud Platform Create / delete Oracle databases Retrieve information on available databases Export / Import schemas Backup/ restore management Database management : start / stop,... Create and manage RabbitMQ brokers Single (1-node broker) Master / slave (2-node cluster with queue mirroring) Create and manage Openshift projects Project / namespace management Openshift platform management Manage analytics and datalake services - New release LUCID Analytics and datalake infrastructure services Ingestion infrastructure services Restitution infrastructure services Create and manage Hadoop / HDF clusters Big data HDP / HDF clusters management Data Ingestion management","title":"PaaS services"},{"location":"office/cloudPlatformProfessionalServices/intermediate/cloudPlatformDelivery/deepDiveIntoServiceCatalog/#public-and-hybrid-cloud","text":"Obtain secured training, innovation or production environments for all your public cloud use cases and enjoy CSP service catalogs Native CSP consoles to manage services in a Societe Generale Public \"Cloud Box\" Training, innovation or production public cloud environments Internet Access Management Shared infrastructure (DNS, SMTP,...), OS / OS patching Trust and control framework, IAM, logs Build a hybrid Application internal IS and public Cloud and guarantee end-to-end security Manage connectivity between internal IS and CSP Instantiate administrative services in a DMZ zone for the public Cloud Share hybrid connectivity and services to / from applications in the cloud Create and manage workflows that connect data, processing, and services across clouds","title":"Public and hybrid cloud"},{"location":"office/cloudPlatformProfessionalServices/intermediate/cloudPlatformDelivery/doItNowService/","text":"DoItNow Services Principles and concepts What is DoItNow? DoItNow is the web-console of Cloud Platform. It offers an interface for all Societe Generale users who want to discover and use Cloud services. Cloud Platform objective is to allow its users to consume API to build Cloud native applications. DoItNow acts exactly as a user by calling any service's API on his behalf We do not aim at creating workflows or operations that cannot be achieved through API by a user The main objectives are: To help developers to discover and understand Cloud services To gather information for Account Leaders to manage their applications Available features and usage The general menu Allows you to access various transversal services of Cloud Platform such as billing, service health, service documentation, authorization of services used and,for sure, the actual Cloud Platform catalog Account selection DoItNow allows you to work with several accounts. After being authenticated, all accounts where you have at least one permission will be available in the drop down list. Region selection Through this selector, you can choose in which region you want to use a service. Please note that assets created in one region are tied to this specific region, therefore will not be displayed in DoItNow if you switch to another one. Notification The notifications panel will hold you latest notifications in order to retrieve you last requests made and their results Assistance This is a direct channel to communicate with the team in charge of any service you want to get information/help on. Cloud services The official catalog(in white) contains the latest stable version of each service Beta services The beta catalog contains the latest features of each service, that might not be completely bug free","title":"DoItNow Services"},{"location":"office/cloudPlatformProfessionalServices/intermediate/cloudPlatformDelivery/doItNowService/#doitnow-services","text":"","title":"DoItNow Services"},{"location":"office/cloudPlatformProfessionalServices/intermediate/cloudPlatformDelivery/doItNowService/#principles-and-concepts","text":"What is DoItNow? DoItNow is the web-console of Cloud Platform. It offers an interface for all Societe Generale users who want to discover and use Cloud services. Cloud Platform objective is to allow its users to consume API to build Cloud native applications. DoItNow acts exactly as a user by calling any service's API on his behalf We do not aim at creating workflows or operations that cannot be achieved through API by a user The main objectives are: To help developers to discover and understand Cloud services To gather information for Account Leaders to manage their applications","title":"Principles and concepts"},{"location":"office/cloudPlatformProfessionalServices/intermediate/cloudPlatformDelivery/doItNowService/#available-features-and-usage","text":"The general menu Allows you to access various transversal services of Cloud Platform such as billing, service health, service documentation, authorization of services used and,for sure, the actual Cloud Platform catalog Account selection DoItNow allows you to work with several accounts. After being authenticated, all accounts where you have at least one permission will be available in the drop down list. Region selection Through this selector, you can choose in which region you want to use a service. Please note that assets created in one region are tied to this specific region, therefore will not be displayed in DoItNow if you switch to another one. Notification The notifications panel will hold you latest notifications in order to retrieve you last requests made and their results Assistance This is a direct channel to communicate with the team in charge of any service you want to get information/help on. Cloud services The official catalog(in white) contains the latest stable version of each service Beta services The beta catalog contains the latest features of each service, that might not be completely bug free","title":"Available features and usage"},{"location":"office/cloudPlatformProfessionalServices/intermediate/cloudPlatformUse/cloudNativeArchitecture/","text":"Cloud Native Architecture The Principles of Cloud-native Architecture What do leading companies care about? \"We may not timely identify or effectively respond to consumer trends or preferences, which could negatively affect our relationship with our customers, demand for the products and services we sell, our market share and the growth of our business\" \"We rely extensively on information systems to process transactions, summarize results and manage our business. Disruption in out systems could harm our ability to conduct our operations\" \"If we fail to develop and maintain satisfactory relationships with physicians, hospitals and other service providers, our business could be materially and adversely affected\" \"Our future competitiveness and ability to achieve long-term profitability depends on our ability to control our costs\" What's expected of our software today? Valued by customers Constantly and easily changed Available at all times Scalable to meet demand Secure in all respects Maintainable at scale Defining \"Cloud Native\" Cloud native technologies empower organizations to build and run scalable applications in modern, dynamic environments such as public, private, and hybrid clouds Cloud Native is structuring teams, culture and technology to utilize automation and architectures to manage complexity and unlock velocity Cloud-native is an approach to building and running applications that exploits the advantages of the cloud computing delivery model. Cloud-native is about how applications are created and deployed, not where Cloud-native software is built for scale, built for continuous change, built to tolerate failure, built for manageability Traits of the Cloud Native Customer-centric Learning culture Agile developement Focus on products, not projects Automation of entire delivery process Heavy use of open-source software What does positive progress look like? More speed : Faster lead time, regular deployments More scale : Low API response time, easily scale in and out, linear dev productivity More stability : Drop in impact minutes, fast MTTR, low change failure rate More secure : Fully patched software, regularly changed credentials, small amounts of unplanned work Cloud-native applies to more than Apps Cloud-native infrastucture Cloud-native data Cloud-native security Cloud-native integration The pattern of cloud-native architecture Application architecture pattern 12-Factor applications One codebase in source control Declared dependencies Config stored in the environment Backing services as attached resources Separate build and run stages App executed as stataless processes Services exported as port bindings Scale out processes Disposability Environment parity Treat logs like event streams Run admin processes as one-off processes Microservices architecture Boundaries found via domain-driven design Loosely coupled components Continuously delivered Surgical scaling Contract-driven tests Organized around teams The supporting infrastucture for Microservices Service discovery Circuit breaker Externalized configuration Token-based security Messaging API gateway Modern data management Scalable, on-demand databases per microservice Favor event sourcing and CQRS pattern Use intelligent caching to improve resilience Application delivery patterns Fast feedback via continuous integration Version control is a must Trunk-based development Often coupled with test-driven development CI jobs triggered on code check-in Test in production-like environments Packaging up software Include configuration and code Build service generate artifacts Containers are a useful packaging structure Artifact repositories play a key role Continuously deliver value Small changes, regularly shipped Same binaries in each environment Multiple strategies for low-impact deployments Smoke test and watch metrics to ensure healthy releases Application infrastucture patterns Immutable infrastucture Observable systems APIs for interacting with infrastucture Chaos engineering to fight fragility Application team patterns Empowered, customer-focused teams DevOps style teams build and run services Platform Ops for managing underlying systems Site reliability engineering applies software engineering approach to operations The technologies for Cloud-native architecture Application architecture technologies External config including cloud-only services like Azure Key Vault, software like Hashicorp Vault or Spring Cloud Config Code-based microservice infrastucture like Spring Cloud, Steeltoe and Go Micro API gateways from public public cloud providers, or software from Apigee and Microsoft Identity management technologies including oAuth 2.0, OpenID connect and JWT Cloud-native database technologies Self-managed, OSS databases like PostGreSQL, MuSQL, MongoDB, and Cassandra Managed cloud databases from Amazon (RDS, DynamoDB), Microsoft (SQL Database, CosmosDB) and Google (Spanner) Self-managed or hosted application caches based on Redis, Memcached and GemFire Cloud-native Messaging technologies Brokers like RabbitMQ, ActiveMQ or NATS Event stream processors like Apache Kafka, Apache Flink or WSO2 Stream Processor Cloud-based services like Amazon SQS, Google Pub/Sub, or Azure Event Hubs Continuous integration technologies Version control software from GitHub, GitLab, Azure Repos, and Bitbucket Continuous integration workflow tools like Jenkins, Concourse, Circle CI, TeamCity, AXS CodePipeline and Azure Pipelines Packaging and Deploying technologies Artifact repositories like JFrog Artifactory, Sonartype Nexus repository, and Apache Archiva Package formats like Linux or Windows containers and package managers like Helm Use CI tools like Concourse or Jenkins, plus software like GoCD and Spinnaker Enable feature flags with services like LaunchDarkly, and analyze post-deploy metrics with DynaTrace and New Relic Infrastructure Automation technologies Config management like Chef, Ansible Create infrastucture with Terraform Build and manage systems with BOSH Run containers with Kubernetes, Mesos or Nomad Automate app runtime with PaaS and FaaS Microservices infrastucture with a service mesh Collaboration technologies Chat tools like Slack and Microsoft Teams Kanban boards using tools from Trello, Realtime Board, and Asana Shared access to logging and monitoring tools to pinpoint issues Video conferencing tools like Zoom, BlueJeans, Skype, and Google Hangouts","title":"Cloud Native Architecture"},{"location":"office/cloudPlatformProfessionalServices/intermediate/cloudPlatformUse/cloudNativeArchitecture/#cloud-native-architecture","text":"","title":"Cloud Native Architecture"},{"location":"office/cloudPlatformProfessionalServices/intermediate/cloudPlatformUse/cloudNativeArchitecture/#the-principles-of-cloud-native-architecture","text":"What do leading companies care about? \"We may not timely identify or effectively respond to consumer trends or preferences, which could negatively affect our relationship with our customers, demand for the products and services we sell, our market share and the growth of our business\" \"We rely extensively on information systems to process transactions, summarize results and manage our business. Disruption in out systems could harm our ability to conduct our operations\" \"If we fail to develop and maintain satisfactory relationships with physicians, hospitals and other service providers, our business could be materially and adversely affected\" \"Our future competitiveness and ability to achieve long-term profitability depends on our ability to control our costs\" What's expected of our software today? Valued by customers Constantly and easily changed Available at all times Scalable to meet demand Secure in all respects Maintainable at scale Defining \"Cloud Native\" Cloud native technologies empower organizations to build and run scalable applications in modern, dynamic environments such as public, private, and hybrid clouds Cloud Native is structuring teams, culture and technology to utilize automation and architectures to manage complexity and unlock velocity Cloud-native is an approach to building and running applications that exploits the advantages of the cloud computing delivery model. Cloud-native is about how applications are created and deployed, not where Cloud-native software is built for scale, built for continuous change, built to tolerate failure, built for manageability Traits of the Cloud Native Customer-centric Learning culture Agile developement Focus on products, not projects Automation of entire delivery process Heavy use of open-source software What does positive progress look like? More speed : Faster lead time, regular deployments More scale : Low API response time, easily scale in and out, linear dev productivity More stability : Drop in impact minutes, fast MTTR, low change failure rate More secure : Fully patched software, regularly changed credentials, small amounts of unplanned work Cloud-native applies to more than Apps Cloud-native infrastucture Cloud-native data Cloud-native security Cloud-native integration","title":"The Principles of Cloud-native Architecture"},{"location":"office/cloudPlatformProfessionalServices/intermediate/cloudPlatformUse/cloudNativeArchitecture/#the-pattern-of-cloud-native-architecture","text":"Application architecture pattern 12-Factor applications One codebase in source control Declared dependencies Config stored in the environment Backing services as attached resources Separate build and run stages App executed as stataless processes Services exported as port bindings Scale out processes Disposability Environment parity Treat logs like event streams Run admin processes as one-off processes Microservices architecture Boundaries found via domain-driven design Loosely coupled components Continuously delivered Surgical scaling Contract-driven tests Organized around teams The supporting infrastucture for Microservices Service discovery Circuit breaker Externalized configuration Token-based security Messaging API gateway Modern data management Scalable, on-demand databases per microservice Favor event sourcing and CQRS pattern Use intelligent caching to improve resilience Application delivery patterns Fast feedback via continuous integration Version control is a must Trunk-based development Often coupled with test-driven development CI jobs triggered on code check-in Test in production-like environments Packaging up software Include configuration and code Build service generate artifacts Containers are a useful packaging structure Artifact repositories play a key role Continuously deliver value Small changes, regularly shipped Same binaries in each environment Multiple strategies for low-impact deployments Smoke test and watch metrics to ensure healthy releases Application infrastucture patterns Immutable infrastucture Observable systems APIs for interacting with infrastucture Chaos engineering to fight fragility Application team patterns Empowered, customer-focused teams DevOps style teams build and run services Platform Ops for managing underlying systems Site reliability engineering applies software engineering approach to operations","title":"The pattern of cloud-native architecture"},{"location":"office/cloudPlatformProfessionalServices/intermediate/cloudPlatformUse/cloudNativeArchitecture/#the-technologies-for-cloud-native-architecture","text":"Application architecture technologies External config including cloud-only services like Azure Key Vault, software like Hashicorp Vault or Spring Cloud Config Code-based microservice infrastucture like Spring Cloud, Steeltoe and Go Micro API gateways from public public cloud providers, or software from Apigee and Microsoft Identity management technologies including oAuth 2.0, OpenID connect and JWT Cloud-native database technologies Self-managed, OSS databases like PostGreSQL, MuSQL, MongoDB, and Cassandra Managed cloud databases from Amazon (RDS, DynamoDB), Microsoft (SQL Database, CosmosDB) and Google (Spanner) Self-managed or hosted application caches based on Redis, Memcached and GemFire Cloud-native Messaging technologies Brokers like RabbitMQ, ActiveMQ or NATS Event stream processors like Apache Kafka, Apache Flink or WSO2 Stream Processor Cloud-based services like Amazon SQS, Google Pub/Sub, or Azure Event Hubs Continuous integration technologies Version control software from GitHub, GitLab, Azure Repos, and Bitbucket Continuous integration workflow tools like Jenkins, Concourse, Circle CI, TeamCity, AXS CodePipeline and Azure Pipelines Packaging and Deploying technologies Artifact repositories like JFrog Artifactory, Sonartype Nexus repository, and Apache Archiva Package formats like Linux or Windows containers and package managers like Helm Use CI tools like Concourse or Jenkins, plus software like GoCD and Spinnaker Enable feature flags with services like LaunchDarkly, and analyze post-deploy metrics with DynaTrace and New Relic Infrastructure Automation technologies Config management like Chef, Ansible Create infrastucture with Terraform Build and manage systems with BOSH Run containers with Kubernetes, Mesos or Nomad Automate app runtime with PaaS and FaaS Microservices infrastucture with a service mesh Collaboration technologies Chat tools like Slack and Microsoft Teams Kanban boards using tools from Trello, Realtime Board, and Asana Shared access to logging and monitoring tools to pinpoint issues Video conferencing tools like Zoom, BlueJeans, Skype, and Google Hangouts","title":"The technologies for Cloud-native architecture"},{"location":"office/cloudPlatformProfessionalServices/intermediate/cloudPlatformUse/introductionToCloudArchitecture/","text":"Introduction to Cloud Architecture What is the Cloud? What are the different types of Cloud? What is the Cloud exactly? The Cloud (Computing) is a way of providing access to computer resources, characterized by its self-service availability, elasticity, openness, mutualisation and pay-per-use Self-service and on-demand resources of storage capacity and computing power, according to the customer's needs. This contrasts with so-called \"traditional\" computing where any need to change an application requires manual operations and therefore time.In the Cloud, the need, automatically detected by the application or at the customer's request, is taken into account and satisfied immediately. Openness : Cloud services are accessible through a network, using standardized techniques, whether from a computer, a amartphone or a tablet Mutualization : The Cloud mutualizes its IT resources (servers, CPU, RAM, storage, network) to serve its customers, to whom the ordered resources are allocated according to automatic processes. Mutualization improves scalability and elasticity; it facilitates the automatic adaptation of resources to variations in demand Pay-per-use: The quantity of services consumed in the Cloud is measured for purposes of control, adaptation of technical means and billing. With the Cloud, we should talk about \"XAAS\". What's XAAS? The acronym XaaS refers to Everything-as-a-Service. This term refers to the different models of Cloud computing \"as a service\" Indeed with the Cloud, we no longer speak of infrastructure components but of services, which explains the syntax of the terms (aaS). XaaS services are organised into 3 categories IaaS (Infrastructure as a Service) : Provides CPU, storage, RAM, Network PaaS (Platform as a Service) : Provides ready-to-use middlewares (database, web server,etc.) SaaS (Software as a Service) : Provides ready-to-use softwares (CRM, expense claim management, online office automation tools such as Office 365, payroll management, etc.) We talk about \"Infrastructure as a Service\" is the case where: The client manages the middlewares and softwares (executables, settings, databases) The Cloud provider manages server hardware, virtualization layers, storage, networks It is a model where the customer has, on a paying subscription basis, an IT infrastructure (servers, storage, backup, network) that is physically located at the Cloud provider XaaS service in detail Infrastructure as a Service (IaaS) It's the lowest level of service. It consist of providing access to a virtualized computer park. Virtual machines on which the customer can install an operating system and applications. The service is similar to traditional data center hosting services, and the trend is towards highest level services (PaaS or IaaS) that are more abstract in terms of technical details Platform as a Service In this type of service, the operating system and infrastructure tools are the responsibility of the Cloud provider. The customer has direct access to specialized services (web front-ends, middlewares, databases, etc.) that can be customized: the customer chooses, in a Marketplace, the design of the technical solution to be deployed. The Cloud provider will execute the implementation with its own Scripts. Advantage The customer of the Cloud solution will be able to focus on the business application to be implemented Disadvantage In the event that the PaaS provider decides to no longer authorize the use of a tool or a version, or to interrupt or develop its offer, the consumer must adapt within the timeframe chosen by the PaaS provider Software as a Service In this type of service, software are made available to clients, accessible from a Web browser or installed on a PC for rental. The customer does not have to worry about making updates, adding security patches and ensuring the availability of the service Advantage Rapid implementation and provision of services for the customer. No need to worry about software packagees and licenses anymore. The service is immediately 'available online' As the software is managed by the provider, customers no longer need to worry about deployments, maintenance and technical evolution phases of the Service Disadvantage It is difficult to manage service interruptions; customers have to organize themselves around the constraints imposed by the SaaS provider It is necessary to comply with the supplier's prerequisites for a good use The customer is subject to the SaaS product product lifecycle by the Cloud provider, particularly in the event of a lack orabandonment of functionality A SaaS provider can operate PaaS-type services, which in turn can use IaaS. The use of services (IaaS-PaaS-SaaS), by its nature, is therefore a shared responsibility. The different types of clouds The public cloud The infrastructure is mutualized ans is shared between several companies and individuals. It is owned by a service provider. The Service Level Agreement (SLA) is the same for all users and is defined by the provider Natively, Public Cloud services are provided in a virtualized environment, built using physical resources in pools shared with all other subscribers The services are accessible via the Internet The Public Cloud offers the following features and benefits High resource scalability so that an application can respond flexibly to charge fluctuations Only leased resources are billed The pricing model is based on what is consumed(no cost on unused resources) No more need to tie up resources to anticipate future needs The (very) high availability of access to environments The multitude of physical components implemented by the supplier to create a Public Cloud means that there is no (theoretically) infrastructure SPOF (Single Point of Failure : a system-part whose failure stops the system from working) The services offered can meet most of the requirements and use cases sought by the company Customers have access to a standardized environment The Private Cloud It is an environment exclusively used by a company The company is then responsible for the purchase, installation and management of servers, network, storage, etc. all of which are protected by security solutions implemented by the company The Private Cloud can be hosted in company-owned datacenter or hosted by a partner The Hybrid Cloud It is a use of several Clouds where all combinations between Private and Public Clouds are possible These combinations of several types of accomodation totally independent of each other require to respect: Technological standards to be able to communicate between Clouds A network connectivity that can meet the needs The Hybrid Cloud makes it possible to shift workloads between different types of hosting according to changing needs, cost reduction or in case of need for dynamic increase of mass resources The Cloud Market According to the RightScale (2019) report on the state of cloud computing, 91% of companies reported using a Public Cloud service Gartner's most recent data on the global market for infrastructure as Cloud IaaS Service indicates annual revenues of 32.4 billion dollars. This is a 31.3% growth from 24.7 billion dollars in 2017. According to Gartner, the market is dominated by 5 vendors that account for nearly 80% of the global Cloud IaaS market share in 2018 AWS : 50% Microsoft Azure : 15% Alibaba Cloud : 8% Google Cloud Platform : 5% IBM Cloud :2% What are the key architecture concepts of the Cloud? Anatomy of the Cloud A Cloud is made up of regions, which in turn are made up of Availability Zones(AZs) that contain services Region : It is a collection of availability zones. The regions are far enough apart from each other so that they are not simultaneously impacted by disasters of regional scope: earthquake, electrical grid loss, etc. The regions are too far apart to allow synchronoud data replication Availability Zones : This is a deployment zone for infrastructure resources that can be deployed via the Cloud. Zones in the same region are close enough to be interconnected with high-capacity, low-latency network links that allow synchronous data replication. However they are far enough apart to avoid being impacted by local disasters such as loss of power, fire, etc. A distance of a few km to 50 km is generally observed Services As seen in the previous section, a cloud is composed of automated services These services can be classified into two categories: Services that support the operation of the Cloud Billing Supervision Events Authorizations Infrastructure services VM Containers Load Balancer Databases Anatomy of a Cloud: how it works Consumers of Cloud Platform Developers Applications COO, etc. There are several ways to interact with a service By API On the command line (CLI) By a console (DoItNow internally) Cloud Platform is composed of unit services called XaaS A resource can be any infrastructure object that supports an application (examples: VM, database, VIP, DNA aliases, etc.) Control plane Everything that allows you to manage the service's resources (creation, deletion, supervision, etc.) Resource plane These are the resources created by the service (VMs, databases, etc.) Some key concepts - the account at the heart of everything The Clouds are organized around the notion of account. This account can be seen as a container for all the resources deployed within a Cloud : database, virtual machines, etc. The same account will be used: To manage the authorization on the services and resources of Cloud Platform To also manage the billing of services The only thing to remember at this stage is that you will need an account to access Cloud Platform. If you want to know more, please consult the specific MOOC on IAM (Identity and Access Management) Cloud native, what does that mean? As described above, a Cloud brings a number of benefits (elasticity, agility, etc.) Nevertheless, in order to take full advantage of the Cloud, applications need to be designed for it. These applications are called Cloud Native Applications : born in the Cloud Multiple frameworks (eg. 12 factors) exist to define precisely what this concept is and the detailed characteristics of the applications implementing it. This will be the subject of the Level 2 MOOC We will summarize them here in the three main characteristics: Resilient The application is designed to survive the loss of a unit component, an area of availability or even a region if necessary. In the same way, an application must support temporary network modifications: throughput, latency, etc. Elastic The application must be able to adapt to the number of requests in order to optimize its operating cost Automated The application is deployed automatically through a continuous deployment chain on infrastructure components which are themselves created in an automated way (infra as code) The application does not require manual actions on the unit components, metrics are fed back and automatic actions are taken on the basis of these metrics What does the Societe Generale cloud offer? What are the founding principles of Cloud Platform? The Societe Generale Cloud Platform has been designed to be multi-Cloud and aligned, for its internal services, with the concepts of the Public Cloud and market standards : Multi-Cloud as it offers internal services and native access to the Public Cloud in accordance with the regulator's rules and the Group's security rules Aligned with Cloud concepts and market standards, it enables internal applications to be designed in the same ways as in the Public Cloud The service offering has been designed to support Cloud Native Applications and DevOps / NoOps practices : The service catalog therefore offers the minimum services enabling Cloud Native architectures (eg. load balancer, containers, event management, etc.) And to support DevOps / NoOps practices, all services are accessible via API Services are designed from the outset to be agnostic of the customer them : in concrete terms, the service consumed is the same regardless of the IT department (BSC, GBSU, ITIM, IRBS) Finally, all services are attractively priced and are billed on a pay-per-use basis One Internal Cloud and two Public Clouds Regions of presence of the GTS Private Cloud in the world : USA East - 2 AZ Paris - 2 AZ North - 1 AZ Asia - 2 AZ One Internal Cloud and two Public Clouds Regions of presence of Public Cloud actors in the world : Azure AWS Business lines may choose to restrict the use of the Public Cloud to certain regions CSP / CSP+ / MSP organization Cloud Service Provider (CSP) Services consumed by API, used by the customers themselves : Account-centric, not application-centric (as in public CSPs) Independence from uses and type of environment (everything is production) Main objective Openness and adaptability of the model for NoOps consumption CSP+ (Controller = \"Bank in compliance\") Business processes for Safety, Compliance, Financial Management and Operations (SOC / OPM) are based on : Knowledge of the application ID (communication, impact assessment) Knowledge of the type of environment (prioritization, impact assessment) Main objective To ensure respect and compliance with enforced rules Managed Service Provider (MSP) Consumed services, adapted to a particular client and its ecosystem Entirely used by GTS on behalf of the customer Use of GTS's MSP tools Marley GDAT iAppli KAT Main objective : To provide managed services on customer resources So, Public Cloud or Private Cloud? What are the main criteria for choosing between Private Cloud and Public Cloud? Data security An application cannot be hosted in the Public Cloud if its data meets at least one of the following criteria : The data is C3 (according to the critically scale C0 / C1 / C2 / C3 in force at Sociate Generale) The data is subject to regulatory (eg. European Central Bank) or legal constraints The data relates to private information (RGPD constraints for the protection of personal data) The strategy of the Business Line, owner of the data, refuses to host it in the Public Cloud (residual risks too high estimated by the Business Line) Innovation / Technological advantage The richness of the catalogues of Public Cloud providers in terms of Data-Science and Artificial Intelligence can help accelerate the development of new cases planned within the different business lines (new services, fight against fraud, improvement of operational efficiency, etc.) Elasticity and agility Users appear to have almost unlimited resources in the Public Cloud. As a result, the Public Cloud is often better suited to large workloads or highly fluctuating demands Business value vs cost A comparative financial analysis (Business Case) is often necessary to make a choice. The Business Case must evaluate the value brought to the business for each type of Cloud and its operating cost (Run). The public Cloud can be penalized by telecom expenses (access to the Cloud) and by costs related to the need for reversibility management","title":"Introduction to Cloud Architecture"},{"location":"office/cloudPlatformProfessionalServices/intermediate/cloudPlatformUse/introductionToCloudArchitecture/#introduction-to-cloud-architecture","text":"","title":"Introduction to Cloud Architecture"},{"location":"office/cloudPlatformProfessionalServices/intermediate/cloudPlatformUse/introductionToCloudArchitecture/#what-is-the-cloud-what-are-the-different-types-of-cloud","text":"What is the Cloud exactly? The Cloud (Computing) is a way of providing access to computer resources, characterized by its self-service availability, elasticity, openness, mutualisation and pay-per-use Self-service and on-demand resources of storage capacity and computing power, according to the customer's needs. This contrasts with so-called \"traditional\" computing where any need to change an application requires manual operations and therefore time.In the Cloud, the need, automatically detected by the application or at the customer's request, is taken into account and satisfied immediately. Openness : Cloud services are accessible through a network, using standardized techniques, whether from a computer, a amartphone or a tablet Mutualization : The Cloud mutualizes its IT resources (servers, CPU, RAM, storage, network) to serve its customers, to whom the ordered resources are allocated according to automatic processes. Mutualization improves scalability and elasticity; it facilitates the automatic adaptation of resources to variations in demand Pay-per-use: The quantity of services consumed in the Cloud is measured for purposes of control, adaptation of technical means and billing. With the Cloud, we should talk about \"XAAS\". What's XAAS? The acronym XaaS refers to Everything-as-a-Service. This term refers to the different models of Cloud computing \"as a service\" Indeed with the Cloud, we no longer speak of infrastructure components but of services, which explains the syntax of the terms (aaS). XaaS services are organised into 3 categories IaaS (Infrastructure as a Service) : Provides CPU, storage, RAM, Network PaaS (Platform as a Service) : Provides ready-to-use middlewares (database, web server,etc.) SaaS (Software as a Service) : Provides ready-to-use softwares (CRM, expense claim management, online office automation tools such as Office 365, payroll management, etc.) We talk about \"Infrastructure as a Service\" is the case where: The client manages the middlewares and softwares (executables, settings, databases) The Cloud provider manages server hardware, virtualization layers, storage, networks It is a model where the customer has, on a paying subscription basis, an IT infrastructure (servers, storage, backup, network) that is physically located at the Cloud provider XaaS service in detail Infrastructure as a Service (IaaS) It's the lowest level of service. It consist of providing access to a virtualized computer park. Virtual machines on which the customer can install an operating system and applications. The service is similar to traditional data center hosting services, and the trend is towards highest level services (PaaS or IaaS) that are more abstract in terms of technical details Platform as a Service In this type of service, the operating system and infrastructure tools are the responsibility of the Cloud provider. The customer has direct access to specialized services (web front-ends, middlewares, databases, etc.) that can be customized: the customer chooses, in a Marketplace, the design of the technical solution to be deployed. The Cloud provider will execute the implementation with its own Scripts. Advantage The customer of the Cloud solution will be able to focus on the business application to be implemented Disadvantage In the event that the PaaS provider decides to no longer authorize the use of a tool or a version, or to interrupt or develop its offer, the consumer must adapt within the timeframe chosen by the PaaS provider Software as a Service In this type of service, software are made available to clients, accessible from a Web browser or installed on a PC for rental. The customer does not have to worry about making updates, adding security patches and ensuring the availability of the service Advantage Rapid implementation and provision of services for the customer. No need to worry about software packagees and licenses anymore. The service is immediately 'available online' As the software is managed by the provider, customers no longer need to worry about deployments, maintenance and technical evolution phases of the Service Disadvantage It is difficult to manage service interruptions; customers have to organize themselves around the constraints imposed by the SaaS provider It is necessary to comply with the supplier's prerequisites for a good use The customer is subject to the SaaS product product lifecycle by the Cloud provider, particularly in the event of a lack orabandonment of functionality A SaaS provider can operate PaaS-type services, which in turn can use IaaS. The use of services (IaaS-PaaS-SaaS), by its nature, is therefore a shared responsibility. The different types of clouds The public cloud The infrastructure is mutualized ans is shared between several companies and individuals. It is owned by a service provider. The Service Level Agreement (SLA) is the same for all users and is defined by the provider Natively, Public Cloud services are provided in a virtualized environment, built using physical resources in pools shared with all other subscribers The services are accessible via the Internet The Public Cloud offers the following features and benefits High resource scalability so that an application can respond flexibly to charge fluctuations Only leased resources are billed The pricing model is based on what is consumed(no cost on unused resources) No more need to tie up resources to anticipate future needs The (very) high availability of access to environments The multitude of physical components implemented by the supplier to create a Public Cloud means that there is no (theoretically) infrastructure SPOF (Single Point of Failure : a system-part whose failure stops the system from working) The services offered can meet most of the requirements and use cases sought by the company Customers have access to a standardized environment The Private Cloud It is an environment exclusively used by a company The company is then responsible for the purchase, installation and management of servers, network, storage, etc. all of which are protected by security solutions implemented by the company The Private Cloud can be hosted in company-owned datacenter or hosted by a partner The Hybrid Cloud It is a use of several Clouds where all combinations between Private and Public Clouds are possible These combinations of several types of accomodation totally independent of each other require to respect: Technological standards to be able to communicate between Clouds A network connectivity that can meet the needs The Hybrid Cloud makes it possible to shift workloads between different types of hosting according to changing needs, cost reduction or in case of need for dynamic increase of mass resources The Cloud Market According to the RightScale (2019) report on the state of cloud computing, 91% of companies reported using a Public Cloud service Gartner's most recent data on the global market for infrastructure as Cloud IaaS Service indicates annual revenues of 32.4 billion dollars. This is a 31.3% growth from 24.7 billion dollars in 2017. According to Gartner, the market is dominated by 5 vendors that account for nearly 80% of the global Cloud IaaS market share in 2018 AWS : 50% Microsoft Azure : 15% Alibaba Cloud : 8% Google Cloud Platform : 5% IBM Cloud :2%","title":"What is the Cloud? What are the different types of Cloud?"},{"location":"office/cloudPlatformProfessionalServices/intermediate/cloudPlatformUse/introductionToCloudArchitecture/#what-are-the-key-architecture-concepts-of-the-cloud","text":"Anatomy of the Cloud A Cloud is made up of regions, which in turn are made up of Availability Zones(AZs) that contain services Region : It is a collection of availability zones. The regions are far enough apart from each other so that they are not simultaneously impacted by disasters of regional scope: earthquake, electrical grid loss, etc. The regions are too far apart to allow synchronoud data replication Availability Zones : This is a deployment zone for infrastructure resources that can be deployed via the Cloud. Zones in the same region are close enough to be interconnected with high-capacity, low-latency network links that allow synchronous data replication. However they are far enough apart to avoid being impacted by local disasters such as loss of power, fire, etc. A distance of a few km to 50 km is generally observed Services As seen in the previous section, a cloud is composed of automated services These services can be classified into two categories: Services that support the operation of the Cloud Billing Supervision Events Authorizations Infrastructure services VM Containers Load Balancer Databases Anatomy of a Cloud: how it works Consumers of Cloud Platform Developers Applications COO, etc. There are several ways to interact with a service By API On the command line (CLI) By a console (DoItNow internally) Cloud Platform is composed of unit services called XaaS A resource can be any infrastructure object that supports an application (examples: VM, database, VIP, DNA aliases, etc.) Control plane Everything that allows you to manage the service's resources (creation, deletion, supervision, etc.) Resource plane These are the resources created by the service (VMs, databases, etc.) Some key concepts - the account at the heart of everything The Clouds are organized around the notion of account. This account can be seen as a container for all the resources deployed within a Cloud : database, virtual machines, etc. The same account will be used: To manage the authorization on the services and resources of Cloud Platform To also manage the billing of services The only thing to remember at this stage is that you will need an account to access Cloud Platform. If you want to know more, please consult the specific MOOC on IAM (Identity and Access Management) Cloud native, what does that mean? As described above, a Cloud brings a number of benefits (elasticity, agility, etc.) Nevertheless, in order to take full advantage of the Cloud, applications need to be designed for it. These applications are called Cloud Native Applications : born in the Cloud Multiple frameworks (eg. 12 factors) exist to define precisely what this concept is and the detailed characteristics of the applications implementing it. This will be the subject of the Level 2 MOOC We will summarize them here in the three main characteristics: Resilient The application is designed to survive the loss of a unit component, an area of availability or even a region if necessary. In the same way, an application must support temporary network modifications: throughput, latency, etc. Elastic The application must be able to adapt to the number of requests in order to optimize its operating cost Automated The application is deployed automatically through a continuous deployment chain on infrastructure components which are themselves created in an automated way (infra as code) The application does not require manual actions on the unit components, metrics are fed back and automatic actions are taken on the basis of these metrics","title":"What are the key architecture concepts of the Cloud?"},{"location":"office/cloudPlatformProfessionalServices/intermediate/cloudPlatformUse/introductionToCloudArchitecture/#what-does-the-societe-generale-cloud-offer","text":"What are the founding principles of Cloud Platform? The Societe Generale Cloud Platform has been designed to be multi-Cloud and aligned, for its internal services, with the concepts of the Public Cloud and market standards : Multi-Cloud as it offers internal services and native access to the Public Cloud in accordance with the regulator's rules and the Group's security rules Aligned with Cloud concepts and market standards, it enables internal applications to be designed in the same ways as in the Public Cloud The service offering has been designed to support Cloud Native Applications and DevOps / NoOps practices : The service catalog therefore offers the minimum services enabling Cloud Native architectures (eg. load balancer, containers, event management, etc.) And to support DevOps / NoOps practices, all services are accessible via API Services are designed from the outset to be agnostic of the customer them : in concrete terms, the service consumed is the same regardless of the IT department (BSC, GBSU, ITIM, IRBS) Finally, all services are attractively priced and are billed on a pay-per-use basis One Internal Cloud and two Public Clouds Regions of presence of the GTS Private Cloud in the world : USA East - 2 AZ Paris - 2 AZ North - 1 AZ Asia - 2 AZ One Internal Cloud and two Public Clouds Regions of presence of Public Cloud actors in the world : Azure AWS Business lines may choose to restrict the use of the Public Cloud to certain regions CSP / CSP+ / MSP organization Cloud Service Provider (CSP) Services consumed by API, used by the customers themselves : Account-centric, not application-centric (as in public CSPs) Independence from uses and type of environment (everything is production) Main objective Openness and adaptability of the model for NoOps consumption CSP+ (Controller = \"Bank in compliance\") Business processes for Safety, Compliance, Financial Management and Operations (SOC / OPM) are based on : Knowledge of the application ID (communication, impact assessment) Knowledge of the type of environment (prioritization, impact assessment) Main objective To ensure respect and compliance with enforced rules Managed Service Provider (MSP) Consumed services, adapted to a particular client and its ecosystem Entirely used by GTS on behalf of the customer Use of GTS's MSP tools Marley GDAT iAppli KAT Main objective : To provide managed services on customer resources","title":"What does the Societe Generale cloud offer?"},{"location":"office/cloudPlatformProfessionalServices/intermediate/cloudPlatformUse/introductionToCloudArchitecture/#so-public-cloud-or-private-cloud","text":"What are the main criteria for choosing between Private Cloud and Public Cloud? Data security An application cannot be hosted in the Public Cloud if its data meets at least one of the following criteria : The data is C3 (according to the critically scale C0 / C1 / C2 / C3 in force at Sociate Generale) The data is subject to regulatory (eg. European Central Bank) or legal constraints The data relates to private information (RGPD constraints for the protection of personal data) The strategy of the Business Line, owner of the data, refuses to host it in the Public Cloud (residual risks too high estimated by the Business Line) Innovation / Technological advantage The richness of the catalogues of Public Cloud providers in terms of Data-Science and Artificial Intelligence can help accelerate the development of new cases planned within the different business lines (new services, fight against fraud, improvement of operational efficiency, etc.) Elasticity and agility Users appear to have almost unlimited resources in the Public Cloud. As a result, the Public Cloud is often better suited to large workloads or highly fluctuating demands Business value vs cost A comparative financial analysis (Business Case) is often necessary to make a choice. The Business Case must evaluate the value brought to the business for each type of Cloud and its operating cost (Run). The public Cloud can be penalized by telecom expenses (access to the Cloud) and by costs related to the need for reversibility management","title":"So, Public Cloud or Private Cloud?"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/IAMService/","text":"IAM Service Principles and concepts The IAM service and why you may need it? The founding concepts of the Identity and Access Management(IAM) service can be summarized in 4 key words Permissions Roles Tools to setup permissions and roles Certifcation rules More precisions on the IAM service concepts (1/3) The account model of Cloud Platform is aligned with public cloud principles, billing constraints and security requirements User A user can be a human (developer, application manager, etc.) or technical (called ClientID). Both are considered in the same way by services and the IAM. A user may be granted 1 or several roles by an Account Leader Account In cloud Platform, all resources and roles(permissions) are tied to 1 and only 1 account. An account can represent any project or application, thus 1 account can be used for N users, and 1 user can use N accounts. Resources are tied to 1 and only 1 account. In fact, an account is a billing entity used to gather resources, their permissions and their costs Roles Roles can be seen as a Template of permissions ready to be given to a user. They contain scopes that are keys to use services. A scope allows the user to perform specific operations on the Cloud Platform services, typically CRUD operations on Cloud Platform resources. Account Leader and Security Office An account has 2 main managers : the Account Leader who can grant roles, created by the Security Officer, to Users or Clients in his account. Today, the App Manager has both responsibilities and can create roles and enable any user to the roles tied to the account Provisioning Officer By default, the Provisioning Officer is the manager of a set of users, as described in go/org. The Provisioning Officer (as well as Account Leader) is in charge of validating any request coming from a user is his/her team validation workflows The processes for validating access to SG are a cornerstone of the bank's security and must be replaced. Available features and usages Today, as an application manager (Account Leader and Security Officer), through WHATS or DIN, i can: Create Roles from a list of predefined scopes (read scopes, write scopes) or by selecting custom scopes Update / Delete Roles List Available Roles Grant / Remove users (and myself) Display scopes attached to a role List menbers of each role View roles granted to a user Track all ongoing requests pushed by me or by others Validate or refuse user permission requests As a developer, through WHATS or DIN, i can: View role description for existing roles Display scopes attached to a role View the roles I have been granted Request permission on an existing role Request permission on a scope not contained in an existing role As a Provisioning Officer, through WHATS, i can: Validate or refuse user permission requests","title":"IAM Service"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/IAMService/#iam-service","text":"","title":"IAM Service"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/IAMService/#principles-and-concepts","text":"The IAM service and why you may need it? The founding concepts of the Identity and Access Management(IAM) service can be summarized in 4 key words Permissions Roles Tools to setup permissions and roles Certifcation rules More precisions on the IAM service concepts (1/3) The account model of Cloud Platform is aligned with public cloud principles, billing constraints and security requirements User A user can be a human (developer, application manager, etc.) or technical (called ClientID). Both are considered in the same way by services and the IAM. A user may be granted 1 or several roles by an Account Leader Account In cloud Platform, all resources and roles(permissions) are tied to 1 and only 1 account. An account can represent any project or application, thus 1 account can be used for N users, and 1 user can use N accounts. Resources are tied to 1 and only 1 account. In fact, an account is a billing entity used to gather resources, their permissions and their costs Roles Roles can be seen as a Template of permissions ready to be given to a user. They contain scopes that are keys to use services. A scope allows the user to perform specific operations on the Cloud Platform services, typically CRUD operations on Cloud Platform resources. Account Leader and Security Office An account has 2 main managers : the Account Leader who can grant roles, created by the Security Officer, to Users or Clients in his account. Today, the App Manager has both responsibilities and can create roles and enable any user to the roles tied to the account Provisioning Officer By default, the Provisioning Officer is the manager of a set of users, as described in go/org. The Provisioning Officer (as well as Account Leader) is in charge of validating any request coming from a user is his/her team validation workflows The processes for validating access to SG are a cornerstone of the bank's security and must be replaced.","title":"Principles and concepts"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/IAMService/#available-features-and-usages","text":"Today, as an application manager (Account Leader and Security Officer), through WHATS or DIN, i can: Create Roles from a list of predefined scopes (read scopes, write scopes) or by selecting custom scopes Update / Delete Roles List Available Roles Grant / Remove users (and myself) Display scopes attached to a role List menbers of each role View roles granted to a user Track all ongoing requests pushed by me or by others Validate or refuse user permission requests As a developer, through WHATS or DIN, i can: View role description for existing roles Display scopes attached to a role View the roles I have been granted Request permission on an existing role Request permission on a scope not contained in an existing role As a Provisioning Officer, through WHATS, i can: Validate or refuse user permission requests","title":"Available features and usages"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/IPAM_DNSService/","text":"IPAM-DNS Service Principles and concepts IP Address Management (IPAM) is a service for planning and managing the assignment and use of IP addresses and networks. It does not typically provide Domain Name System (DNS) and Dynamic Host Configuration Protocol (DHCP) services, but manages information for these components at SG Domain Name System (DNS) is the service for managing SG's domain names. It allows users to translate Cloud Platform resouce names into IP addresses (previously reserved in the IPAM). It's the naming system for the Cloud platform resources Each IP address used in the DNS is known by the IPAM. In this way, IPAM is the golden source for IP addresses and networks The important features of the DNS service are : Define host names in a domain and bind it to an IP address Define aliases for hosts created in domains (also known as FQDNs : Fully Qualified Domain Names) Use cases Reserve an IP address in a subnet Give a human-readable name to my resouce in Cloud Platform and associate it with my previously reserved IP Create an alias on top of my application front-end in order to be used ny my application endusers Available features and usages IPAM/DNS services allow to request an IP, ,manage subnet, manage Hosts or manage DNS aliases It's available in a self-service mode(API or web portal)","title":"IPAM-DNS Service"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/IPAM_DNSService/#ipam-dns-service","text":"","title":"IPAM-DNS Service"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/IPAM_DNSService/#principles-and-concepts","text":"IP Address Management (IPAM) is a service for planning and managing the assignment and use of IP addresses and networks. It does not typically provide Domain Name System (DNS) and Dynamic Host Configuration Protocol (DHCP) services, but manages information for these components at SG Domain Name System (DNS) is the service for managing SG's domain names. It allows users to translate Cloud Platform resouce names into IP addresses (previously reserved in the IPAM). It's the naming system for the Cloud platform resources Each IP address used in the DNS is known by the IPAM. In this way, IPAM is the golden source for IP addresses and networks The important features of the DNS service are : Define host names in a domain and bind it to an IP address Define aliases for hosts created in domains (also known as FQDNs : Fully Qualified Domain Names)","title":"Principles and concepts"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/IPAM_DNSService/#use-cases","text":"Reserve an IP address in a subnet Give a human-readable name to my resouce in Cloud Platform and associate it with my previously reserved IP Create an alias on top of my application front-end in order to be used ny my application endusers","title":"Use cases"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/IPAM_DNSService/#available-features-and-usages","text":"IPAM/DNS services allow to request an IP, ,manage subnet, manage Hosts or manage DNS aliases It's available in a self-service mode(API or web portal)","title":"Available features and usages"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/OSConfigurationService/","text":"OS Configuration Service Principles and concepts What is OS configuration? OS configuration (or OSC) is the service that allows you to modify your server configuration with Puppet recipes (also called modules) available in a maintained catalogue. The context : Business applications require to deploy and configure components on new servers when they are not already installed in the base image from which those servers are instantiated The standard : Some configurations are mandatory within SG. Typically : The configuration of the security components included on the base image provided by GTS is always enforced by OSC The hardening of the servers is also enforced by OSC Finally, you cannot modify configurations under the control if OSC The service : The OSC service allows you to modify server configuration based on catalog if recipes You can also create your own recipes, validated by a CI/CD pipeline, and use them through OSC Available features and usages What are the features of the OS configuration service? List of all available modules in catalog Associate modules to a server Execute a run of puppet agent Get status of the run of the agent Create new module in the OSC catalog Change server from production environment to OSC development one","title":"OS Configuration Service"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/OSConfigurationService/#os-configuration-service","text":"","title":"OS Configuration Service"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/OSConfigurationService/#principles-and-concepts","text":"What is OS configuration? OS configuration (or OSC) is the service that allows you to modify your server configuration with Puppet recipes (also called modules) available in a maintained catalogue. The context : Business applications require to deploy and configure components on new servers when they are not already installed in the base image from which those servers are instantiated The standard : Some configurations are mandatory within SG. Typically : The configuration of the security components included on the base image provided by GTS is always enforced by OSC The hardening of the servers is also enforced by OSC Finally, you cannot modify configurations under the control if OSC The service : The OSC service allows you to modify server configuration based on catalog if recipes You can also create your own recipes, validated by a CI/CD pipeline, and use them through OSC","title":"Principles and concepts"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/OSConfigurationService/#available-features-and-usages","text":"What are the features of the OS configuration service? List of all available modules in catalog Associate modules to a server Execute a run of puppet agent Get status of the run of the agent Create new module in the OSC catalog Change server from production environment to OSC development one","title":"Available features and usages"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/OSFactoryService/","text":"OS Factory Service Principles and concepts What is OS factory? OS factory is the service that allows you to create your own personalized images fro a standardized GTS image The context : Business applications require security to limit the vulnerabilities associated with OS The standard The default images provided by GTS in catalog are hardened They also contain all security agents and requirements imposed by the CSOs Those images allow to be in compliance with security rules of SG The service The OSF allows you to customize those 'source images' in order to create your own image This new personalized image can include specific components allowing for fast provisioning of, compliant, instances already containing business applications packages Available features and usages Features of OSF List of all available images in catalog Create a new image from the source image of the catalog List created image by account ID Get image details Delete created images","title":"OS Factory Service"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/OSFactoryService/#os-factory-service","text":"","title":"OS Factory Service"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/OSFactoryService/#principles-and-concepts","text":"What is OS factory? OS factory is the service that allows you to create your own personalized images fro a standardized GTS image The context : Business applications require security to limit the vulnerabilities associated with OS The standard The default images provided by GTS in catalog are hardened They also contain all security agents and requirements imposed by the CSOs Those images allow to be in compliance with security rules of SG The service The OSF allows you to customize those 'source images' in order to create your own image This new personalized image can include specific components allowing for fast provisioning of, compliant, instances already containing business applications packages","title":"Principles and concepts"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/OSFactoryService/#available-features-and-usages","text":"Features of OSF List of all available images in catalog Create a new image from the source image of the catalog List created image by account ID Get image details Delete created images","title":"Available features and usages"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/blockStorageService/","text":"Block Storage Service Principles and concepts What is Block storage for Openstack? Openstack uses 2 types of storages : Ephemeral storage which is meant for Compute installation. Any data on that area will be wiped when a VM is destroyed Persistent storage which is meant for any data that must survive VM deletion or has it's own lifecycle It allows the addition of performace storage to the Virtual Servers created within the Openstack framework Block storage layer brings to Openstack persistent high performance storage class Block storage what for? Structured data No data sharing between users or computers Accessibility : Only on Openstack environment (VM) and containers Service offers : Tie-fighter (Medium performance) and X-Win (High performance) Protocol : None - Used to create File System within VMs Optional feature : Snapshots, clone, data mobility Available features and usage What can i do with Openstack Block storage? Attach a persistent storage to my Openstack VMs Have a low latency storage available for my applications Build and destroy quickly development and testing environments Move my persistent volume from on VM to another Create a copy of my data","title":"Block Storage Service"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/blockStorageService/#block-storage-service","text":"","title":"Block Storage Service"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/blockStorageService/#principles-and-concepts","text":"What is Block storage for Openstack? Openstack uses 2 types of storages : Ephemeral storage which is meant for Compute installation. Any data on that area will be wiped when a VM is destroyed Persistent storage which is meant for any data that must survive VM deletion or has it's own lifecycle It allows the addition of performace storage to the Virtual Servers created within the Openstack framework Block storage layer brings to Openstack persistent high performance storage class Block storage what for? Structured data No data sharing between users or computers Accessibility : Only on Openstack environment (VM) and containers Service offers : Tie-fighter (Medium performance) and X-Win (High performance) Protocol : None - Used to create File System within VMs Optional feature : Snapshots, clone, data mobility","title":"Principles and concepts"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/blockStorageService/#available-features-and-usage","text":"What can i do with Openstack Block storage? Attach a persistent storage to my Openstack VMs Have a low latency storage available for my applications Build and destroy quickly development and testing environments Move my persistent volume from on VM to another Create a copy of my data","title":"Available features and usage"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/certificateService/","text":"Certificate Service Principles and concepts What is a certificate and why do we need it? A server certificate is a digital certificate issued by a trusted third party (the trusted certified authority) A digital certificate can be compared to an identity card issued by a government, that acts as a trusted third party SG trusted party is named Unipass SSL server certificate is a digital certificate used to initialize a secured connection through secure communication protocols like SSl or TLS between a client and a server or between two servers Secured connection allows data encryption between client and server to avoid unauthorized access or sensitive data to be stolen, as client credit card details or credentials When a secured connection is implemented, your browser displays a locker to point out that you have moved from a non-encrypted / non-secured connection (HTTP) to an encrypted / secured connection (HTTPS) In addition to data encryption, certificate allows authentication as it's bond to : An internet fully qualified domain name An organization Use cases Encrypt data transmitted between a Web application and client browser Encrypt data transmitted between two applications Encrypt data transmitted between an application and database Available features and usages Which features are available? Get an Unipass server certificate List and retrieve existing certificates Be notified when a certificate is about to expire Disable notification for certificates that are no longer used Revoke a certificate in case of security reasons","title":"Certificate Service"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/certificateService/#certificate-service","text":"","title":"Certificate Service"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/certificateService/#principles-and-concepts","text":"What is a certificate and why do we need it? A server certificate is a digital certificate issued by a trusted third party (the trusted certified authority) A digital certificate can be compared to an identity card issued by a government, that acts as a trusted third party SG trusted party is named Unipass SSL server certificate is a digital certificate used to initialize a secured connection through secure communication protocols like SSl or TLS between a client and a server or between two servers Secured connection allows data encryption between client and server to avoid unauthorized access or sensitive data to be stolen, as client credit card details or credentials When a secured connection is implemented, your browser displays a locker to point out that you have moved from a non-encrypted / non-secured connection (HTTP) to an encrypted / secured connection (HTTPS) In addition to data encryption, certificate allows authentication as it's bond to : An internet fully qualified domain name An organization","title":"Principles and concepts"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/certificateService/#use-cases","text":"Encrypt data transmitted between a Web application and client browser Encrypt data transmitted between two applications Encrypt data transmitted between an application and database","title":"Use cases"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/certificateService/#available-features-and-usages","text":"Which features are available? Get an Unipass server certificate List and retrieve existing certificates Be notified when a certificate is about to expire Disable notification for certificates that are no longer used Revoke a certificate in case of security reasons","title":"Available features and usages"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/cloudOrchestrationService/","text":"Cloud Orchestration Service Principles and concepts What is airflow? Airflow is an open source Python framework that allows to programtically crate, schedule and monitor workflows Principles Scalable Airflow has modular architecture and uses a message queue to orchestrate an arbitrary number of workers. Airflow is ready to scale to infinity Dynamic Airflow pipelines are defined in Python, allowing dynamic pipeline generation. You can easily write code to instantiate workflows dynamically Extensible You can define your own operators and extend libraries to fit the level of abstraction that suits your environment Elegant Airflow pipelines are lean and explicit. Parameterization is built into its core using the powerful Jinja templating engine Features Pure Python Use standard Python features to create your workflows, including date time formats for scheduling and loops to dynamically generate tasks. This allows you to maintain full flexibility when building your workflows Useful UI Monito, schedule and manage your workflows through a robust and modern web application. No need to learn old, cron-like interfaces. You always have full insights into the status and logs of completed and ongoing tasks Robust integrations Airflow provides many plug-and-play operators that are ready to execute you tasks on SG clouf platform. They will help you to easily orchestrate your workflows on hybrid (Legacy and XaaS) Easy to use Anyone with Python knowledge can deploy a workflow. Apache Airflow does not limit the scope of your pipelines. You can use it to build ML models, transfer data, manage your infrastructure and more Open source Wherever you want to share your improvements, you can do so by opening a PR. Airflow has many active users who willingly share their experiences Available features and usage Cloud orchestration service is broadly based on two layers Control Plane API It manages the life cycle of Airflow instances by providing an interface allowing CRUD operations Resource Plane It allows the clients to deploy their artifacts and manage his workflows using Airflow API - It allows to deploy your artifacts and execute workflows Flower UI - It allows to monitor and administrate Celery clusters Airflow UI - Its allows to manage Airflow instances","title":"Cloud Orchestration Service"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/cloudOrchestrationService/#cloud-orchestration-service","text":"","title":"Cloud Orchestration Service"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/cloudOrchestrationService/#principles-and-concepts","text":"What is airflow? Airflow is an open source Python framework that allows to programtically crate, schedule and monitor workflows Principles Scalable Airflow has modular architecture and uses a message queue to orchestrate an arbitrary number of workers. Airflow is ready to scale to infinity Dynamic Airflow pipelines are defined in Python, allowing dynamic pipeline generation. You can easily write code to instantiate workflows dynamically Extensible You can define your own operators and extend libraries to fit the level of abstraction that suits your environment Elegant Airflow pipelines are lean and explicit. Parameterization is built into its core using the powerful Jinja templating engine Features Pure Python Use standard Python features to create your workflows, including date time formats for scheduling and loops to dynamically generate tasks. This allows you to maintain full flexibility when building your workflows Useful UI Monito, schedule and manage your workflows through a robust and modern web application. No need to learn old, cron-like interfaces. You always have full insights into the status and logs of completed and ongoing tasks Robust integrations Airflow provides many plug-and-play operators that are ready to execute you tasks on SG clouf platform. They will help you to easily orchestrate your workflows on hybrid (Legacy and XaaS) Easy to use Anyone with Python knowledge can deploy a workflow. Apache Airflow does not limit the scope of your pipelines. You can use it to build ML models, transfer data, manage your infrastructure and more Open source Wherever you want to share your improvements, you can do so by opening a PR. Airflow has many active users who willingly share their experiences","title":"Principles and concepts"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/cloudOrchestrationService/#available-features-and-usage","text":"Cloud orchestration service is broadly based on two layers Control Plane API It manages the life cycle of Airflow instances by providing an interface allowing CRUD operations Resource Plane It allows the clients to deploy their artifacts and manage his workflows using Airflow API - It allows to deploy your artifacts and execute workflows Flower UI - It allows to monitor and administrate Celery clusters Airflow UI - Its allows to manage Airflow instances","title":"Available features and usage"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/cloudPlatformComputeService/","text":"Cloud Platform Compute Service Principles and concepts What is a virtual server A virtual server is a compute instance from images, sized by a flavor, communicating via a network, and secured by authentication mechanism Virtual server : The compute instance itself Network : The network zone of the instance Flavor : Amount of CPU / Disk / RAM of the instance Images : Template of the Operating system Authentication mechanism : Public part of the SSH keypair used to log into the instance For the creation of a virtual server, we have 2 platforms OCS : Openstack Compute Services (Cloud Native No Ops) VCS : VMware Compute Services (Cloud Lift and Shift) Available features and usages What are the mode of consumption of Cloud Platform? Virtual server service is to submit from the Cloud Platform or API. It's available in self-service : no more need to contact the GTS team Virtual server can be consumed in 2 ways Programmatically / via API Enable to automate Virtual server creatives Graphically / via a web portal From DoItNow, it is possible to build and manage these Virtual servers What are the main features of the Virtual server service? Create, list and destroy Virtual Server instances Craete, list and destroy Server Groups Add, list, change and delete tags on Virtual Server instances Add, list, change and delete metadata on Virtual Server instances List available subnets for Virtual Server instances Reboot or start a stopped Virtual Server instance Get the console output of my Virtual Server instance Resize my Virtual Server instance","title":"Cloud Platform Compute Service"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/cloudPlatformComputeService/#cloud-platform-compute-service","text":"","title":"Cloud Platform Compute Service"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/cloudPlatformComputeService/#principles-and-concepts","text":"What is a virtual server A virtual server is a compute instance from images, sized by a flavor, communicating via a network, and secured by authentication mechanism Virtual server : The compute instance itself Network : The network zone of the instance Flavor : Amount of CPU / Disk / RAM of the instance Images : Template of the Operating system Authentication mechanism : Public part of the SSH keypair used to log into the instance For the creation of a virtual server, we have 2 platforms OCS : Openstack Compute Services (Cloud Native No Ops) VCS : VMware Compute Services (Cloud Lift and Shift)","title":"Principles and concepts"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/cloudPlatformComputeService/#available-features-and-usages","text":"What are the mode of consumption of Cloud Platform? Virtual server service is to submit from the Cloud Platform or API. It's available in self-service : no more need to contact the GTS team Virtual server can be consumed in 2 ways Programmatically / via API Enable to automate Virtual server creatives Graphically / via a web portal From DoItNow, it is possible to build and manage these Virtual servers What are the main features of the Virtual server service? Create, list and destroy Virtual Server instances Craete, list and destroy Server Groups Add, list, change and delete tags on Virtual Server instances Add, list, change and delete metadata on Virtual Server instances List available subnets for Virtual Server instances Reboot or start a stopped Virtual Server instance Get the console output of my Virtual Server instance Resize my Virtual Server instance","title":"Available features and usages"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/fileStorageService/","text":"File Storage Service Principles and concepts What is file storage? File storage is a Cloud Platform service which provides storage over network (NAS) It allows applications to share data between multiple Vms (OCS/VCS) It is designed to meet business requirements (costs optimized, high performance, high availability within region or cross regions) It is API driven (create, delete, size, etc.) It also comprises of advanced features such as user triggered snapshots, consistency group, encryption and more File storage manages both structured and unstructured data and is an ideal solution for workloads that rely on shared file systems for use cases like Transactional applications Database live applications Database dumps Business connectivity Disaster recovery Containers Big data What does file storage have? Data sharing between users or computers with high performance and low latency Accessibility : Everywhere (on internal SG network - Not available on DMZ / Web / Cloud cells) Suitable for both Structured and Unstructured data Protocol : NFSv4 and above Service offers : Premium offer without Replication, Premium offer with Mono-region Replication, Premium offer with Cross-region Replication Optional features : Replication, Snapshots, Clone, Failover, Grow, etc. Available features and usage Features available today Create a Mono-AZ resilient file system that can be shared across multiple VM's using NFSv4 Protocol Create a consistency group for logical grouping of file systems List and delete File systems List and delete consistency groups Grant and revoke access on file system to compute hosts Create / List / Delete a Snapshot of consistency group","title":"File Storage Service"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/fileStorageService/#file-storage-service","text":"","title":"File Storage Service"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/fileStorageService/#principles-and-concepts","text":"What is file storage? File storage is a Cloud Platform service which provides storage over network (NAS) It allows applications to share data between multiple Vms (OCS/VCS) It is designed to meet business requirements (costs optimized, high performance, high availability within region or cross regions) It is API driven (create, delete, size, etc.) It also comprises of advanced features such as user triggered snapshots, consistency group, encryption and more File storage manages both structured and unstructured data and is an ideal solution for workloads that rely on shared file systems for use cases like Transactional applications Database live applications Database dumps Business connectivity Disaster recovery Containers Big data What does file storage have? Data sharing between users or computers with high performance and low latency Accessibility : Everywhere (on internal SG network - Not available on DMZ / Web / Cloud cells) Suitable for both Structured and Unstructured data Protocol : NFSv4 and above Service offers : Premium offer without Replication, Premium offer with Mono-region Replication, Premium offer with Cross-region Replication Optional features : Replication, Snapshots, Clone, Failover, Grow, etc.","title":"Principles and concepts"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/fileStorageService/#available-features-and-usage","text":"Features available today Create a Mono-AZ resilient file system that can be shared across multiple VM's using NFSv4 Protocol Create a consistency group for logical grouping of file systems List and delete File systems List and delete consistency groups Grant and revoke access on file system to compute hosts Create / List / Delete a Snapshot of consistency group","title":"Available features and usage"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/objectStorageService/","text":"Object Storage Service Principles and concepts What is object storage? Object Storage is a way to store data without depending on a file system structure which makes it genuinely cross platform As well as objects, related description of that object, referred as metadata, are stored. This makes large type of data easy to handle accross various systems Using AWS S3 (Simple Storage Service) - now a defacto standard - data are widely accessible using simple HTTPS queries using IAM for authentication Objects are stored within containers referred as buckets Use cases What are the best use cases of Object Storage? Unstructured data such as media and application files (like archive files, picture) Data sharing between users and computers Main characteristics of the offer Accessibility : Everywhere Service offers : Toad (no multi AZ resiliency) and Yoshi (multi resiliency on same region) Access protocol : S3 (through HTTPS) Optional features : Versioning, life cycle, data mobility (replication) Module 3 : Available features and usages Standard and low flavors are differentiated by data protection level (mono or dual AZ) Object Storage offer is available in several regions No limitations on the number of objects within a bucket","title":"Object Storage Service"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/objectStorageService/#object-storage-service","text":"","title":"Object Storage Service"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/objectStorageService/#principles-and-concepts","text":"What is object storage? Object Storage is a way to store data without depending on a file system structure which makes it genuinely cross platform As well as objects, related description of that object, referred as metadata, are stored. This makes large type of data easy to handle accross various systems Using AWS S3 (Simple Storage Service) - now a defacto standard - data are widely accessible using simple HTTPS queries using IAM for authentication Objects are stored within containers referred as buckets","title":"Principles and concepts"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/objectStorageService/#use-cases","text":"What are the best use cases of Object Storage? Unstructured data such as media and application files (like archive files, picture) Data sharing between users and computers Main characteristics of the offer Accessibility : Everywhere Service offers : Toad (no multi AZ resiliency) and Yoshi (multi resiliency on same region) Access protocol : S3 (through HTTPS) Optional features : Versioning, life cycle, data mobility (replication) Module 3 : Available features and usages Standard and low flavors are differentiated by data protection level (mono or dual AZ) Object Storage offer is available in several regions No limitations on the number of objects within a bucket","title":"Use cases"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/securityGroupService/","text":"Security Group Service Principles and concepts What is micro segmentation? Micro segmentation is a security solution that enables fine-grained network filtering policies to be assigned to datacenter applications down to the workload level. With micro segmentation, security settings can be tailored to different types of traffic, creating policies that limit network and application flows between workloads to those that are explicitly permitted. The goal is to decrease the network attach surface. By applying the segmentation rules down to the micro level of the workload or application, the risk of an attacker moving from one compromised workload or app to another is reduced Micro segmentation is the best way to prevent the spread if threats inside your data centres and Cloud environment What is security group? A security group is a set of firewall rules for your instance to control incoming and outgoing traffic Inbound rules control the incoming traffic to your VM instance, and outbound rules control the outgoing traffic from your VM instance When you launch an instance, you can specify one or more security groups; otherwise, the default security group is applied You can modify the rules for a security group at any time. New and modified rules are automatically appplied to all instances that are associated with the security group Unlike network access control lists (NACLs), there are no 'Deny' rules. If there is no rule that explicitly permits a particular data packet, it will be dropped Only allow the access that is needed for your application or service, and do not apply overly permissive access as this can result in future security breaches and vulnerabilities Available features and usages Features available today Manage security group for an Account : Create a security group Fetch a security group Update a security group Delete security group Manage firewall rules of security group of an Account Create firewall rule in a security group Fetch a firewall rule Delete firewall rules Attach or Detach a Security Group to an OCS VM Debug flows for a given Account","title":"Security Group Service"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/securityGroupService/#security-group-service","text":"","title":"Security Group Service"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/securityGroupService/#principles-and-concepts","text":"What is micro segmentation? Micro segmentation is a security solution that enables fine-grained network filtering policies to be assigned to datacenter applications down to the workload level. With micro segmentation, security settings can be tailored to different types of traffic, creating policies that limit network and application flows between workloads to those that are explicitly permitted. The goal is to decrease the network attach surface. By applying the segmentation rules down to the micro level of the workload or application, the risk of an attacker moving from one compromised workload or app to another is reduced Micro segmentation is the best way to prevent the spread if threats inside your data centres and Cloud environment What is security group? A security group is a set of firewall rules for your instance to control incoming and outgoing traffic Inbound rules control the incoming traffic to your VM instance, and outbound rules control the outgoing traffic from your VM instance When you launch an instance, you can specify one or more security groups; otherwise, the default security group is applied You can modify the rules for a security group at any time. New and modified rules are automatically appplied to all instances that are associated with the security group Unlike network access control lists (NACLs), there are no 'Deny' rules. If there is no rule that explicitly permits a particular data packet, it will be dropped Only allow the access that is needed for your application or service, and do not apply overly permissive access as this can result in future security breaches and vulnerabilities","title":"Principles and concepts"},{"location":"office/cloudPlatformProfessionalServices/intermediate/coreServicesDiscovery/securityGroupService/#available-features-and-usages","text":"Features available today Manage security group for an Account : Create a security group Fetch a security group Update a security group Delete security group Manage firewall rules of security group of an Account Create firewall rule in a security group Fetch a firewall rule Delete firewall rules Attach or Detach a Security Group to an OCS VM Debug flows for a given Account","title":"Available features and usages"},{"location":"office/myLearning/bascisOfLevel1PermanentControl/","text":"Basics of Level 1 Permanent Control Reminder of the principles of Permanent Control L1C Definition Internal Control In France, the main principles of internal control have been expressed in law by the decree of November 3rd, 2014 recently complemented by the decree of February 25th, 2021. The SG Code describes the main internal control principles and procedures that apply to the Societe Generale Group in compliance with this regulatory framework. Internal control consists of both permanent control and periodic control (audit and inspection) Level 1 permanent control (L1C) contributes to containing non-financial risks to the level accepted in the Group's risk appetite. Level 2 permanent control(L2C) and periodic control (or level 3) are intended to verify the correct and continuous functioning of level 1 permanent control, but in no way replace the first one Permanent Control The 3 lines of defense model, defining the distribution of roles and responsibilities for controls and risk management in on organisation, is applied at Societe Generale as follows: The third line of defense (LOD3) consists of Inspection and Internal Audit function. It is strictly independent of the first two lines of defense and ensures, in particular, a periodic review of the first two weeks The second line of defense (LOD2) consists of Risk, Finance and Compliance functions The other BU/SU are the first line of defense (LOD1) DGLE/PIC is responsible for the permanent control framework and coordinates the Group's internal control. The Director of DGLE/PIC also has a functional authority over the heads of the Level 2 control teams Internal Control Framework Permanent Control Framework LOD1 Business Units (L1C) Service Units (L1C) (Except those in charge of LOD2) LOD2 (All L2C in LOD2 reports to DGLE/PIC) Risk function (L1C and L2C) Finance function (L1C and L2C) Compliance function (L1C and L2C) Periodic Control LOD3 IGAD (L1C) (Internal Inspection and Audit function) L1C Objective The objective of Level 1 permanent control framework is to protect the bank by contributing to the control/mitigation of its non-financial risks The permanent control framework therefore contributes fully to protecting the bank, its financial performance, and its reputation Key Stakeholders The operational staff and their managers They are responsible: Identifying, accessing, and controlling the risks Deploying the control framework within the area of responsibility Disassembling the risk and control culture within their teams Transversal functions (IS/ISS, legal, RH, communication, etc.) They contribute to the LOD2 for the definition of: Norms, standards and procedures applicable to permanent control frameworks in their area of expertise Control needs and provide expertise on the transversal analysis of the deployment of level 1 permanent control in their area of expertise to DGLE/PIC and the LOD2 They may also be consulted via the LOD2s by the first line of defense concerning the implementation and operational application of the principles of protecting/securing the activity in their area of expertise The second line of defense (LOD2:RISQ, CPLE and DFIN) The LOD2s define the Group norms and principles for securing operational risk in their respective areas. They support the first line of defense(LOD1) The level 2 control teams (L2C), within LOD2, are independent teams that contribute through a second level of assesssment to their effectiveness of the level 1 control framework CORO (Control and Operational Risk Officer) The CORO and the OSM/ORM/R2L1C are responsible for: Implementing, coordinating, monitoring, challenging, and leading the level 1 control framework Controlling the operational risks of their BU and SU The department in charge of the permanent control and internal control coordination (DGLE/PIC) Is responsible for the permanent control framework (definition of the Group's norms and standards for level 1(L1Cs) and level 2 (L2Cs) control, coordination of the network of central COROs and L2Cs,etc.) and coordinates the Group's internal control. Risk-based approach The permanent control system is applied in priority to significant risks, so it is necessary to adopt a risk-based approach The permanent control framework must be proportionate to the severity of the risks to which the Group is exposed The ambition of this framework is to efficiently contain non-financial risks, the possible materialisation of which have a significant impact on the financial situation and/or reputation of the Group, or of a Group entity Regular assesssment of these risks is therefore necessary to keep them at the level accepted in the Group's risk appetite The regular assesssment of risks and controls is done through Risk and Control Self-Assessment (RCSA) exercises, the following way: Each of our activities has its own Intrinsic risks (II) For which Risk Management Frameworks are put in place (RMFs) according to the risk appetite To limit our exposure to Residual Risk (RR) The regular assesssment of risks and controls, in addition to being a regulatory obligation, is an essential part of the permanent control framework. In other words, for each manager, the RCSA exercise amounts to an assesssment of their residual risk. To do this, he/she assesses his/her intrinsic risk and the soundness of his/her risk control framework These assesssments (low, moderate, important, critical) also make it possible to prioritize/proportion the framework on risks carrying a significant impact. APRC framework As part of the Group's internal control and operational risk management framework Societe Generale has set up a permanent control referentiel, known as APRC, which lists: All of activities (A) of the Group Their processes (P) TThe main risks (R) associated with these P's (exclusively those of the Group's operational risk taxonomy) The control needs (C) necessary to reduce these risks(listed in the Normative Controls Library : NCL) The APRC referentiel provides an overall view, at Group level, of the permanent control framework, independently of the organizational structure. It considers the various constraints (operational, regulatory, etc.) that weigh on all activities in order to limit operational risks. This referentiel is used by the entire Group and its constant improvement is achieved through the active participation of all It applies to all Legal and Regulatory Entities (ELR) identified in the Scope of deployment of the permanent control framework of the Societe Generale Group Continuous improvement loop Strategy and risk appetite Processes (P) Risks (R) Controls (C) Losses and incidents Plans of actions Reporting and steering The whole picture must be reported so that management (all the way upto the top management and the supervisory body) can ensure that activities are carried out in accordance with the strategy and risk appetite and can decide on remedial actions within its authority. The entire framework is managed with a view to continuous improvement. The existence of these reports is a major regulatory requirement All steps are subject to continuous improvement, which we will check at the end of the training. Chapter summary: In this section, we have discussed the basic elements of internal control, through the definitions, objectives and stakeholders of different processes and reference framework: Internal control encompasses all the means implemented to contribute to the control of the company risks; in this way it aims to protect the bank Level 1 permanent control contributes to containing all non-financial risks; the permanent control framework must be deployed throughout the Societe Generale Group; i.e., including all subsidiaries and branches, joint ventures, etc. The permanent control framework is made up of six iterative stages : processes, risks, controls, losses and incidents, plans of actions, reporting and steering The risk-based approach is to be preferred, and the permanent control framework is to be applied as a priority to the significant risks to which the Group is exposed The stakeholders in the framework: the first line of defense(LOD1) made up of operational staff and their managers, the COROs, the transversal functions; the second line of defense (LOD2), periodic control (LOD3) and the management in charge of the permanent control framework and internal control coordination (DGLE/PIC) The APRC referential : Activities, Processes, Risks, Control needs Designing a Control Plan Blueprint : general principles The implementation of the APRC approach, for each entity of the Group included in the deployment scope, and at the appropriate level of detail, is done through a 'Blueprint'. Let's see what it consists of: The blueprint is the instrument for selecting the content of the activities and processes in the area of responsibility The blueprint is the \"golden source\" to be used when organising and performing exercises related to the control of non-financial risks (implementation of the APRC approach, risk management [RCSA, COMPASS, etc.], collection of losses and incidents, etc.) Based on the selected activities and processes, the blueprint inherits a level 1 control plan. The control plan makes it possible to determine the control needs applicable to the scope of responsibility, for the control of non-financial risks Control Plan : General principles Building a blueprint requires selecting from the APRC reference framework: The activities you are responsible for The processes attached to the activities applicable to you The applicable controls contributing to the control of risks in these processes In short, APRC allows us to say : we know what we are doing, we know whats risks we face, and we know what controls to put in place to manage these risks The blueprint is the instrument used to select the activities and processes related to the operations contained in a given scope of responsibility Based on this description, and depending on the activities and processes selected, the blueprint inherits a control plan to be deployed from the APRC referentiel The risk control framework is therefore the implementation of this control plan Chapter summary In this section, we have discussed the elements of a blueprint and its usefulness in the context of permanent control. We have also discussed the principles of the control plan and the qualifications of the process and the control need: The blueprint is the instrument for selecting the content of the scope of responsibility for controlling non-financial risks The blueprint is the golden source to be used when organising and conducting non-financial risk management exercises The person responsible for a perimeter establishes a blueprint (at least one) describing the entire perimeter Controls contribute to containing the risks of the processes associated with the activities applicable to you and for which you are responsible Designing Level 1 Controls Reminder of the different type of L1Cs Let's look at the different frameworks for level 1 controls: GPS is the Group's default tool which covers the vast majority of the Group's level 1 controls. It is available with all the functionalities required to deploy a permanent control, including a library of reference controls (generic controls). It is deployed in all BUs/SUs Other tools : Based on business control tools or business management applications can also be used if they meet the Group's requirements (eg., ARCHER, MORSE+, GTC, etc.) Committees : Committees with formalized and approved terms of reference including controls can be extremely efficient as a risk mitigation measure (eg. New Product Committee) Committees or work group whose terms of reference have been defined, approved, reviewed, and published Example : New Product Committee Incident Committee \"IT-Driven\" automated controls : Some controls can be automated and integrated into tools to prevent the occurence of an operational risk or to detect its possible materialization (eg. input control in a form, blocking control) System and (semi) automated application of a rule within a business process/flow. Example : Automatic calculation of the effective annual interest rate List of pending/blocked transactions Alerts on transactions with unauthorized counterparties In an organizational and governance framework that can help to better secure the activity (eg. Chinese wall) and that it is interesting to highlight Policies, instructions, organizational charts, frameworks, etc. published and regularly updated. Example : Published organizational chart Signed Code of Conduct Let us continue by exploring the main elements of the controls Objectives Reminder : Their purpose is to ensure, where justified, that activities are carried out correctly, while remaining proportionate to the risks The objectives of L1Cs Ensure the quality and proper execution of processes. Mitigate our risks through automated controls, in particular, through automated blocking controls, i.e., preventive controls. Identify situations where the risk has already materialised through detective controls To limit the impact of the materialisation of a risk, i.e., through corrective controls Ensuring the proper application of existing procedures and the control of all risks relating to processes, operations and/or accounts Alerting the hierarchy in the event of anomalies or malfunctions. Characteristics Depending on the degree of automation of the control procedures Manual controls / semi-automated controls / automated controls Depending on the person carrying out the controls Control carried out by a manager, \"4 eyes\" control (carried out by a third party) Depending on the control's operating mode Comparison of a situation with the applicable procedure, comparison of an operation or data with a referentiel, with a range of expected or plausible values, with a target (result, budget, etc.) with the same operation or data from a third party (confirmation) Examples Some examples of automated (\"IT-driven\") controls Blocking control in a tool Impossiblity to continue the process of customer credit origination until all fields of the KYC are completed Restriction of loan approval Up to the maximum allowed per delegation/limit Systematic requirement in a workflow for approval by a dedicated party Automatic calculation of the effective annual interest rate Segregation of duties built into/configured in a system (i.e., staff approving the invoice cannot change the supplier's information on the GNI, etc.) Chapter summary In this section, we have recapitulated the different types of L1Cs as well as their key principles : Various types of first-level controls can be used to contain the risks involved (eg. IT-driven, committee, organizational and governance control sheets) These controls must be formalized in specialized tools (eg. GPS) or described sheets in myAPRC The controls must have specific characteristics as indicated in the L1Cs methodological guide : in particular, it is mandatory to provide the frequency, the sample, the scale of criticality of anomalies, the control rating scale It is imperative to correctly map each control needs in its blueprint and qualify all possible risks on all the control needs in the blueprint The stakeholders The operational staff and the managers of the L1Cs teams are involved in the instantiation of the controls The experts of LOD1 and LOD2 are involved in updating the NCL, i.e., the control needs in the referentiel The L2C and LOD3 (periodic control) teams review and challenge the implementation of the controls that LOD1 has made locally Common key principles for the execution of 1st level controls Guidelines All deployed level 1 controls must be executed (except in the case of \"No Migration\"). It is therefore essential to ensure that the controls are carried out on a permament basis through a precise work organization Compliance with procedures Compliance with the instructions of the control design, frequency, sampling, control points, type of evidence, etc. Precise formalization of the execution of the control and justification of the sample if necessary Formalization of execution in the Group's tools The execution of a control must be formalized in one of the Group tools The execution of L1Cs must be linked to the permanent control referentials (APRC...) Auditability The outcome of a control must be auditable within 5 years of its implementation, i.e., the supporting documents must be kept throughout this period Reporting of anomalies and action plans Scoring of anomalies in accordance with the explanations provided in the control procedure Reporting of anomalies in the permanent control tools Formalization of a mandatory action plan, in the L1C tools for high and very high criticality anomalies Compliance with procedures The quality of the control and the validity of the analysis of the results depend on the relevance of the sampling method. The creators of level 1 controls must ensure that the sampling requested complies with the following principles Responsibility The sampling instructions available in the controls within their scope are appropriate and proportionate to the volumes and risks covered by the control Methods Sample items are selected either in a discretionary (non-statistical) manner based on a particular risk factor (eg., high intrinsic risk level), or in a random (or statistical) manner using mathematical / statistical methods to determine the sample size Freedom of choice The performer of the control must exercise his freedom of choice : he can decide to carry out exhaustive reviews when the level of risk requires it (even if the control procedure allows control based on a sample). Indeed, because of his expertise and knowledge of his activity, the control performer is best able to categorize the \"population\" that is subject to the control, and thus to proportion the control means to the level of risk attached to this population Reporting of anomalies and action plans Let's continue with the reporting of anomalies and action plans. An anomaly must be described and qualified; any anomaly described must be corrected. An anomaly is an error detected or a difference between an expected result and a result obtained during the execution of a control. It can be the result of: A dysfunction with proven losses (a real loss has been noted) A dysfunction with proven impacts but without financial consequences (the risk has materialised but has not resulted in a financial loss) A dysfunction detected without (or before) materialisation of the risk (without proven impact) In the cases, the incident reporting instructions of the operational incident tools will be followed, in compliance with the thresholds defined by the Group The objective of anomaly detection is to be able to make the necessary corrections to prevent recurrence and to ensure that action plans are drawn up It is essential to declare L1C anomalies (including those corrected before the control is finalized) and describe them in detail, so that their impact is clearly explained All this information allows the launch of action plans whose objective is the correction of anomalies and the improvement of processes. The criticality of anomalies must be defined in accordance with Group rules to allow for a uniform analysis of process dysfunctions throughout the Group As a reminder, the Group has adopted a four-level scale for rating level 1 control anomalies: \"Very high\" : Risk for the Societe Generale Group \"High\" : Risk for a BU/SU \"Moderate\" : Risk for an entity or several departments \"Low\" : Risk for a department High and very high criticality anomalies must be subject to an action plan and followed up by General Management Formalization of execution Next comes traceability, with the formalization of execution in the Group's tools The execution of a control must be captured in the central systems (Group datalake) to indicate that the planned risk control framework is in place and functioning Furthermore, it must be possible to link this execution to a blueprint and therefore to the APRC referentiel Auditability Finally, we conclude out presentation of the main principles of control implementation with auditability Formalization of the execution (operating procedure, results) is mandatory All of this information must be traceable, auditable and accessible to the Audit/Inspection, level 2 control teams, and DGLE/PIC, as well as to supervisory authorities These elements must be kept for a minimum of five years, unless otherwise specified By complying with local regulations imposed by the regulator (eg., FATCA regulations require a minimum retention period of 6 years) If specific recommendations have been issued in this regard by the General Inspection and Audit Department Chapter summary In this section, we have discussed the general principles as well as the details of each approach : compliance with procedures, reporting of anomalies and action plans, formalization of execution and audutability In respecting procedures, particular attention must be paid to sampling, which must therefore respect certain principles : responsibility, methods, freedom of choice There are two general approaches to sampling : discretionary and random The performer of the control retains his free will and can decide to carry out exhaustive reviews when the level of risk requires it, even if the control procedure authorizes the control based on a sample An anomaly is an error detected or a difference between an expected result and a result obtained during the performance of a control. As such, a L1Cs anomaly can correspond to dysfunctions with proven losses, dysfunctions with proven impacts, dysfunctions detected without materialization of the risk For all significant anomalies detected, it is essential to define and implement an actio plan to ensure that the dysfunction does not recur,these plans also contribute the continuous improvement of our processes Anomalies, and more particularly high and very high criticality anomalies, must be described in detail in order to clearly explain the impact and the stakes Monitoring permament control Principle of reporting As we saw in the introduction, the entire permanent control framework must be monitored by means of reports so that management can ensure that activities are carried out in accordance with the strategy and risk appetite defined by the Group. On this basis, management should be able to take remedial action if necessary. Lets look at their principles and how these reports are set up The objective of permanent control reporting is to capture the results of controls at the finest level, by cross-referencing them with the elements of the non-financial risk management framework, in order to detect significant areas af risk and possible remedial or corrective actions, to summarize them and to inform management and the supervisory bodies Reporting methodology The reporting is done according to a specific methology which we will see in detail Manager, staff Analysis level 1 Performing level 1 control - Daily risk management : Control rating, creation of anomalies, of action plans The level 1 controls that are correctly deplyed and carried out daily throughout the Group make it possible to protect the bank day-to-day and thus to detect and prevent risks The formalization of these controls allows their analysis at the following levels of analysis CORO, ORM, RCL1C Analysis level 2 Daily analysis by the operational risk management teams using the KRI and business intelligence tools provided The data relating to the results of these controls are stored in the datalake. This data can then be used daily by everyone to perform the necessary reports and analyses These analyses are carried out by the operational risk management teams who manage the framework daily BU/SU managers Analysis level 3 Level 1 permanent control certification by the BU/SU managers to the General Management The deployment of level 1 controls, the results of their execution, as well as the analyses made of them, are brought to the attention of the BU/SU management. With the support of the CORO, the BU/SU manager is informed of, analyses, and certifies the results of the execution of the L1Cs in his or her area of supervision. The certification of level 1 control results by management is a quaterly exercise A dashboard is then compiled and challenged every six months by the BU/SU manager at the BU/SU Internal Control Coordination Committee DGLE Analysis level 4 Permanent control dashboard. Presentation of the status of the framework to the Group Internal Control Coordination Committee, General Management and the CACI The elements of L1Cs certification are integrated into the Group's permament control dashboard which compares them with the other non-financial risk management frameworks : the RCSA, losses and incidents, the results of L2C and IGAD missions, etc., in order to detect the priority areas for improvement of the framework, as part of a continuous improvement process. This exercise is also carried out quaterly This dashboard is presented to General Management at the Group Internal Control Coordination Committee meeting, to enable monitoring of the framework and supervision of the Group's internal control. After review and validation, the dashboard is then presented to the Audit and Internal Control Committee DGLE to CACI and ACPR Analysis level 5 Report on Internal Control (RCI) to be reviewed by the GICCC, validated by the General Management, presented to the CACI and the Board of Directors, and communicated to the ACPR and the ECB Finally, the Group produces an annual consolidated report on internal control, known as the RCI. This document presents a transversal analysis (by the experts of LOD1 and LOD2) of all types of risks by comparing the various elements of the framework : losses, incidents, controls, RCSA, etc. It also includes the main results of the missions carried out by LOD3 This report is presented to the CACI (Audit and Internal Control Committee) after neing examined and validated by General Management during the GICCC. It is also sent to the Group's supervisory authorities (ACPR and ECB) Each of the reporting stages described earlier makes possible to assess the internal control framework and to decide on actions to improve this framework to enhance risk management. The formalization of the results of level 1 controls is therefore a key step in the process of continuous improvement of the Group's permanent control framework and allows transparent information to be transmitted to all levels of management, including the General Management and the Board of Directors Chapter summary In this section, we have discussed the monitoring of permament control The permanent control monitoring system enables Management to ensure that activities are carried out in accordance with the strategy and risk appetite. It enables it to decide on remedial actions and to exercise its supervision of internal control. Permanent control reporting makes it possible to capture control results at the finest level, by cross-referencing them with the elements of the non-financial risk management system, in order to detect significant areas of risk and the actions to be taken to effectively contain these risks at the accepted level The formalization and certification of the results of the execution of level 1 controls is one of the key stages in the process of continuous improvement of the Group's permanent control system,; it makes possible to transmit transparent information to all levels of management and to the supervisory authorities Continuous improvement if the permament control framework Continuous improvement loop and articulation with losses/incidents and RCSA The permament control framework operates in an iterative way. Each component of the framework is fed by the other components, in a continuous improvement logic, so that the framework is agile and adaptable to the evolving risk profile faced by the Group The level 1 control framework is embedded in the non-financial risk management system and contributes to containing risks at the level accepted in the Group's risk appetite. The dynamics of continuous improvement therefore comes from you because permanent control is everyone's responsibility Anomalies can be detected at all levels, operational, managers, level 2 controller, LOD2 expert, periodic controller (IGAD) or supervisory authority All anomalies detected (a process failure, a significant loss, etc.) must be the subject of an action plan to ensure that the dysfunction does not repeat itself. At least for significant anomalies, a follow-up of the action plan is compulsory in a dedicated permament control tool If deemed necessary, the action plan defined may be extended to other entites to ensure that the anomaly does not occur elsewhere in the Group. The permament control framework is deployed throughout the Group (subsidiaries and branches as well as the various organizational structures existing within the scope, such as joint ventures) If significant anomalies are detected, the stakeholders in the permament control framework must react. Improvement actions to enhance the framework can be taken at several levels: At the General Management level, which will identify actions based on the visibility given to the framework by the permanent control dashboard to ensure compliance with the risk appetite defined by the Group AT BU/SU management level, the manager assesses his or her level of residual risk based on \"Risk and Control Self Assessment\" (RCSA) or Compass, the results of L1Cs, incidents and losses, audit reports and the existing L1C framework At your level : through the implementation of procedures, recommendations issued by your management, level 2 control, periodic control (IGAD), supervisory authorities Chapter summary In this section, we have discussed the continuous improvement loop: The permanent control framework must be deployed throughout the Societe Generale Group, i.e., all consolidated subsidiaries and branches, as well as the various organizational structures existing within this scope, such as joint ventures The permanent control framework operates in an iterative way, as part of a continuous improvement process All anomalies detected (a process failure, a significant loss, etc.) must be the subject of an action plan to ensure that the dysfunction does not occur The residual risk remaining after the implementation of the permanent control framework must be compliant with the guidelines laid down by the Group's risk appetite","title":"Basics of Level 1 Permanent Control"},{"location":"office/myLearning/bascisOfLevel1PermanentControl/#basics-of-level-1-permanent-control","text":"","title":"Basics of Level 1 Permanent Control"},{"location":"office/myLearning/bascisOfLevel1PermanentControl/#reminder-of-the-principles-of-permanent-control","text":"L1C Definition Internal Control In France, the main principles of internal control have been expressed in law by the decree of November 3rd, 2014 recently complemented by the decree of February 25th, 2021. The SG Code describes the main internal control principles and procedures that apply to the Societe Generale Group in compliance with this regulatory framework. Internal control consists of both permanent control and periodic control (audit and inspection) Level 1 permanent control (L1C) contributes to containing non-financial risks to the level accepted in the Group's risk appetite. Level 2 permanent control(L2C) and periodic control (or level 3) are intended to verify the correct and continuous functioning of level 1 permanent control, but in no way replace the first one Permanent Control The 3 lines of defense model, defining the distribution of roles and responsibilities for controls and risk management in on organisation, is applied at Societe Generale as follows: The third line of defense (LOD3) consists of Inspection and Internal Audit function. It is strictly independent of the first two lines of defense and ensures, in particular, a periodic review of the first two weeks The second line of defense (LOD2) consists of Risk, Finance and Compliance functions The other BU/SU are the first line of defense (LOD1) DGLE/PIC is responsible for the permanent control framework and coordinates the Group's internal control. The Director of DGLE/PIC also has a functional authority over the heads of the Level 2 control teams Internal Control Framework Permanent Control Framework LOD1 Business Units (L1C) Service Units (L1C) (Except those in charge of LOD2) LOD2 (All L2C in LOD2 reports to DGLE/PIC) Risk function (L1C and L2C) Finance function (L1C and L2C) Compliance function (L1C and L2C) Periodic Control LOD3 IGAD (L1C) (Internal Inspection and Audit function) L1C Objective The objective of Level 1 permanent control framework is to protect the bank by contributing to the control/mitigation of its non-financial risks The permanent control framework therefore contributes fully to protecting the bank, its financial performance, and its reputation Key Stakeholders The operational staff and their managers They are responsible: Identifying, accessing, and controlling the risks Deploying the control framework within the area of responsibility Disassembling the risk and control culture within their teams Transversal functions (IS/ISS, legal, RH, communication, etc.) They contribute to the LOD2 for the definition of: Norms, standards and procedures applicable to permanent control frameworks in their area of expertise Control needs and provide expertise on the transversal analysis of the deployment of level 1 permanent control in their area of expertise to DGLE/PIC and the LOD2 They may also be consulted via the LOD2s by the first line of defense concerning the implementation and operational application of the principles of protecting/securing the activity in their area of expertise The second line of defense (LOD2:RISQ, CPLE and DFIN) The LOD2s define the Group norms and principles for securing operational risk in their respective areas. They support the first line of defense(LOD1) The level 2 control teams (L2C), within LOD2, are independent teams that contribute through a second level of assesssment to their effectiveness of the level 1 control framework CORO (Control and Operational Risk Officer) The CORO and the OSM/ORM/R2L1C are responsible for: Implementing, coordinating, monitoring, challenging, and leading the level 1 control framework Controlling the operational risks of their BU and SU The department in charge of the permanent control and internal control coordination (DGLE/PIC) Is responsible for the permanent control framework (definition of the Group's norms and standards for level 1(L1Cs) and level 2 (L2Cs) control, coordination of the network of central COROs and L2Cs,etc.) and coordinates the Group's internal control. Risk-based approach The permanent control system is applied in priority to significant risks, so it is necessary to adopt a risk-based approach The permanent control framework must be proportionate to the severity of the risks to which the Group is exposed The ambition of this framework is to efficiently contain non-financial risks, the possible materialisation of which have a significant impact on the financial situation and/or reputation of the Group, or of a Group entity Regular assesssment of these risks is therefore necessary to keep them at the level accepted in the Group's risk appetite The regular assesssment of risks and controls is done through Risk and Control Self-Assessment (RCSA) exercises, the following way: Each of our activities has its own Intrinsic risks (II) For which Risk Management Frameworks are put in place (RMFs) according to the risk appetite To limit our exposure to Residual Risk (RR) The regular assesssment of risks and controls, in addition to being a regulatory obligation, is an essential part of the permanent control framework. In other words, for each manager, the RCSA exercise amounts to an assesssment of their residual risk. To do this, he/she assesses his/her intrinsic risk and the soundness of his/her risk control framework These assesssments (low, moderate, important, critical) also make it possible to prioritize/proportion the framework on risks carrying a significant impact. APRC framework As part of the Group's internal control and operational risk management framework Societe Generale has set up a permanent control referentiel, known as APRC, which lists: All of activities (A) of the Group Their processes (P) TThe main risks (R) associated with these P's (exclusively those of the Group's operational risk taxonomy) The control needs (C) necessary to reduce these risks(listed in the Normative Controls Library : NCL) The APRC referentiel provides an overall view, at Group level, of the permanent control framework, independently of the organizational structure. It considers the various constraints (operational, regulatory, etc.) that weigh on all activities in order to limit operational risks. This referentiel is used by the entire Group and its constant improvement is achieved through the active participation of all It applies to all Legal and Regulatory Entities (ELR) identified in the Scope of deployment of the permanent control framework of the Societe Generale Group Continuous improvement loop Strategy and risk appetite Processes (P) Risks (R) Controls (C) Losses and incidents Plans of actions Reporting and steering The whole picture must be reported so that management (all the way upto the top management and the supervisory body) can ensure that activities are carried out in accordance with the strategy and risk appetite and can decide on remedial actions within its authority. The entire framework is managed with a view to continuous improvement. The existence of these reports is a major regulatory requirement All steps are subject to continuous improvement, which we will check at the end of the training. Chapter summary: In this section, we have discussed the basic elements of internal control, through the definitions, objectives and stakeholders of different processes and reference framework: Internal control encompasses all the means implemented to contribute to the control of the company risks; in this way it aims to protect the bank Level 1 permanent control contributes to containing all non-financial risks; the permanent control framework must be deployed throughout the Societe Generale Group; i.e., including all subsidiaries and branches, joint ventures, etc. The permanent control framework is made up of six iterative stages : processes, risks, controls, losses and incidents, plans of actions, reporting and steering The risk-based approach is to be preferred, and the permanent control framework is to be applied as a priority to the significant risks to which the Group is exposed The stakeholders in the framework: the first line of defense(LOD1) made up of operational staff and their managers, the COROs, the transversal functions; the second line of defense (LOD2), periodic control (LOD3) and the management in charge of the permanent control framework and internal control coordination (DGLE/PIC) The APRC referential : Activities, Processes, Risks, Control needs","title":"Reminder of the principles of Permanent Control"},{"location":"office/myLearning/bascisOfLevel1PermanentControl/#designing-a-control-plan","text":"Blueprint : general principles The implementation of the APRC approach, for each entity of the Group included in the deployment scope, and at the appropriate level of detail, is done through a 'Blueprint'. Let's see what it consists of: The blueprint is the instrument for selecting the content of the activities and processes in the area of responsibility The blueprint is the \"golden source\" to be used when organising and performing exercises related to the control of non-financial risks (implementation of the APRC approach, risk management [RCSA, COMPASS, etc.], collection of losses and incidents, etc.) Based on the selected activities and processes, the blueprint inherits a level 1 control plan. The control plan makes it possible to determine the control needs applicable to the scope of responsibility, for the control of non-financial risks Control Plan : General principles Building a blueprint requires selecting from the APRC reference framework: The activities you are responsible for The processes attached to the activities applicable to you The applicable controls contributing to the control of risks in these processes In short, APRC allows us to say : we know what we are doing, we know whats risks we face, and we know what controls to put in place to manage these risks The blueprint is the instrument used to select the activities and processes related to the operations contained in a given scope of responsibility Based on this description, and depending on the activities and processes selected, the blueprint inherits a control plan to be deployed from the APRC referentiel The risk control framework is therefore the implementation of this control plan Chapter summary In this section, we have discussed the elements of a blueprint and its usefulness in the context of permanent control. We have also discussed the principles of the control plan and the qualifications of the process and the control need: The blueprint is the instrument for selecting the content of the scope of responsibility for controlling non-financial risks The blueprint is the golden source to be used when organising and conducting non-financial risk management exercises The person responsible for a perimeter establishes a blueprint (at least one) describing the entire perimeter Controls contribute to containing the risks of the processes associated with the activities applicable to you and for which you are responsible","title":"Designing a Control Plan"},{"location":"office/myLearning/bascisOfLevel1PermanentControl/#designing-level-1-controls","text":"Reminder of the different type of L1Cs Let's look at the different frameworks for level 1 controls: GPS is the Group's default tool which covers the vast majority of the Group's level 1 controls. It is available with all the functionalities required to deploy a permanent control, including a library of reference controls (generic controls). It is deployed in all BUs/SUs Other tools : Based on business control tools or business management applications can also be used if they meet the Group's requirements (eg., ARCHER, MORSE+, GTC, etc.) Committees : Committees with formalized and approved terms of reference including controls can be extremely efficient as a risk mitigation measure (eg. New Product Committee) Committees or work group whose terms of reference have been defined, approved, reviewed, and published Example : New Product Committee Incident Committee \"IT-Driven\" automated controls : Some controls can be automated and integrated into tools to prevent the occurence of an operational risk or to detect its possible materialization (eg. input control in a form, blocking control) System and (semi) automated application of a rule within a business process/flow. Example : Automatic calculation of the effective annual interest rate List of pending/blocked transactions Alerts on transactions with unauthorized counterparties In an organizational and governance framework that can help to better secure the activity (eg. Chinese wall) and that it is interesting to highlight Policies, instructions, organizational charts, frameworks, etc. published and regularly updated. Example : Published organizational chart Signed Code of Conduct Let us continue by exploring the main elements of the controls Objectives Reminder : Their purpose is to ensure, where justified, that activities are carried out correctly, while remaining proportionate to the risks The objectives of L1Cs Ensure the quality and proper execution of processes. Mitigate our risks through automated controls, in particular, through automated blocking controls, i.e., preventive controls. Identify situations where the risk has already materialised through detective controls To limit the impact of the materialisation of a risk, i.e., through corrective controls Ensuring the proper application of existing procedures and the control of all risks relating to processes, operations and/or accounts Alerting the hierarchy in the event of anomalies or malfunctions. Characteristics Depending on the degree of automation of the control procedures Manual controls / semi-automated controls / automated controls Depending on the person carrying out the controls Control carried out by a manager, \"4 eyes\" control (carried out by a third party) Depending on the control's operating mode Comparison of a situation with the applicable procedure, comparison of an operation or data with a referentiel, with a range of expected or plausible values, with a target (result, budget, etc.) with the same operation or data from a third party (confirmation) Examples Some examples of automated (\"IT-driven\") controls Blocking control in a tool Impossiblity to continue the process of customer credit origination until all fields of the KYC are completed Restriction of loan approval Up to the maximum allowed per delegation/limit Systematic requirement in a workflow for approval by a dedicated party Automatic calculation of the effective annual interest rate Segregation of duties built into/configured in a system (i.e., staff approving the invoice cannot change the supplier's information on the GNI, etc.) Chapter summary In this section, we have recapitulated the different types of L1Cs as well as their key principles : Various types of first-level controls can be used to contain the risks involved (eg. IT-driven, committee, organizational and governance control sheets) These controls must be formalized in specialized tools (eg. GPS) or described sheets in myAPRC The controls must have specific characteristics as indicated in the L1Cs methodological guide : in particular, it is mandatory to provide the frequency, the sample, the scale of criticality of anomalies, the control rating scale It is imperative to correctly map each control needs in its blueprint and qualify all possible risks on all the control needs in the blueprint The stakeholders The operational staff and the managers of the L1Cs teams are involved in the instantiation of the controls The experts of LOD1 and LOD2 are involved in updating the NCL, i.e., the control needs in the referentiel The L2C and LOD3 (periodic control) teams review and challenge the implementation of the controls that LOD1 has made locally","title":"Designing Level 1 Controls"},{"location":"office/myLearning/bascisOfLevel1PermanentControl/#common-key-principles-for-the-execution-of-1st-level-controls","text":"Guidelines All deployed level 1 controls must be executed (except in the case of \"No Migration\"). It is therefore essential to ensure that the controls are carried out on a permament basis through a precise work organization Compliance with procedures Compliance with the instructions of the control design, frequency, sampling, control points, type of evidence, etc. Precise formalization of the execution of the control and justification of the sample if necessary Formalization of execution in the Group's tools The execution of a control must be formalized in one of the Group tools The execution of L1Cs must be linked to the permanent control referentials (APRC...) Auditability The outcome of a control must be auditable within 5 years of its implementation, i.e., the supporting documents must be kept throughout this period Reporting of anomalies and action plans Scoring of anomalies in accordance with the explanations provided in the control procedure Reporting of anomalies in the permanent control tools Formalization of a mandatory action plan, in the L1C tools for high and very high criticality anomalies Compliance with procedures The quality of the control and the validity of the analysis of the results depend on the relevance of the sampling method. The creators of level 1 controls must ensure that the sampling requested complies with the following principles Responsibility The sampling instructions available in the controls within their scope are appropriate and proportionate to the volumes and risks covered by the control Methods Sample items are selected either in a discretionary (non-statistical) manner based on a particular risk factor (eg., high intrinsic risk level), or in a random (or statistical) manner using mathematical / statistical methods to determine the sample size Freedom of choice The performer of the control must exercise his freedom of choice : he can decide to carry out exhaustive reviews when the level of risk requires it (even if the control procedure allows control based on a sample). Indeed, because of his expertise and knowledge of his activity, the control performer is best able to categorize the \"population\" that is subject to the control, and thus to proportion the control means to the level of risk attached to this population Reporting of anomalies and action plans Let's continue with the reporting of anomalies and action plans. An anomaly must be described and qualified; any anomaly described must be corrected. An anomaly is an error detected or a difference between an expected result and a result obtained during the execution of a control. It can be the result of: A dysfunction with proven losses (a real loss has been noted) A dysfunction with proven impacts but without financial consequences (the risk has materialised but has not resulted in a financial loss) A dysfunction detected without (or before) materialisation of the risk (without proven impact) In the cases, the incident reporting instructions of the operational incident tools will be followed, in compliance with the thresholds defined by the Group The objective of anomaly detection is to be able to make the necessary corrections to prevent recurrence and to ensure that action plans are drawn up It is essential to declare L1C anomalies (including those corrected before the control is finalized) and describe them in detail, so that their impact is clearly explained All this information allows the launch of action plans whose objective is the correction of anomalies and the improvement of processes. The criticality of anomalies must be defined in accordance with Group rules to allow for a uniform analysis of process dysfunctions throughout the Group As a reminder, the Group has adopted a four-level scale for rating level 1 control anomalies: \"Very high\" : Risk for the Societe Generale Group \"High\" : Risk for a BU/SU \"Moderate\" : Risk for an entity or several departments \"Low\" : Risk for a department High and very high criticality anomalies must be subject to an action plan and followed up by General Management Formalization of execution Next comes traceability, with the formalization of execution in the Group's tools The execution of a control must be captured in the central systems (Group datalake) to indicate that the planned risk control framework is in place and functioning Furthermore, it must be possible to link this execution to a blueprint and therefore to the APRC referentiel Auditability Finally, we conclude out presentation of the main principles of control implementation with auditability Formalization of the execution (operating procedure, results) is mandatory All of this information must be traceable, auditable and accessible to the Audit/Inspection, level 2 control teams, and DGLE/PIC, as well as to supervisory authorities These elements must be kept for a minimum of five years, unless otherwise specified By complying with local regulations imposed by the regulator (eg., FATCA regulations require a minimum retention period of 6 years) If specific recommendations have been issued in this regard by the General Inspection and Audit Department Chapter summary In this section, we have discussed the general principles as well as the details of each approach : compliance with procedures, reporting of anomalies and action plans, formalization of execution and audutability In respecting procedures, particular attention must be paid to sampling, which must therefore respect certain principles : responsibility, methods, freedom of choice There are two general approaches to sampling : discretionary and random The performer of the control retains his free will and can decide to carry out exhaustive reviews when the level of risk requires it, even if the control procedure authorizes the control based on a sample An anomaly is an error detected or a difference between an expected result and a result obtained during the performance of a control. As such, a L1Cs anomaly can correspond to dysfunctions with proven losses, dysfunctions with proven impacts, dysfunctions detected without materialization of the risk For all significant anomalies detected, it is essential to define and implement an actio plan to ensure that the dysfunction does not recur,these plans also contribute the continuous improvement of our processes Anomalies, and more particularly high and very high criticality anomalies, must be described in detail in order to clearly explain the impact and the stakes","title":"Common key principles for the execution of 1st level controls"},{"location":"office/myLearning/bascisOfLevel1PermanentControl/#monitoring-permament-control","text":"Principle of reporting As we saw in the introduction, the entire permanent control framework must be monitored by means of reports so that management can ensure that activities are carried out in accordance with the strategy and risk appetite defined by the Group. On this basis, management should be able to take remedial action if necessary. Lets look at their principles and how these reports are set up The objective of permanent control reporting is to capture the results of controls at the finest level, by cross-referencing them with the elements of the non-financial risk management framework, in order to detect significant areas af risk and possible remedial or corrective actions, to summarize them and to inform management and the supervisory bodies Reporting methodology The reporting is done according to a specific methology which we will see in detail Manager, staff Analysis level 1 Performing level 1 control - Daily risk management : Control rating, creation of anomalies, of action plans The level 1 controls that are correctly deplyed and carried out daily throughout the Group make it possible to protect the bank day-to-day and thus to detect and prevent risks The formalization of these controls allows their analysis at the following levels of analysis CORO, ORM, RCL1C Analysis level 2 Daily analysis by the operational risk management teams using the KRI and business intelligence tools provided The data relating to the results of these controls are stored in the datalake. This data can then be used daily by everyone to perform the necessary reports and analyses These analyses are carried out by the operational risk management teams who manage the framework daily BU/SU managers Analysis level 3 Level 1 permanent control certification by the BU/SU managers to the General Management The deployment of level 1 controls, the results of their execution, as well as the analyses made of them, are brought to the attention of the BU/SU management. With the support of the CORO, the BU/SU manager is informed of, analyses, and certifies the results of the execution of the L1Cs in his or her area of supervision. The certification of level 1 control results by management is a quaterly exercise A dashboard is then compiled and challenged every six months by the BU/SU manager at the BU/SU Internal Control Coordination Committee DGLE Analysis level 4 Permanent control dashboard. Presentation of the status of the framework to the Group Internal Control Coordination Committee, General Management and the CACI The elements of L1Cs certification are integrated into the Group's permament control dashboard which compares them with the other non-financial risk management frameworks : the RCSA, losses and incidents, the results of L2C and IGAD missions, etc., in order to detect the priority areas for improvement of the framework, as part of a continuous improvement process. This exercise is also carried out quaterly This dashboard is presented to General Management at the Group Internal Control Coordination Committee meeting, to enable monitoring of the framework and supervision of the Group's internal control. After review and validation, the dashboard is then presented to the Audit and Internal Control Committee DGLE to CACI and ACPR Analysis level 5 Report on Internal Control (RCI) to be reviewed by the GICCC, validated by the General Management, presented to the CACI and the Board of Directors, and communicated to the ACPR and the ECB Finally, the Group produces an annual consolidated report on internal control, known as the RCI. This document presents a transversal analysis (by the experts of LOD1 and LOD2) of all types of risks by comparing the various elements of the framework : losses, incidents, controls, RCSA, etc. It also includes the main results of the missions carried out by LOD3 This report is presented to the CACI (Audit and Internal Control Committee) after neing examined and validated by General Management during the GICCC. It is also sent to the Group's supervisory authorities (ACPR and ECB) Each of the reporting stages described earlier makes possible to assess the internal control framework and to decide on actions to improve this framework to enhance risk management. The formalization of the results of level 1 controls is therefore a key step in the process of continuous improvement of the Group's permanent control framework and allows transparent information to be transmitted to all levels of management, including the General Management and the Board of Directors Chapter summary In this section, we have discussed the monitoring of permament control The permanent control monitoring system enables Management to ensure that activities are carried out in accordance with the strategy and risk appetite. It enables it to decide on remedial actions and to exercise its supervision of internal control. Permanent control reporting makes it possible to capture control results at the finest level, by cross-referencing them with the elements of the non-financial risk management system, in order to detect significant areas of risk and the actions to be taken to effectively contain these risks at the accepted level The formalization and certification of the results of the execution of level 1 controls is one of the key stages in the process of continuous improvement of the Group's permanent control system,; it makes possible to transmit transparent information to all levels of management and to the supervisory authorities","title":"Monitoring permament control"},{"location":"office/myLearning/bascisOfLevel1PermanentControl/#continuous-improvement-if-the-permament-control-framework","text":"Continuous improvement loop and articulation with losses/incidents and RCSA The permament control framework operates in an iterative way. Each component of the framework is fed by the other components, in a continuous improvement logic, so that the framework is agile and adaptable to the evolving risk profile faced by the Group The level 1 control framework is embedded in the non-financial risk management system and contributes to containing risks at the level accepted in the Group's risk appetite. The dynamics of continuous improvement therefore comes from you because permanent control is everyone's responsibility Anomalies can be detected at all levels, operational, managers, level 2 controller, LOD2 expert, periodic controller (IGAD) or supervisory authority All anomalies detected (a process failure, a significant loss, etc.) must be the subject of an action plan to ensure that the dysfunction does not repeat itself. At least for significant anomalies, a follow-up of the action plan is compulsory in a dedicated permament control tool If deemed necessary, the action plan defined may be extended to other entites to ensure that the anomaly does not occur elsewhere in the Group. The permament control framework is deployed throughout the Group (subsidiaries and branches as well as the various organizational structures existing within the scope, such as joint ventures) If significant anomalies are detected, the stakeholders in the permament control framework must react. Improvement actions to enhance the framework can be taken at several levels: At the General Management level, which will identify actions based on the visibility given to the framework by the permanent control dashboard to ensure compliance with the risk appetite defined by the Group AT BU/SU management level, the manager assesses his or her level of residual risk based on \"Risk and Control Self Assessment\" (RCSA) or Compass, the results of L1Cs, incidents and losses, audit reports and the existing L1C framework At your level : through the implementation of procedures, recommendations issued by your management, level 2 control, periodic control (IGAD), supervisory authorities Chapter summary In this section, we have discussed the continuous improvement loop: The permanent control framework must be deployed throughout the Societe Generale Group, i.e., all consolidated subsidiaries and branches, as well as the various organizational structures existing within this scope, such as joint ventures The permanent control framework operates in an iterative way, as part of a continuous improvement process All anomalies detected (a process failure, a significant loss, etc.) must be the subject of an action plan to ensure that the dysfunction does not occur The residual risk remaining after the implementation of the permanent control framework must be compliant with the guidelines laid down by the Group's risk appetite","title":"Continuous improvement if the permament control framework"},{"location":"office/myLearning/csrHistoryStandardsOpportunities/","text":"CSR : History, Standards and Opportunities CSR : Going From Obligation to Mission Reducing our carbon footprint, fighting unemployment or encouraging gender parity: without realizing it, we run into CSR issues every day. But what is CSR, and why is it crucial for companies today? Corporate Social Responsibility Corporate Social Responsibility, or CSR, consists of incorporating economic, social and environmental issues into a company's strategy, to make a positive contribution to society and sustainable development while making sure to still remain economically viable CSR as a Simple Constraint The growing challenges posed by environmental and social issues are forcing governments to put in place regulations to encourage companies to be more responsible. Whereas a company must above all be profitable, investing in sustainable development could represent unnecessary costs created by the simple constraint of having to comply with the laws and standards in force Yet if it's integrated into the company's business model, CSR can actively contribute to its profitability! Image and Stakeholders Adapting to the needs and expectations of all of its stakeholders is an essential part of the proper functioning of a company Employees, investors and consumers increasingly take brand positions and commitments into account This is how Nespresso single-use capsules have in just a few years gone from being a flagship product to a real burden for the coffee giant: to respond to consumer pressure, the company is now showcasing responsible approaches and a recycling programme for its aluminium capsules By committing to having a positive impact on the planet and society, the company is securing the support of its entire ecosystem and engaged in a virtuous circle Long Tern Vision CSR requires companies to plan for the long term by anticipating the climate and energy risks linked to their activities In 2015, COP21 created the Task Force on Climate-related Financial Disclosures to study climate-related financial risks. The TCFD estimates that climate change will cost the economy several trillion dollars. Investors, shareholders and insurers, who aim for long-term profitability, are also putting pressure on companies to take care not to neglect environmental and social challenges From Constraint to Mission CSR is gradually becoming an absolute necessity for companies, to the point of sometimes being at the very heart of thier strategy. This is the case for the French sneaker brand VEJA: its very identity is based on fair trade and responsible production For these companies with innovative business models, CSR has gone from being a constraint to being a source of opportunities and profit! CSR at the International Level: Standards and Regulations While CSR is by nature an international concern, not all countries give it the same importance or the same definition. It can therefore be difficult to have a clear vision of things. Let's take closer look at them The UNs SDGs Let's start with the SDGs, for Sustainable Development Goals: in 2015, the United Nations set 17 SDGs to be achieved by 2030. These revolve around 5 pillars: planet, population, prosperity, peace and partnerships For a company, identifying the SDGs that are relevant to its business sector is a good way to develop its CSR strategy. It's no longer a question of simply limiting the company's negative impact, but of actively integrating these global objectives into its business development strategy For the fashion and textile industry, for example, the goal clean water and sanitation is a major challenge to limit the depletion of the planet's scarce drinking water resources. The polluting products it uses are also an issue as regards the goals health and well-being and preserving the bidiversity of aquatic and terrestrial life The ISO 26000 standard Like the SDGs, the ISO 26000 standard sets a common framework and guidelines at the international level Adopted in 2010, it is today the authorative benchmark in terms of sustainable development. It's often found at the heart of a company's CSR strategy ISO 26000 is based on 7 lines of thinking around best practices in human rights, the environment and ethics. For example, informing consumers in a transparent manner Designed as a guide based on a series of recommendations, it offers guidance for companies without imposing binding obligations on them Software and National Regulations ISO 26000 and ODD are not binding on companies, as they constitute no legal obligation per se. We speak here of \"soft law\". Some consulting companies now offer solutions consisting of advising companies on ways to define business-sector-specific means of action However, these international instruments provide guidelines that more and more countries are translating into their national law. While CSR in the United States is still largely based on voluntary and philantropic initiatives, the countries of the European Union are transposing the European directive requiring large companies to carry out extra-financial reporting, including their CO2 emissions, into their national laws The international framework hence guides governments to evolve their national legislation on the one hand, and companies to anticipate this evolution on the other Identify and measure: A user's Guide to CSR The scope of CSR is broad and comprehensive. When national or sector-specific particularities are also taken into consideration, it can become understandably difficult to know where to start! Identifying the players and issues involved The first thing to do when deciding to adopt a CSR approach is to map the risks and opportunities that are specific to your business sector. To do this, you need to know and consult your stakeholders, to identify the possibilities for joint action. The stakeholders can be internal, such as employees, or external, such as consumers or public authorities For example, organic products or animal welfare are central issues for many consumers today. And as a result, they are also becoming essential for the food and textile sectors In the same way, the positive impact a company has on society is a powerful lever for recruitment, especially among young workers, and a factor in reducing job turnover. This situation is prompting large groups such as Total to set themselves bold CSR objectives Give yourself the means to achieve your goals But beware of greenwashing, this tendency companies have of giving themselves false image of responsible and ethical concern. Declared ambitions are not always synonymous with concrete actions. Once the issues and stakeholders have been identified, you must give yourself the means to achieve your goals A genuine CSR approach begins with concrete and measurable goals that are specific to your business activity. IKEA made a commitment to be using 100% responsible wood by the end of 2020. Between 2017 and 2019, the percentage rose from 77% to 91% There must also be agreement on these means: is CSR solely the concern of a separate department, or does it concern all the teams inside a company? Is there a dedicated budget, and how are CSR-related KPIs integrated into the company's overall KPIs? CSR strategy vs Impact strategy In addition to voluntary initiatives, certifications, labels and rating agencies are good ways to guarantee the credibility of a CSR approach. For example, the B Corporation certification, obtained by Ben and Jerry's in 2012, is an international benchmark But for companies that have opted for an impact strategy, merely reducing the negative externalities associated with their activity is not enough. They must instead be committed to actively improving their contribution to society. For example, by investing part of their turnover in an ecological or social cause, as Patagonia has been doing since 1985 Reducing negative impact with CSR, or generating positive impacts with an impact strategy","title":"CSR History Standards and Opportunities"},{"location":"office/myLearning/csrHistoryStandardsOpportunities/#csr-history-standards-and-opportunities","text":"","title":"CSR : History, Standards and Opportunities"},{"location":"office/myLearning/csrHistoryStandardsOpportunities/#csr-going-from-obligation-to-mission","text":"Reducing our carbon footprint, fighting unemployment or encouraging gender parity: without realizing it, we run into CSR issues every day. But what is CSR, and why is it crucial for companies today?","title":"CSR : Going From Obligation to Mission"},{"location":"office/myLearning/csrHistoryStandardsOpportunities/#corporate-social-responsibility","text":"Corporate Social Responsibility, or CSR, consists of incorporating economic, social and environmental issues into a company's strategy, to make a positive contribution to society and sustainable development while making sure to still remain economically viable","title":"Corporate Social Responsibility"},{"location":"office/myLearning/csrHistoryStandardsOpportunities/#csr-as-a-simple-constraint","text":"The growing challenges posed by environmental and social issues are forcing governments to put in place regulations to encourage companies to be more responsible. Whereas a company must above all be profitable, investing in sustainable development could represent unnecessary costs created by the simple constraint of having to comply with the laws and standards in force Yet if it's integrated into the company's business model, CSR can actively contribute to its profitability!","title":"CSR as a Simple Constraint"},{"location":"office/myLearning/csrHistoryStandardsOpportunities/#image-and-stakeholders","text":"Adapting to the needs and expectations of all of its stakeholders is an essential part of the proper functioning of a company Employees, investors and consumers increasingly take brand positions and commitments into account This is how Nespresso single-use capsules have in just a few years gone from being a flagship product to a real burden for the coffee giant: to respond to consumer pressure, the company is now showcasing responsible approaches and a recycling programme for its aluminium capsules By committing to having a positive impact on the planet and society, the company is securing the support of its entire ecosystem and engaged in a virtuous circle","title":"Image and Stakeholders"},{"location":"office/myLearning/csrHistoryStandardsOpportunities/#long-tern-vision","text":"CSR requires companies to plan for the long term by anticipating the climate and energy risks linked to their activities In 2015, COP21 created the Task Force on Climate-related Financial Disclosures to study climate-related financial risks. The TCFD estimates that climate change will cost the economy several trillion dollars. Investors, shareholders and insurers, who aim for long-term profitability, are also putting pressure on companies to take care not to neglect environmental and social challenges","title":"Long Tern Vision"},{"location":"office/myLearning/csrHistoryStandardsOpportunities/#from-constraint-to-mission","text":"CSR is gradually becoming an absolute necessity for companies, to the point of sometimes being at the very heart of thier strategy. This is the case for the French sneaker brand VEJA: its very identity is based on fair trade and responsible production For these companies with innovative business models, CSR has gone from being a constraint to being a source of opportunities and profit!","title":"From Constraint to Mission"},{"location":"office/myLearning/csrHistoryStandardsOpportunities/#csr-at-the-international-level-standards-and-regulations","text":"While CSR is by nature an international concern, not all countries give it the same importance or the same definition. It can therefore be difficult to have a clear vision of things. Let's take closer look at them","title":"CSR at the International Level: Standards and Regulations"},{"location":"office/myLearning/csrHistoryStandardsOpportunities/#the-uns-sdgs","text":"Let's start with the SDGs, for Sustainable Development Goals: in 2015, the United Nations set 17 SDGs to be achieved by 2030. These revolve around 5 pillars: planet, population, prosperity, peace and partnerships For a company, identifying the SDGs that are relevant to its business sector is a good way to develop its CSR strategy. It's no longer a question of simply limiting the company's negative impact, but of actively integrating these global objectives into its business development strategy For the fashion and textile industry, for example, the goal clean water and sanitation is a major challenge to limit the depletion of the planet's scarce drinking water resources. The polluting products it uses are also an issue as regards the goals health and well-being and preserving the bidiversity of aquatic and terrestrial life","title":"The UNs SDGs"},{"location":"office/myLearning/csrHistoryStandardsOpportunities/#the-iso-26000-standard","text":"Like the SDGs, the ISO 26000 standard sets a common framework and guidelines at the international level Adopted in 2010, it is today the authorative benchmark in terms of sustainable development. It's often found at the heart of a company's CSR strategy ISO 26000 is based on 7 lines of thinking around best practices in human rights, the environment and ethics. For example, informing consumers in a transparent manner Designed as a guide based on a series of recommendations, it offers guidance for companies without imposing binding obligations on them","title":"The ISO 26000 standard"},{"location":"office/myLearning/csrHistoryStandardsOpportunities/#software-and-national-regulations","text":"ISO 26000 and ODD are not binding on companies, as they constitute no legal obligation per se. We speak here of \"soft law\". Some consulting companies now offer solutions consisting of advising companies on ways to define business-sector-specific means of action However, these international instruments provide guidelines that more and more countries are translating into their national law. While CSR in the United States is still largely based on voluntary and philantropic initiatives, the countries of the European Union are transposing the European directive requiring large companies to carry out extra-financial reporting, including their CO2 emissions, into their national laws The international framework hence guides governments to evolve their national legislation on the one hand, and companies to anticipate this evolution on the other","title":"Software and National Regulations"},{"location":"office/myLearning/csrHistoryStandardsOpportunities/#identify-and-measure-a-users-guide-to-csr","text":"The scope of CSR is broad and comprehensive. When national or sector-specific particularities are also taken into consideration, it can become understandably difficult to know where to start!","title":"Identify and measure: A user's Guide to CSR"},{"location":"office/myLearning/csrHistoryStandardsOpportunities/#identifying-the-players-and-issues-involved","text":"The first thing to do when deciding to adopt a CSR approach is to map the risks and opportunities that are specific to your business sector. To do this, you need to know and consult your stakeholders, to identify the possibilities for joint action. The stakeholders can be internal, such as employees, or external, such as consumers or public authorities For example, organic products or animal welfare are central issues for many consumers today. And as a result, they are also becoming essential for the food and textile sectors In the same way, the positive impact a company has on society is a powerful lever for recruitment, especially among young workers, and a factor in reducing job turnover. This situation is prompting large groups such as Total to set themselves bold CSR objectives","title":"Identifying the players and issues involved"},{"location":"office/myLearning/csrHistoryStandardsOpportunities/#give-yourself-the-means-to-achieve-your-goals","text":"But beware of greenwashing, this tendency companies have of giving themselves false image of responsible and ethical concern. Declared ambitions are not always synonymous with concrete actions. Once the issues and stakeholders have been identified, you must give yourself the means to achieve your goals A genuine CSR approach begins with concrete and measurable goals that are specific to your business activity. IKEA made a commitment to be using 100% responsible wood by the end of 2020. Between 2017 and 2019, the percentage rose from 77% to 91% There must also be agreement on these means: is CSR solely the concern of a separate department, or does it concern all the teams inside a company? Is there a dedicated budget, and how are CSR-related KPIs integrated into the company's overall KPIs?","title":"Give yourself the means to achieve your goals"},{"location":"office/myLearning/csrHistoryStandardsOpportunities/#csr-strategy-vs-impact-strategy","text":"In addition to voluntary initiatives, certifications, labels and rating agencies are good ways to guarantee the credibility of a CSR approach. For example, the B Corporation certification, obtained by Ben and Jerry's in 2012, is an international benchmark But for companies that have opted for an impact strategy, merely reducing the negative externalities associated with their activity is not enough. They must instead be committed to actively improving their contribution to society. For example, by investing part of their turnover in an ecological or social cause, as Patagonia has been doing since 1985 Reducing negative impact with CSR, or generating positive impacts with an impact strategy","title":"CSR strategy vs Impact strategy"},{"location":"office/myLearning/fightAgainstCorruption/","text":"Fight Against Corruption Introduction The fight against corruption concerns us all Corruption has long been recognised as an unfair and unethical practice. In spite of this, it is still present in many countries. Anyone maybe confronted with corruption. The demands of lawmakers and the expectations of civil society for companies to behave are increasing The Group is subject, in the countries in which it operates, to various regulations that help to prevent corruption, such as the UK Bribery Act or the American FCPA The French law known as \"Sapin II\", which came into force in June 2017, also requires large companies to adopt, under penalty of sanctions, a mechanism for preventing and detecting acts of corruption committed in France as well as abroad These regulations have been enforced in the Organisation for Economic Cooperation and Developement (OECD) convention against Corruption and the United Nations agreement against corruption The Group has zero tolerance for corruption, regardless of its form and the interests at stake It is the responsibility of each employee to not participate in acts of corruption, to be vigilant in detecting abnormal behaviour, and to report it as soon as possible By the end of this module, you will be able to: Understand the international regulatory framework and issues related to the fight against corruption Define the term corruption and understand the different forms it may take Adopt good practices in situations that may lead to corruption Regulatory framework and sanctions Legal measures Many countries have strengthened their legal measures to fight corruption through the enforcement of heavier sanctions to companies and individuals involved in acts of corruption The scope of some legislation has also been extended making orgamisations liable for prosecution for acts of corruption committed abroad Extraterritorial statute A statue is said to be extraterritorial when it allows for the punishment of Either individuals or legal entities established outside of the State which issued the law Or acts committed outside of the State which issued the law Extraterritorial laws are as follows United States of America The Foreign Corrup Practices Act (FCPA) The US FCPA of 1977 prohibits offering or providing \"anything of value\" to a \"foreign official\" for an \"improper purpose\" The Act applies to: Companies with securities listed in the US US citizens, US residents ot companies organized under US laws, wherever they are located Foreign persons or entities who commit an act in furtherance of a prohibited payment while in the US or a US territory Even a minimal US nexus allows the US authorities to bring cirminal proceedings for corrupt practices committed outside of the territory of the US Applicable penalties : Violations of the FCPA can lead to substantial civil and criminal penalties For each violation of the anti-corruption provisions of the FCPA, companies face a fine of upto $2 million for each violation (or twice the amount of the gain obtained) while individuals face a fine of upto $250k per violation (or twice the amount of gain obtained) and/or five years imprisonment THE FCPA also contains accounting provisions, the violation of which may also be heavily penalized with companies facing upto $25 million for each violation United Kingdom UK Bribery Act (UKBA) The 2010 British law, the UK Bribery Act (UKBA), punishes the corruption of a public servant but also corruption between people working in the private sector The UKBA's scope of application inclues acts Committed in UK Committed by an individual who has a close link to the UK (i.e. head office, citizenship, or residency) In addition the law establishes the criminal liability of a legal person when an employee commits an act of corruption on behalf of or interest of a legal person This is applicable to all organisations operating fully or even partially in the UK including instances of corruption not directly connected to UK territory Ensuing sanctions : For individuals, a prison sentence of upto 10 years including an uncaped fine. Legal entities are also liable to an uncapped fine France The law known as \"Sapin II\" The 2016 law \"dealing with transparency, the fight against corruption and the modernisation of economy\" known as \"Sapin II\", completes the French criminal code, which sanctions acts of corruption committed in the private and public sector in France or abroad The law has recently introduced the obligation for large companies to implement a system for detecting and preventing corruption and influence peddling The law specifies that such a system must include A Code governing the Fight against corruption and influence peddling An internal whistleblowing system A corruption risk mapping Vigilance measures to be implemented with regards to clients, suppliers, and brokers Accounting control procedures A training system A system of disciplinary sanctions An internal system of control and evaluation of measures implemented Ensuing sanctions : Prison sentences of upto 10 years including a fine of 1 million Euros for individuals and upto 10 times the profit or 30 percent of the sales revenue of legal entities The strengthening of the fight against corruption has also resulted in a strengthening of cooperation between States and an increase in the number of prosecutions Sanctions Any act of corruption exposes the Group, its Management, and employees to penal sanctions and heavy administrative penalties. The reputation of the Group is also likely to be tainted The penalties imposed for corruption can take various forms : prison sentences, fines, confiscation of assets, prohibition of practice, and so-on Employees involved in corruption are also subject to disciplinary sanctions Complying with the rules Respecting the Group's rules on corruption will Protect employees of the Group Protect the Group Maintain the trust of our customers, of our partners and other stakeholders (public opinion, media, rating agencies, etc.) Defining Corruption and Understanding its Different Forms Corruption is defined as : \"The act of proposing, giving, soliciting or receiving an undue benefit with a view to accomplishing or refraining from accomplishing an action related to one's professional duties or an action facilitated by the carrying out of such professional duties\" Influence peddling is defined as : \"The act of offering, soliciting or accepting an undue benefit, in order to obtain, to the advantage of the person providing this benefit. A favourable decision from public authority or administration\" The notion of influence peddling is close to the notion of corruption The difference is that the influence peddling implies the presence of an intermediary between the beneficiary and the public official Corruption may take different forms. None of these forms are acceptable Corruption can be public or private, depending on whether it involves a public official or only people from the private sector Because of their duties and capacity to influence or make decisions, Politically exposed persons and Senior Public Officials represent a heightened risk of corruption and influence peddling Politically exposed persons A Politically Exposed Person is a physical person whi is exposed to specific risks of money laundering and corruption due to the functions he or she exercises or has ceased to exercise for less than a year. The relevant functions are as follows: Head of State, Head of the Government, Member of Government or of the European Commission Member of a national parliamentary assembly or the European Parliament, Member of the governing body of a political party or group in France or outside France Members of a supreme court, a constitutional court, or another high court whose decisions are not, except in case of exceptional circumstances, subject to appeal Member of a Court of Auditors Member of the Board of Directors (or equivalent) of a central bank Ambassadors or \"charge d'affaires\" Flag officer or high-ranking military officer in charge of commanding an army Member of the governing body, board of directors or supervisory board of a state-owned company President, vice-president, members of the Council of an international organization created by a treaty, or by a person in an equivalent position within it The term PEP also extends to the close relations of a PEP, in particular direct family members and persons known to be closely linked to the PEP The direct members of the PEP's family is limited to the close family circle and covers the following persons The spouse or known partner The partner under a civil union or under a registered partnership The children as well as their spouse, partner under civil union or registered partnership The parents The persons \"known to be closely associated to a PEP\" are: Any person known as maintaining a \"close business connection\" with a PEP Any individual who is the only beneficial owner of a legal person or a legal structure established by or for the sole benefit of such PEP Any legal person with a beneficial owner who is a PEP because of the function he/her exercises or has ceased to exercise since less than 12 months Senior Public Officials Among Public Persons, the Senior Public Officials (SPO) are persons holding specific functions that do not fall under functions performed by a Politically Exposed Person that are specified above but are nevertheless significantly exposed to corruption and money laundering risk The functions held by a SPO include: Special advisors to the Head of State or Heas of the Government High level civil servants occupying sensitive functions at national level Uppermost levels of the regional civil service Deputy Head of Mission, Consul General Deputy Chief of Staff, Deputy Commander of Armed Forces Chief of the national police and Chief of regional police forces (including chief officer of customs, police commissioner) Senior member of the secret services/intelligence Top officials at the financial market supervisors and other regulatory bodies Regional/state prime ministers, presidents, premiers, governors, chief ministers and their deputies Ministers in regional government, where these exist Leaders of major faith traditions Senior officials of international organizations Mayors of capitals, reginal capitals and major large cities (those with a population of over 100K) Leaders and senior officials of major interest groups that seek to influence public policy and legislation in relation to their particular priorities Officials defined by official national PEP regulations but who fall outside any of the existing Categories Senior officials of the International Olympic Committee and executives from international sporting organizations representing offical Olympic sports Other important functions linked to the exercise of power or to the power holding which can lead the concerned persons to make decisions which result in a significant exposure to a corruption risk, determined by the AMLO and/or the FCC Core business team/FCU according the country, its structure and its political administrative traditions Types of corruption Active corruption is defined as an action carried out by an employee who suggests or gives an undue advantage, regardless of its value Corruption is passive if the employee requests or accepts such an advantage in exchange for performing or refraining from an action associated with their position The mere attempt of an undue advantage is enough to initiate a prosecution even if the advantage has not yet been granted and the person giving an undue advantage may be prosecuted even if the receiving party does not in return perform the wrongful act requested The advantage may be directly given to the beneficiary, or indirectly through the use of a third party acting as an intermediary Regarding the third party, we define influence peddling as the abuse of their real or alleged influence over a holder of a public function to influence the normal performance of their duties or behaviour In fact, all of these examples are advantages that can be proposed, given, solicited, or accepted for an improper purpose The granting or acceptance of an advantage must not call into question or give the impression of calling into question the independence of decision and judgement of the beneficiary of that advantage Respecting the Code Governing the Fight Against Corruption and Influence Peddling and internal procedures allows us to ensure that the advantage will not be considered improper Undue advantages Internship offer Granting, or promising to grant an advantage (paid or not, temporary or permanent) to obtain an advantage is considered to be corruption Recruitment at the request or recommendation of a third party (client, intermediary, etc.) may cast doubt on the impartiality and independence of the recruiter's decisions. Particularly sensitive to the risk of corruption is the recruitment (including for trainee posts) of public officials and their loved ones It is imperative to comply with internal recruitment procedures to ensure a transparent and objective selection of candidates Gifts and invitations It is strictly prohibited for employees to receive or offer any money or any other means of payment such as a gift voucher Giving a voucher to a client may be considered an act of active corruption on the part of the employee in question In the context of his or her professional activity, an employee cannot accept or offer invitations, or gifts of any kind, exceeding a resonable amount. As soon as the amount set by internal procedure is exceeded, the line manager and/or Compliance department should be consulted prior to approval and the invitation or the gift must be declared Remember that irrespective of the cost of the gift, the employee must respect internal procedures which specify prohibitions and restrictions which include payments in cash or similar, paying for the transportation of guests, or offering a gift at one's own expense Unacceptable performance of duties Unacceptable performance of duties can mean carrying out an action (awarding a contract, credit, a benefit in kind or cash) or not carrying out an action For the duration of the relationship, employees must be highly vigilant and perform all appropriate checks in line with the Group's Financial Security Procedures Failing to act (in this case checking the origin of the funds) in return for a favour or the promise of a favour (positive feedback from your manager) constitutes an act of corruption The examples of benefits given or received unduly and the different scenarios proposed in this e-learning are by no means exhaustive. This training cannot cover all behaviours or all possible situations The Code governing the Fight Against Corruption and Influence Peddling should serve as a reference for identifying situations of corruption and recognizing behaviour that may be corrupt. In addition to this code, employees must read the internal instructions in this area Liability for corrupt acts committed by third parties The Group may be liable for acts of corruption committed by third parties acting on the Group's behalf even if Group employees were not directly involved or even aware of such acts Offences committed by partners The Group may be prosecuted for acts of corruption committed by this third party even if none of our employees were aware of these acts It is also possible for the Group to be prosecuted if employees deliberately ignore circumstances that raise suspicions of corrupt acts (\"red flags\"). This is sometimes referred to as being \"willfully blind\". Therefore, employees must not \"look the other way\" when faced with suspicions of possible corruption. Common \"red flags\" associated with using third parties are the following: Excessive commissions to third-party agents or consultants Unreasonable large discounts to third-party distributors Third-party \"consulting agreements\" that include only vaguely described services The third-party consultant is in a different line of business than that for which it has been engaged The third-party is related to or closely associated with the Senior Public Official The third-party became part of the transaction at the express request or insistence of the foreign Senior Public Official The third-party is merely a shell company incorporated in an offshore jurisdiction The third-party requests payment to offshore bank accounts Offences committed by clients In addition, as part of its activities as a banking and financial services provider, the Group is susceptible to clients using bank accounts at the Group to launder the proceeds of acts of corruption For example, a client may use an account at the Group to distribute the profits gained from a bribe. The Group's Anti-Money Laundering and Terrorist Financing standards and mechanisms are in place to prevent, detect and manage such cases KYC In order to mitigate the risks of corruption involving a client or partner, employees must apply the internal procedures for identifying, knowing and monitoring the business relationship These vigilance measures must be adapted to the level of risk presented by the relationship. When assessing risk, there are a number of factors to consider, including: The presence of a Politically Exposed Person (PEP) / Senior Public Official (SPO) Performing an activity in a higher-risk country in terms of corruption The exercise of an activity in a sector exposed to the risk of corruption Zero tolerance Our zero tolerance applies not only to bribery in which an employee participates, but also to cases involving our partners and customers that we may be aware of, particularly in the context of the implementation of AML/CFT vigilance measures Examples of situations that may trigger liability for the Group and/or its employees An employee requests or accepts an undue advantage from another party (client, supplier, intermediary) in return for completing or abstaining from an action related to his position (passive corruption) An employee suggests or gives an undue advantage to another party to facilitate achieving professional or personal goals (active corruption) An employee covers up or is willfully blind (purposefully avoids knowing) about an act of corruption The Group is unintentionally implicated in an act of corruption involving a third party Your Role in Fight Against Corruption As an employee you must follow the Code governing the Fight Against Corruption and Influence Peddling as well as internal procedures It is the responsibility of each employee to follow the Code governing the Fight Against Corruption and Influence Peddling - which describes the different behaviours that may constitute acts of corruption - and the internal procedures, those relating to : Gifts Business meals and external events Actions of patronage and sponsoring Know your customer Third Intermediaries Following the internal rules will allow: Employees to avoid involvement in an act of corruption and, more broadly, any situation or behaviour likely to call into question his or her independence and integrity Partners to ensure integrity by implmenting appropriate due diligence measures The Group to ensure that it is not used by one of its clients to launder the proceeds of an act of corruption As an employee, you also have a duty of care Be vigilant You must be able to : Identify situations that may compromise or give the impression of compromising you ability to perform you duties objectively and impartially Detect abnormal behaviour Being vigilant also means asking yourself the right questions Why is someone offering me something? Why am I offering something to someone? Do I have doubts about the legality or the compliance of the transaction? Will my act allow the company, myself, or someone close to me to benefit from an undue advantage in return? Could my act be considered an attempt to influence someone's impartiality? Do I feel that I am indebted to the person who is giving me an advantage? Would I make the same decision if I were acting in complete transparency? For example, could I justify it to my manager or Compliance? Remember that in case of doubt, it is advisable to seek the advice of the designated person or service (your line management, Compliance, Anti-Corruption correspondent, legal department) If suspicious behaviour is detected, it is your duty, as an employee, to report it to your line manager and/or to local Compliance (\"Chief Compliance Officer\") of you entity You may raise an alert by contacting you management, the compliance department, any local designated whistleblower officer, the HR department or via the Group Whistleblowing tool The law also allows the whistleblower to bring the matter to the competent European or national authorities either after the internal report or directly What is whistleblowing Whistleblowing is the essential right for each of us to raise an alert if we feel that we have good reason to consider that an instruction received, a transaction or, more generally, any given situation of which we are personally aware does not seem to comply with the rules of conduct governing the Group's activities Who has the right to raise an alert? Any Group employee, irrespective of their role or position in the hierarchy External and temporary staff (temps, apprentices, interns, etc.) Agent, Director or Shareholder Service providers having an established business relationship with the Group (subcontractors and suppliers) A third party \"facilitator\" : any natural or legal person of private non-profit law assisting a whistleblower to raise an alert The right must be exercised in good faith, in a responsible, impartial, non-defamatory and non-abusive manner What kind of situations may be subject to whistleblowing? You may raise an alert for any situation that is sufficiently serious, including reporting a crime or offense, any breach of an international treaty, any violation of law or regulation, or any serious threat to the public interest, any retaliation against a whistleblower especially in the following domains : Public or private corruption, including influence peddling Conflicts of interests Embezzlement Anti-competitive practices Money laundering and terrorist financing Non-compliance or circumvention of sanctions and embargoes Tax and accounting fraud Human Resources (discrimination, harassment, endangering the health and safety of employees) Breach of personal data protection rules Override or attempt to override controls Any conduct or situations that are not compliant with the Group's Code of Conduct may also give rise to an alert How are whistleblowers protected? If you raise an alert in good faith, the Group provides you with protection from reprisals and retaliation. Even if the allegation you raised subsequently turns out to be inaccurate, your identity will be treated confidentially, and you will be protected against any acts of retaliation If you believe you are the victim of retaliation after raising an alert, you may raise a further alert by describing the actions taken against you (e.g. paycut, disciplinary sanctions, redundancy) Of course, the right to raise an alert must be exercised in a responsible, impartial, non-defamatory and non-abusive manner. Failure to do so, may result in disciplinary or even criminal sanctions How does it work in practice? The Group has dedicated whistleblowing tool that can be accessed by all, hosted on a secure platform that guarantees strict confidentiality of The identity of the whistleblower and any person concerned by the alert The facts underlying the alert The whistleblowing tool can be used to raise alerts anonymously (local laws may however prohibit anonymity) or by disclosing your identity. Stating your identity may facilitate investigations The whistleblowing tool can be accessed from the home page of the Group intranet. A link to the tool can also be accessed from the Group's website Communications sent through this channel are secure and confidential If you are a whistleblower, you must keep a careful record of your user name and log on regularly on platform to monitor the progress of your alert and provide any additional information How do I go about it? I would like to raise an alert Assess whether the situation is eligible for whistleblowing Request advice from line management and/or the Compliance department I am the direct or indirect line management The report is a whistleblowing alert If needed, I request the assistance of the compliance department to organise the processing of the alert I explain the whistleblower status to the staff member (protection of his/her identity and protection towards sanctions) and confirm his/her alert have been taken in charge I request advice from experts (HR, Compliance, Audit Risk, etc.) in dealing with the alert. At the end of the investigation, I inform the whistleblower about the conclusion I preserve confidentiality, in particular by encrypting (C3) written correspondence, by contacting only the people who should have access to the information and reminding them of the applicable confidentiality rules The report is not a whistleblowing alert I inform the staff member that his/her report is not in the scope of whistleblowing I manage the report using the usual process (compliance incidents, operational risks, HR management, etc.) with the implications of the concerned departments I do not communicate on the source of the information and rephrase the facts in a more generic wording I work in the Compliance department Same as that of the line manager Keep these best Practices in Mind Comply with the Code Governing the Fight Against Corruption and Influence Peddling Comply with internal procedures Remember to declare your gifts, business meals and external events in the internal declaration tool using the appropriate internal procedures Remain vigilant Ask for advice if in doubt Exercise your right to raise an alert Report promptly any possible violation of corruption of public officials wherever it occurs to you chief compliance officers","title":"Protection Against Corruption"},{"location":"office/myLearning/fightAgainstCorruption/#fight-against-corruption","text":"","title":"Fight Against Corruption"},{"location":"office/myLearning/fightAgainstCorruption/#introduction","text":"The fight against corruption concerns us all Corruption has long been recognised as an unfair and unethical practice. In spite of this, it is still present in many countries. Anyone maybe confronted with corruption. The demands of lawmakers and the expectations of civil society for companies to behave are increasing The Group is subject, in the countries in which it operates, to various regulations that help to prevent corruption, such as the UK Bribery Act or the American FCPA The French law known as \"Sapin II\", which came into force in June 2017, also requires large companies to adopt, under penalty of sanctions, a mechanism for preventing and detecting acts of corruption committed in France as well as abroad These regulations have been enforced in the Organisation for Economic Cooperation and Developement (OECD) convention against Corruption and the United Nations agreement against corruption The Group has zero tolerance for corruption, regardless of its form and the interests at stake It is the responsibility of each employee to not participate in acts of corruption, to be vigilant in detecting abnormal behaviour, and to report it as soon as possible By the end of this module, you will be able to: Understand the international regulatory framework and issues related to the fight against corruption Define the term corruption and understand the different forms it may take Adopt good practices in situations that may lead to corruption","title":"Introduction"},{"location":"office/myLearning/fightAgainstCorruption/#regulatory-framework-and-sanctions","text":"","title":"Regulatory framework and sanctions"},{"location":"office/myLearning/fightAgainstCorruption/#legal-measures","text":"Many countries have strengthened their legal measures to fight corruption through the enforcement of heavier sanctions to companies and individuals involved in acts of corruption The scope of some legislation has also been extended making orgamisations liable for prosecution for acts of corruption committed abroad Extraterritorial statute A statue is said to be extraterritorial when it allows for the punishment of Either individuals or legal entities established outside of the State which issued the law Or acts committed outside of the State which issued the law Extraterritorial laws are as follows United States of America The Foreign Corrup Practices Act (FCPA) The US FCPA of 1977 prohibits offering or providing \"anything of value\" to a \"foreign official\" for an \"improper purpose\" The Act applies to: Companies with securities listed in the US US citizens, US residents ot companies organized under US laws, wherever they are located Foreign persons or entities who commit an act in furtherance of a prohibited payment while in the US or a US territory Even a minimal US nexus allows the US authorities to bring cirminal proceedings for corrupt practices committed outside of the territory of the US Applicable penalties : Violations of the FCPA can lead to substantial civil and criminal penalties For each violation of the anti-corruption provisions of the FCPA, companies face a fine of upto $2 million for each violation (or twice the amount of the gain obtained) while individuals face a fine of upto $250k per violation (or twice the amount of gain obtained) and/or five years imprisonment THE FCPA also contains accounting provisions, the violation of which may also be heavily penalized with companies facing upto $25 million for each violation United Kingdom UK Bribery Act (UKBA) The 2010 British law, the UK Bribery Act (UKBA), punishes the corruption of a public servant but also corruption between people working in the private sector The UKBA's scope of application inclues acts Committed in UK Committed by an individual who has a close link to the UK (i.e. head office, citizenship, or residency) In addition the law establishes the criminal liability of a legal person when an employee commits an act of corruption on behalf of or interest of a legal person This is applicable to all organisations operating fully or even partially in the UK including instances of corruption not directly connected to UK territory Ensuing sanctions : For individuals, a prison sentence of upto 10 years including an uncaped fine. Legal entities are also liable to an uncapped fine France The law known as \"Sapin II\" The 2016 law \"dealing with transparency, the fight against corruption and the modernisation of economy\" known as \"Sapin II\", completes the French criminal code, which sanctions acts of corruption committed in the private and public sector in France or abroad The law has recently introduced the obligation for large companies to implement a system for detecting and preventing corruption and influence peddling The law specifies that such a system must include A Code governing the Fight against corruption and influence peddling An internal whistleblowing system A corruption risk mapping Vigilance measures to be implemented with regards to clients, suppliers, and brokers Accounting control procedures A training system A system of disciplinary sanctions An internal system of control and evaluation of measures implemented Ensuing sanctions : Prison sentences of upto 10 years including a fine of 1 million Euros for individuals and upto 10 times the profit or 30 percent of the sales revenue of legal entities The strengthening of the fight against corruption has also resulted in a strengthening of cooperation between States and an increase in the number of prosecutions","title":"Legal measures"},{"location":"office/myLearning/fightAgainstCorruption/#sanctions","text":"Any act of corruption exposes the Group, its Management, and employees to penal sanctions and heavy administrative penalties. The reputation of the Group is also likely to be tainted The penalties imposed for corruption can take various forms : prison sentences, fines, confiscation of assets, prohibition of practice, and so-on Employees involved in corruption are also subject to disciplinary sanctions","title":"Sanctions"},{"location":"office/myLearning/fightAgainstCorruption/#complying-with-the-rules","text":"Respecting the Group's rules on corruption will Protect employees of the Group Protect the Group Maintain the trust of our customers, of our partners and other stakeholders (public opinion, media, rating agencies, etc.)","title":"Complying with the rules"},{"location":"office/myLearning/fightAgainstCorruption/#defining-corruption-and-understanding-its-different-forms","text":"Corruption is defined as : \"The act of proposing, giving, soliciting or receiving an undue benefit with a view to accomplishing or refraining from accomplishing an action related to one's professional duties or an action facilitated by the carrying out of such professional duties\" Influence peddling is defined as : \"The act of offering, soliciting or accepting an undue benefit, in order to obtain, to the advantage of the person providing this benefit. A favourable decision from public authority or administration\" The notion of influence peddling is close to the notion of corruption The difference is that the influence peddling implies the presence of an intermediary between the beneficiary and the public official Corruption may take different forms. None of these forms are acceptable Corruption can be public or private, depending on whether it involves a public official or only people from the private sector Because of their duties and capacity to influence or make decisions, Politically exposed persons and Senior Public Officials represent a heightened risk of corruption and influence peddling Politically exposed persons A Politically Exposed Person is a physical person whi is exposed to specific risks of money laundering and corruption due to the functions he or she exercises or has ceased to exercise for less than a year. The relevant functions are as follows: Head of State, Head of the Government, Member of Government or of the European Commission Member of a national parliamentary assembly or the European Parliament, Member of the governing body of a political party or group in France or outside France Members of a supreme court, a constitutional court, or another high court whose decisions are not, except in case of exceptional circumstances, subject to appeal Member of a Court of Auditors Member of the Board of Directors (or equivalent) of a central bank Ambassadors or \"charge d'affaires\" Flag officer or high-ranking military officer in charge of commanding an army Member of the governing body, board of directors or supervisory board of a state-owned company President, vice-president, members of the Council of an international organization created by a treaty, or by a person in an equivalent position within it The term PEP also extends to the close relations of a PEP, in particular direct family members and persons known to be closely linked to the PEP The direct members of the PEP's family is limited to the close family circle and covers the following persons The spouse or known partner The partner under a civil union or under a registered partnership The children as well as their spouse, partner under civil union or registered partnership The parents The persons \"known to be closely associated to a PEP\" are: Any person known as maintaining a \"close business connection\" with a PEP Any individual who is the only beneficial owner of a legal person or a legal structure established by or for the sole benefit of such PEP Any legal person with a beneficial owner who is a PEP because of the function he/her exercises or has ceased to exercise since less than 12 months Senior Public Officials Among Public Persons, the Senior Public Officials (SPO) are persons holding specific functions that do not fall under functions performed by a Politically Exposed Person that are specified above but are nevertheless significantly exposed to corruption and money laundering risk The functions held by a SPO include: Special advisors to the Head of State or Heas of the Government High level civil servants occupying sensitive functions at national level Uppermost levels of the regional civil service Deputy Head of Mission, Consul General Deputy Chief of Staff, Deputy Commander of Armed Forces Chief of the national police and Chief of regional police forces (including chief officer of customs, police commissioner) Senior member of the secret services/intelligence Top officials at the financial market supervisors and other regulatory bodies Regional/state prime ministers, presidents, premiers, governors, chief ministers and their deputies Ministers in regional government, where these exist Leaders of major faith traditions Senior officials of international organizations Mayors of capitals, reginal capitals and major large cities (those with a population of over 100K) Leaders and senior officials of major interest groups that seek to influence public policy and legislation in relation to their particular priorities Officials defined by official national PEP regulations but who fall outside any of the existing Categories Senior officials of the International Olympic Committee and executives from international sporting organizations representing offical Olympic sports Other important functions linked to the exercise of power or to the power holding which can lead the concerned persons to make decisions which result in a significant exposure to a corruption risk, determined by the AMLO and/or the FCC Core business team/FCU according the country, its structure and its political administrative traditions Types of corruption Active corruption is defined as an action carried out by an employee who suggests or gives an undue advantage, regardless of its value Corruption is passive if the employee requests or accepts such an advantage in exchange for performing or refraining from an action associated with their position The mere attempt of an undue advantage is enough to initiate a prosecution even if the advantage has not yet been granted and the person giving an undue advantage may be prosecuted even if the receiving party does not in return perform the wrongful act requested The advantage may be directly given to the beneficiary, or indirectly through the use of a third party acting as an intermediary Regarding the third party, we define influence peddling as the abuse of their real or alleged influence over a holder of a public function to influence the normal performance of their duties or behaviour In fact, all of these examples are advantages that can be proposed, given, solicited, or accepted for an improper purpose The granting or acceptance of an advantage must not call into question or give the impression of calling into question the independence of decision and judgement of the beneficiary of that advantage Respecting the Code Governing the Fight Against Corruption and Influence Peddling and internal procedures allows us to ensure that the advantage will not be considered improper","title":"Defining Corruption and Understanding its Different Forms"},{"location":"office/myLearning/fightAgainstCorruption/#undue-advantages","text":"Internship offer Granting, or promising to grant an advantage (paid or not, temporary or permanent) to obtain an advantage is considered to be corruption Recruitment at the request or recommendation of a third party (client, intermediary, etc.) may cast doubt on the impartiality and independence of the recruiter's decisions. Particularly sensitive to the risk of corruption is the recruitment (including for trainee posts) of public officials and their loved ones It is imperative to comply with internal recruitment procedures to ensure a transparent and objective selection of candidates Gifts and invitations It is strictly prohibited for employees to receive or offer any money or any other means of payment such as a gift voucher Giving a voucher to a client may be considered an act of active corruption on the part of the employee in question In the context of his or her professional activity, an employee cannot accept or offer invitations, or gifts of any kind, exceeding a resonable amount. As soon as the amount set by internal procedure is exceeded, the line manager and/or Compliance department should be consulted prior to approval and the invitation or the gift must be declared Remember that irrespective of the cost of the gift, the employee must respect internal procedures which specify prohibitions and restrictions which include payments in cash or similar, paying for the transportation of guests, or offering a gift at one's own expense Unacceptable performance of duties Unacceptable performance of duties can mean carrying out an action (awarding a contract, credit, a benefit in kind or cash) or not carrying out an action For the duration of the relationship, employees must be highly vigilant and perform all appropriate checks in line with the Group's Financial Security Procedures Failing to act (in this case checking the origin of the funds) in return for a favour or the promise of a favour (positive feedback from your manager) constitutes an act of corruption The examples of benefits given or received unduly and the different scenarios proposed in this e-learning are by no means exhaustive. This training cannot cover all behaviours or all possible situations The Code governing the Fight Against Corruption and Influence Peddling should serve as a reference for identifying situations of corruption and recognizing behaviour that may be corrupt. In addition to this code, employees must read the internal instructions in this area","title":"Undue advantages"},{"location":"office/myLearning/fightAgainstCorruption/#liability-for-corrupt-acts-committed-by-third-parties","text":"The Group may be liable for acts of corruption committed by third parties acting on the Group's behalf even if Group employees were not directly involved or even aware of such acts Offences committed by partners The Group may be prosecuted for acts of corruption committed by this third party even if none of our employees were aware of these acts It is also possible for the Group to be prosecuted if employees deliberately ignore circumstances that raise suspicions of corrupt acts (\"red flags\"). This is sometimes referred to as being \"willfully blind\". Therefore, employees must not \"look the other way\" when faced with suspicions of possible corruption. Common \"red flags\" associated with using third parties are the following: Excessive commissions to third-party agents or consultants Unreasonable large discounts to third-party distributors Third-party \"consulting agreements\" that include only vaguely described services The third-party consultant is in a different line of business than that for which it has been engaged The third-party is related to or closely associated with the Senior Public Official The third-party became part of the transaction at the express request or insistence of the foreign Senior Public Official The third-party is merely a shell company incorporated in an offshore jurisdiction The third-party requests payment to offshore bank accounts Offences committed by clients In addition, as part of its activities as a banking and financial services provider, the Group is susceptible to clients using bank accounts at the Group to launder the proceeds of acts of corruption For example, a client may use an account at the Group to distribute the profits gained from a bribe. The Group's Anti-Money Laundering and Terrorist Financing standards and mechanisms are in place to prevent, detect and manage such cases","title":"Liability for corrupt acts committed by third parties"},{"location":"office/myLearning/fightAgainstCorruption/#kyc","text":"In order to mitigate the risks of corruption involving a client or partner, employees must apply the internal procedures for identifying, knowing and monitoring the business relationship These vigilance measures must be adapted to the level of risk presented by the relationship. When assessing risk, there are a number of factors to consider, including: The presence of a Politically Exposed Person (PEP) / Senior Public Official (SPO) Performing an activity in a higher-risk country in terms of corruption The exercise of an activity in a sector exposed to the risk of corruption","title":"KYC"},{"location":"office/myLearning/fightAgainstCorruption/#zero-tolerance","text":"Our zero tolerance applies not only to bribery in which an employee participates, but also to cases involving our partners and customers that we may be aware of, particularly in the context of the implementation of AML/CFT vigilance measures Examples of situations that may trigger liability for the Group and/or its employees An employee requests or accepts an undue advantage from another party (client, supplier, intermediary) in return for completing or abstaining from an action related to his position (passive corruption) An employee suggests or gives an undue advantage to another party to facilitate achieving professional or personal goals (active corruption) An employee covers up or is willfully blind (purposefully avoids knowing) about an act of corruption The Group is unintentionally implicated in an act of corruption involving a third party","title":"Zero tolerance"},{"location":"office/myLearning/fightAgainstCorruption/#your-role-in-fight-against-corruption","text":"As an employee you must follow the Code governing the Fight Against Corruption and Influence Peddling as well as internal procedures It is the responsibility of each employee to follow the Code governing the Fight Against Corruption and Influence Peddling - which describes the different behaviours that may constitute acts of corruption - and the internal procedures, those relating to : Gifts Business meals and external events Actions of patronage and sponsoring Know your customer Third Intermediaries Following the internal rules will allow: Employees to avoid involvement in an act of corruption and, more broadly, any situation or behaviour likely to call into question his or her independence and integrity Partners to ensure integrity by implmenting appropriate due diligence measures The Group to ensure that it is not used by one of its clients to launder the proceeds of an act of corruption As an employee, you also have a duty of care Be vigilant You must be able to : Identify situations that may compromise or give the impression of compromising you ability to perform you duties objectively and impartially Detect abnormal behaviour Being vigilant also means asking yourself the right questions Why is someone offering me something? Why am I offering something to someone? Do I have doubts about the legality or the compliance of the transaction? Will my act allow the company, myself, or someone close to me to benefit from an undue advantage in return? Could my act be considered an attempt to influence someone's impartiality? Do I feel that I am indebted to the person who is giving me an advantage? Would I make the same decision if I were acting in complete transparency? For example, could I justify it to my manager or Compliance? Remember that in case of doubt, it is advisable to seek the advice of the designated person or service (your line management, Compliance, Anti-Corruption correspondent, legal department) If suspicious behaviour is detected, it is your duty, as an employee, to report it to your line manager and/or to local Compliance (\"Chief Compliance Officer\") of you entity You may raise an alert by contacting you management, the compliance department, any local designated whistleblower officer, the HR department or via the Group Whistleblowing tool The law also allows the whistleblower to bring the matter to the competent European or national authorities either after the internal report or directly","title":"Your Role in Fight Against Corruption"},{"location":"office/myLearning/fightAgainstCorruption/#what-is-whistleblowing","text":"Whistleblowing is the essential right for each of us to raise an alert if we feel that we have good reason to consider that an instruction received, a transaction or, more generally, any given situation of which we are personally aware does not seem to comply with the rules of conduct governing the Group's activities Who has the right to raise an alert? Any Group employee, irrespective of their role or position in the hierarchy External and temporary staff (temps, apprentices, interns, etc.) Agent, Director or Shareholder Service providers having an established business relationship with the Group (subcontractors and suppliers) A third party \"facilitator\" : any natural or legal person of private non-profit law assisting a whistleblower to raise an alert The right must be exercised in good faith, in a responsible, impartial, non-defamatory and non-abusive manner What kind of situations may be subject to whistleblowing? You may raise an alert for any situation that is sufficiently serious, including reporting a crime or offense, any breach of an international treaty, any violation of law or regulation, or any serious threat to the public interest, any retaliation against a whistleblower especially in the following domains : Public or private corruption, including influence peddling Conflicts of interests Embezzlement Anti-competitive practices Money laundering and terrorist financing Non-compliance or circumvention of sanctions and embargoes Tax and accounting fraud Human Resources (discrimination, harassment, endangering the health and safety of employees) Breach of personal data protection rules Override or attempt to override controls Any conduct or situations that are not compliant with the Group's Code of Conduct may also give rise to an alert How are whistleblowers protected? If you raise an alert in good faith, the Group provides you with protection from reprisals and retaliation. Even if the allegation you raised subsequently turns out to be inaccurate, your identity will be treated confidentially, and you will be protected against any acts of retaliation If you believe you are the victim of retaliation after raising an alert, you may raise a further alert by describing the actions taken against you (e.g. paycut, disciplinary sanctions, redundancy) Of course, the right to raise an alert must be exercised in a responsible, impartial, non-defamatory and non-abusive manner. Failure to do so, may result in disciplinary or even criminal sanctions How does it work in practice? The Group has dedicated whistleblowing tool that can be accessed by all, hosted on a secure platform that guarantees strict confidentiality of The identity of the whistleblower and any person concerned by the alert The facts underlying the alert The whistleblowing tool can be used to raise alerts anonymously (local laws may however prohibit anonymity) or by disclosing your identity. Stating your identity may facilitate investigations The whistleblowing tool can be accessed from the home page of the Group intranet. A link to the tool can also be accessed from the Group's website Communications sent through this channel are secure and confidential If you are a whistleblower, you must keep a careful record of your user name and log on regularly on platform to monitor the progress of your alert and provide any additional information How do I go about it? I would like to raise an alert Assess whether the situation is eligible for whistleblowing Request advice from line management and/or the Compliance department I am the direct or indirect line management The report is a whistleblowing alert If needed, I request the assistance of the compliance department to organise the processing of the alert I explain the whistleblower status to the staff member (protection of his/her identity and protection towards sanctions) and confirm his/her alert have been taken in charge I request advice from experts (HR, Compliance, Audit Risk, etc.) in dealing with the alert. At the end of the investigation, I inform the whistleblower about the conclusion I preserve confidentiality, in particular by encrypting (C3) written correspondence, by contacting only the people who should have access to the information and reminding them of the applicable confidentiality rules The report is not a whistleblowing alert I inform the staff member that his/her report is not in the scope of whistleblowing I manage the report using the usual process (compliance incidents, operational risks, HR management, etc.) with the implications of the concerned departments I do not communicate on the source of the information and rephrase the facts in a more generic wording I work in the Compliance department Same as that of the line manager","title":"What is whistleblowing"},{"location":"office/myLearning/fightAgainstCorruption/#keep-these-best-practices-in-mind","text":"Comply with the Code Governing the Fight Against Corruption and Influence Peddling Comply with internal procedures Remember to declare your gifts, business meals and external events in the internal declaration tool using the appropriate internal procedures Remain vigilant Ask for advice if in doubt Exercise your right to raise an alert Report promptly any possible violation of corruption of public officials wherever it occurs to you chief compliance officers","title":"Keep these best Practices in Mind"},{"location":"office/myLearning/preventionOfSexualHarassment/","text":"Prevention of Sexual Harassment Prevention of Sexual Harassment in workplace The workplace should be Safe Secure Friendly Non-discrimainatory The Legal Mandate Awareness Training and Sensitization of all Employees is required under Sexual Harassment of Women at Workplace (Prevention, Prohibition and Redressal) Act, 2013 Act provides for : Protection against sexual harassment of women at workplace Prevention and Redressal of complaints of sexual harassment Understanding sexual harassment Facets of harassment Workplace harassment Behaviours that are humiliating and cause embarassment, discomfort or emotional distress is workplace harassment Gender discrimination Sexual harassment Sexual harassment is unwelcome sexual advances, requests for sexual favours or verbal or physical conduct that is of sexual nature Definition of Sexual harassment According to the Act, sexual harassment includes the following, whether directly or by implication Showing pornography Making sexually coloured remarks Physical contact and advances A demand or request for sexual favours Unwelcome physical, verbal or non-verbal conduct of sexual nature constitutes sexual harassment. Types of sexual harassment Quid pro-quo Hostile environment Sexual conduct that creates an intimidating, hostile or offensive working environement For example : Coming very close to someone when speaking or using a suggestive voice Sexual innuendos, stories, jokes or suggestive comments Asking personal questions or spreading rumours about a co-worker's private life Giving compliments with sexual undertones Forms of sexual harassment Verbal Physical Psychological Visual Elements of sexual harassment Conduct must be unwelcomed, unwanted, uninvited, unreasonable and offensive to the harassed individual which adversely affects the dignity of that individual Physical contact is not an essential ingredient for sexual harassment Act of harassment must be related to employment or work Harasser can be the complainant's boss, supervisor, visitor, professor, co-worker, non-employee, vendor, contractor or agent of the employer Complainant does not have to be the person harassed but anyone affected by the offensive misconduct Sexual Harassment - Where Else? Business travel Travelling to an from work Offsite conferences/trainings After hours office party Work from home Summary Physical, verbal or non-conduct of sexual nature that is Unwelcome constitutes sexual harassment Types of sexual harassment - Quid Pro Quo, Hostile Environment Forms of sexual harassment - Physical, Verbal, Psychological, Visual Intent vs Impact : Its not the intent that matters but the impact that counts Redressal Mechanism Internal Committee (IC) Constituted by the employer Has the powers of the civil court Receives complaint and conducts an inquiry into complaint Members trained and equipped to handle instances of sexual harassment Inquiry has to be completed within 90 days from receipt of complaint Constituents of IC A Presiding Officer who shall be a woman employed at a senior level at the workplace amongst the employees Two other members amongst the employees preferably committed to the cause of women or who had experience in social work or have legal knowledge One member from Non-Governmental organisations or associations committed to the cause of women, or a person familiar with the issues relating to sexual harassment At least 50% of the committee shall be women Tenure of the committee is 3 years Registering a Complaint to the IC In the event of an incident, the members of the IC will conduct the inquiry based on the location The details of you IC members are available on the intranet portal Socgen IC endures Confidentiality Fair and just hearing Reasonable assistance No retaliation False and malicious complaints/ evidence Appropriate disciplinary action will be taken against the person(s) giving false complaints or false evidence Appeal The Complainant or the Respondant can file an appeal to the Head - Conduct and Culture, within thirty(30) days of the recommendations being communicated Summary IC constituted by the Employer has the powers of the Civil Court and conducts an inquiry into the complaint Strict confidentiality is maintained throughout the proceedings False and malicious complaints or evidence are penalized The Law ensures fair and just hearing and no retaliation Handling sexual harassment What to do if it happens to you? Keep an incident log If you need any help/ advice/ clarification, approach a member of the IC by call/ mail/ in person Draft a complaint Send the complaint to the IC within 3 months from the date of the last incident In the event of sexual harassment Do not blame yourself Reach out to your IC members Know your policy on prevention of sexual harassment The right thing to do Respect your colleagues Do not abuse, intimidate or be hostile Keep relationships professional Ensure appropriate touching, like a polite handshake Apologise immediately if it was not intended Do not investigate on your own Report incidents of Sexual harassment to the IC Examine if the act is discrimination or harassment prior to reporting Provide assistance when needed What is not acceptable Loose talk Being frivolous Abusive Sexually explicit language Touching Streotyping a person based on culture Encouraging cover up Discouraging the person to complain or drop charges Threatening Assumption that one is not offended by your behavior Making personal comments or remarks Spreading rumours","title":"Prevention of Sexual Harassment"},{"location":"office/myLearning/preventionOfSexualHarassment/#prevention-of-sexual-harassment","text":"","title":"Prevention of Sexual Harassment"},{"location":"office/myLearning/preventionOfSexualHarassment/#prevention-of-sexual-harassment-in-workplace","text":"The workplace should be Safe Secure Friendly Non-discrimainatory The Legal Mandate Awareness Training and Sensitization of all Employees is required under Sexual Harassment of Women at Workplace (Prevention, Prohibition and Redressal) Act, 2013 Act provides for : Protection against sexual harassment of women at workplace Prevention and Redressal of complaints of sexual harassment","title":"Prevention of Sexual Harassment in workplace"},{"location":"office/myLearning/preventionOfSexualHarassment/#understanding-sexual-harassment","text":"Facets of harassment Workplace harassment Behaviours that are humiliating and cause embarassment, discomfort or emotional distress is workplace harassment Gender discrimination Sexual harassment Sexual harassment is unwelcome sexual advances, requests for sexual favours or verbal or physical conduct that is of sexual nature Definition of Sexual harassment According to the Act, sexual harassment includes the following, whether directly or by implication Showing pornography Making sexually coloured remarks Physical contact and advances A demand or request for sexual favours Unwelcome physical, verbal or non-verbal conduct of sexual nature constitutes sexual harassment. Types of sexual harassment Quid pro-quo Hostile environment Sexual conduct that creates an intimidating, hostile or offensive working environement For example : Coming very close to someone when speaking or using a suggestive voice Sexual innuendos, stories, jokes or suggestive comments Asking personal questions or spreading rumours about a co-worker's private life Giving compliments with sexual undertones Forms of sexual harassment Verbal Physical Psychological Visual Elements of sexual harassment Conduct must be unwelcomed, unwanted, uninvited, unreasonable and offensive to the harassed individual which adversely affects the dignity of that individual Physical contact is not an essential ingredient for sexual harassment Act of harassment must be related to employment or work Harasser can be the complainant's boss, supervisor, visitor, professor, co-worker, non-employee, vendor, contractor or agent of the employer Complainant does not have to be the person harassed but anyone affected by the offensive misconduct Sexual Harassment - Where Else? Business travel Travelling to an from work Offsite conferences/trainings After hours office party Work from home Summary Physical, verbal or non-conduct of sexual nature that is Unwelcome constitutes sexual harassment Types of sexual harassment - Quid Pro Quo, Hostile Environment Forms of sexual harassment - Physical, Verbal, Psychological, Visual Intent vs Impact : Its not the intent that matters but the impact that counts","title":"Understanding sexual harassment"},{"location":"office/myLearning/preventionOfSexualHarassment/#redressal-mechanism","text":"Internal Committee (IC) Constituted by the employer Has the powers of the civil court Receives complaint and conducts an inquiry into complaint Members trained and equipped to handle instances of sexual harassment Inquiry has to be completed within 90 days from receipt of complaint Constituents of IC A Presiding Officer who shall be a woman employed at a senior level at the workplace amongst the employees Two other members amongst the employees preferably committed to the cause of women or who had experience in social work or have legal knowledge One member from Non-Governmental organisations or associations committed to the cause of women, or a person familiar with the issues relating to sexual harassment At least 50% of the committee shall be women Tenure of the committee is 3 years Registering a Complaint to the IC In the event of an incident, the members of the IC will conduct the inquiry based on the location The details of you IC members are available on the intranet portal Socgen IC endures Confidentiality Fair and just hearing Reasonable assistance No retaliation False and malicious complaints/ evidence Appropriate disciplinary action will be taken against the person(s) giving false complaints or false evidence Appeal The Complainant or the Respondant can file an appeal to the Head - Conduct and Culture, within thirty(30) days of the recommendations being communicated Summary IC constituted by the Employer has the powers of the Civil Court and conducts an inquiry into the complaint Strict confidentiality is maintained throughout the proceedings False and malicious complaints or evidence are penalized The Law ensures fair and just hearing and no retaliation","title":"Redressal Mechanism"},{"location":"office/myLearning/preventionOfSexualHarassment/#handling-sexual-harassment","text":"What to do if it happens to you? Keep an incident log If you need any help/ advice/ clarification, approach a member of the IC by call/ mail/ in person Draft a complaint Send the complaint to the IC within 3 months from the date of the last incident In the event of sexual harassment Do not blame yourself Reach out to your IC members Know your policy on prevention of sexual harassment The right thing to do Respect your colleagues Do not abuse, intimidate or be hostile Keep relationships professional Ensure appropriate touching, like a polite handshake Apologise immediately if it was not intended Do not investigate on your own Report incidents of Sexual harassment to the IC Examine if the act is discrimination or harassment prior to reporting Provide assistance when needed What is not acceptable Loose talk Being frivolous Abusive Sexually explicit language Touching Streotyping a person based on culture Encouraging cover up Discouraging the person to complain or drop charges Threatening Assumption that one is not offended by your behavior Making personal comments or remarks Spreading rumours","title":"Handling sexual harassment"},{"location":"office/myLearning/protectionOfPersonalData/","text":"Protection of Personal Data Faced with the increasing use of personal data in all economic sectors and in response to the concerns expressed by citizens, legislative measures are being strengthened to provide a better framework for the use of personal data, to guarantee its protection and to extend the rights of data subjects. The European Parliament has adopted a regulatory text that governs the processing of personal data within the European Economic Area (EEA) This text, called the General Data Protection Regulation (GDPR), came into force on 25 May 2018 GDPR It aims to: Strengthen the rights of individuals The GDPR offers data subjects greater transparency in the use of their data, notably through better information and strengthening of their rights Strengthen the accountability of organisations that process personal data The GDPR imposes new requirements on organisations that process personal data and introduces the principle of accountability This obliges organisations to implement internal mechanisms and procedures to demonstrate compliance with data protection rules Harmonise all legislation at European level The GDPR harmonises the laws of Member States on the protection of personal data However, some specific local dispositions may exist Since the GDPR came into force, other countries outside the European Union have also changed their personal data protection regulations European Union May 2018 : General Data Protection Regulation Japan June 2020 : Act of Protection of Personal Information South Africa July 2020 : Protection of Personal Information Act Brazil August 2020 : General Data Protection Law New Zealand December 2020 : Privacy Act China November 2021 : Personal Information Protection Law As trusted third parties, banks are particularly sensitive to the protection of data they process Service providers Suppliers Other partners As Societe Generale employees, we are all affected in our daily lives by the use of personal data. Awareness of current regulations is therefore essential. Through this module, you will learn to : Master the basic concepts Be aware of who is involved Understand the application framework Learn the main principles to be followed Understand the rights of individuals over their data Recognise a data breach and respond appropriately And use your common sense, because the GDPR often comes down to the application of simple principles GDPR : Who, What, How? Personal data is any information relating to a natural person that can be used, directly or indirectly, to identify that specific person Personal data Private email address Personal phone number Health information Work email address Work phone number Salary amount Be careful, however, not to confuse personal data with private data! Whether in a private or professional context, data relating to an indentifiable person remains personal data In addition , there are special categories of personal data known as \"sensitive data\" within the meaning of the GDPR Racial or ethnic origin Political opinions Religious or philosophical beliefs Trade union membership Genetic data Biometric data Data concerning health Sex life or sexual orientation This sensitive data is subject to greater attention and it use is strictly regulated With the development of digital technology, new types of data have emerged : Cookies These are trackers that collect information related to browsing activity Sesame ID / Username IP address Browsing history When, alone or combined with other data, they can identify an individual, cookies are considered personal data and must comply with the regulations Now that we have seen what personal data is, let us turn to the concept of data processing Personal data processing is a use of that data, which can take several forms Collection Recording Modification Viewing Distribution The concept of \"processing\" is very broad : the simple fact of collecting or accessing data is considered as processing! This applies to both digital and paper files Examples of processing Payroll management Creation of a directory Direct marketing Physical access management The GDPR applies to organisations (companies associations, etc.) according to their location and/or the location of the individuals whose data they process An organisation located in the EEA is affected by the GDPR regardless of the location of the individuals whose data it processes By harmonising European legislation, the GDPR facilitates the free movement of personal data within the EEA However, transfers of personal data outside the EEA are strictly regulated Transfers of personal data to a non-EEA country are authorised if that country is recognised as \"adequate\" by the European Commission To be \"adequate\", a non-EEA country must be have legislation equivalent to the GDPR Even when personal data is stored within the EEA, the mere fact that it can be accessed from outside the EEA is considered to be a transfer outside the EEA, and must therefore be regulated! GDPR participants Let's now look at the various participants involved in the protection of personal data Data Subject Data subjects are the natural persons whose personal data is processed. Examples Customer User Employee Shareholder Data controller A \"data controller\" is any natural or legal person who manages personal data The Group has identified more than 100 different Data Controllers, corresponding to different legal statuses (subsidiaries, branches, Service Units within SGPM, etc.) Collects the data Decides how the data is processed Data processor Any natural or legal person (supplier, service provider, etc.) who carries out all or part of the processing on behalf of a data controller is considered a data processor Data processors may be external or internal to the Group Thus, a Group entity may act both as data controller and data processor depending on the processing carried out The data processor's obligations in terms of personal data protection must be mentioned in the contract between the data processor and the data controller Data Protection Authority Data Protection Authorities are independent public authorities that monitor the application of data protection legislation Each EU Member State has its own Data Protection Authority Role of a Data Protection Authority Provide expert advice (guidelines, recommendations, etc.) on data protection issues Monitor the application of the regulations and impose sanctions in the event of non-compliance Deal with complaints about breaches of the GDPR and national data protection laws Data Protection Officer The Data Protection Officer (DPO) is designated by a data controller as the point of contract for the Data Protection Authority of their country DPO must be able to carry out their duties independently Within the Societe Generale Group, the DPOs are attached to the Compliance department The Group DPO (CPLE/DPO) reports to the Group Head of Compliance DPO's role Manage GDPR compliance within their organisation Support and advise the organisation's internal departments Cooperate with the Data Protection AUthorities Be the point of contact for data subjects Main principles Processing of personal data must respect the following principles: Be lawful (lawfulness) Let's start with the lawfulness of a processing activity In order to be lawful, a processing activity must be based on one of the six legal bases provided for by the GDPR Performance of a contract Processing is necessary for the performance of a contract to which the data subject is party This legal basis may apply When a contract is signed Example : Processing related to payroll (performance of the employment contract) For the purpose of signing a contract Example : Processing related to the provision of a quote Legal obligation Processing is necessary for compliance with a legal obligation to which the data controller is subject This legal basis is often used by the Group, as the bank operates in a highly regulated environment Example : KYC process, anti-money laundering, etc. Protecting the vital interests of the individual Processing is necessary in order to protect the vital interests of a natural person This legal basis is limited to situations where the lives of individuals are at stake, it is very rarely used in a banking context Example : Hospital admission, health crisis situation, etc. Performance of a public interest risk Processing is necessary for the performance of a public interest responsibility conferred on the data controller The use of this legal basis mainly concerns public authorities and is very rarely used within the bank Example : Specific processing related to the activities of public bodies, such as ministries, town halls, tax authorities, etc. Consent Data subjects must give free, specific and informed consent to the processing of their data They must be able to withdraw their consent at any time as easily as they gave it Consent must result from a positive act (no pre-ticked box) Legitimate interest This legal basis applies to processing activities that do not fall under the previous legal bases but are nonetheless necessary for the activity of the data controller The use of this legal basis requires the data controller to demonstrate and document that the interests pursued do not create an imbalance to the detriment of the rights and interests of the persons whose data is processed Example : Ensuring business development, guaranteeting the security of your assets Pursue defined and limited objectives (purpose limitation) Processing must have a specific and explicit purpose The data must not be used for purposes other than those for which it was collected Be carried out in a transparent manner (transparency) The controller must inform the data subjects of the processing it carries out on their data This information must be Concise Expressed in clear, simple, and easily understandable terms Easily accessible Use only the data that is strictly necessary (minimisation) Only data strictly necessary for the processing may be collected and used No data may be collected \"just in case\" Use accurate and up-to-data (accuracy) The personal data processed must be accurate and kept up to date Keep data for a limited time (storage limitation) The data collected must be kept for a limited period This period must be consistent and justified in relation to the purpose of the processing The data controller must therefore put in place a data erasure mechanism and ensure that the data is completely deleted at the end of this period Be secure (security) Personal data must be processed and stored in a secure manner to protect it from any risk of loss, disclosure, alteration, or destruction Examples : Password Backup Encryption A policy governing the security of personal data has been defined by the Group's IT Security department One of the main compliance tools is the record of processing activities The data controller lists all the personal data processing activities carried out by the organisation, gives a detailed description (purpose of the processing, data processed, operational methods, etc.) and ensures they are kept up to date Employee training management Management of customer's electronic account statements Organisation and management of competitions Management of access to premises Several participants are involved in this process Business / Operational staff For the needs of its activity, implements personal data processing in compliance with the Group's rules Alerts in the event of a data breach Participates, if necessary, in the processing of data subjects' rights requests Data management office Keeps the register of personal data processing activities of the entity concerned Provides level 1 support to operational staff Data Protection Officer / Data Protection Correspondent (LOD2 Compliance) Checks compliance, advises and supports those involved throughout the life of a processing activity Is the main contact for data protection authorities, particularly in the event of an inspection or complaint Rights of individuals The GDPR has strengthened the rights of individuals in relation to the uses made of their data Individuals can exercise their rights with data controllers in a variety of ways : by post or email, orally (e.g. with an adviser), using dedicated digital pathways, etc. Right Of access The right of access allows the data subjects: To find out weather data relating to them is being processed by the data controller To obtain a copy in an intelligle format To obtain information about the processing of their data To rectification The right to rectification allows data subjects to obtain correction of inaccurate or incomplete information concerning them Modification or addition of data To object The right to object allows data subjects to object, on legitimate grounds, to the processing of their personal data by a data controller In the event of objection to direct marketing, the customer does not need to give reasons for the request To erasure The right to erasure allows data subjects to ask the data controller to erase personal data concerning them The data controller may refuse where legal or regulatory requirements require it to retain the data To restriction of processing The right to restriction of processing allows data subjects to request a temporart freeze on the use of some of their personal data in cases provided for by the regulations Data subjects must specify the data whose use they wish to limit and give reasons for the request For example, the processing of data may be \"frozen\" for the time needed to resolve a dispute or a challenge To portability The right to portability allows data subjects to request the recovery of some of their data, collected with their consent or for the purposes of a contract, in a structured digital format (e.g. Excel file) They may request that their data be transmitted directly to another organisation The data controller has one month to respond to a rights request This period may be extended by two months in certain cases (complex requests or volume of requests) and after notifying the data subject Summary Data protection regulations give rights to individuals whose data os being processed The organisation has one month to respond to requests to exercise these rights Upon receipt of a request to exercise a right, it should be forwarded to the line manager or directly to the Data Protection Correspondent (DPC) or the Data Protection Officer (DPO) of the relevant entity Data Breach The GDPR requires a data controller to: have mechanisms for detecting personal data breaches record breaches in a register analyse the impact of a breach on data subjects notify the Data Protection Authority in the event of a breach with a significant impact or even to notify the data subjects themselves If it detects a personal data breach, a data processor must notify its data controller activity After detecting a personal data breach, the data processor has 72 hours to notify the Data Protection Authority It is therefore essential to raise an alert immediately in case of a breach A personal data breach is a security incident : Of malicious origin or otherwise Occurring intentionally or unintentionally That comprises confidentiality, integrity or availability of personal data Examples of data breach include : Theft or loss of laptop containing customer information Mistakenly sending an email containing personal data to the wrong recipient A server failure preventing customers from accessing their personal data for a significant period Ransomware (taking personal data \"hostage\" by malicious encryption and then demanding a ransom) Summary A data breach in the sense of the GDPR is any type of incident resulting in a loss of confidentiality, integrity or availability of personal data As soon as a breach is identified, it should be reported as soon as possible to the Data Protection Correspondent of the area concerned The Correspondent is responsible for assessing the severity of the breach, in conjunction with the relevant teams, and for making a recommendation on the need to notify the Data Protection Authority and where appropriate, the data subjects When required, the notification must be made within 72 hours of the identification of the breach The Data Protection Correspondent must document the data breach in a register","title":"Protection of Personal Data"},{"location":"office/myLearning/protectionOfPersonalData/#protection-of-personal-data","text":"Faced with the increasing use of personal data in all economic sectors and in response to the concerns expressed by citizens, legislative measures are being strengthened to provide a better framework for the use of personal data, to guarantee its protection and to extend the rights of data subjects. The European Parliament has adopted a regulatory text that governs the processing of personal data within the European Economic Area (EEA) This text, called the General Data Protection Regulation (GDPR), came into force on 25 May 2018","title":"Protection of Personal Data"},{"location":"office/myLearning/protectionOfPersonalData/#gdpr","text":"It aims to: Strengthen the rights of individuals The GDPR offers data subjects greater transparency in the use of their data, notably through better information and strengthening of their rights Strengthen the accountability of organisations that process personal data The GDPR imposes new requirements on organisations that process personal data and introduces the principle of accountability This obliges organisations to implement internal mechanisms and procedures to demonstrate compliance with data protection rules Harmonise all legislation at European level The GDPR harmonises the laws of Member States on the protection of personal data However, some specific local dispositions may exist Since the GDPR came into force, other countries outside the European Union have also changed their personal data protection regulations European Union May 2018 : General Data Protection Regulation Japan June 2020 : Act of Protection of Personal Information South Africa July 2020 : Protection of Personal Information Act Brazil August 2020 : General Data Protection Law New Zealand December 2020 : Privacy Act China November 2021 : Personal Information Protection Law As trusted third parties, banks are particularly sensitive to the protection of data they process Service providers Suppliers Other partners As Societe Generale employees, we are all affected in our daily lives by the use of personal data. Awareness of current regulations is therefore essential. Through this module, you will learn to : Master the basic concepts Be aware of who is involved Understand the application framework Learn the main principles to be followed Understand the rights of individuals over their data Recognise a data breach and respond appropriately And use your common sense, because the GDPR often comes down to the application of simple principles","title":"GDPR"},{"location":"office/myLearning/protectionOfPersonalData/#gdpr-who-what-how","text":"Personal data is any information relating to a natural person that can be used, directly or indirectly, to identify that specific person Personal data Private email address Personal phone number Health information Work email address Work phone number Salary amount Be careful, however, not to confuse personal data with private data! Whether in a private or professional context, data relating to an indentifiable person remains personal data In addition , there are special categories of personal data known as \"sensitive data\" within the meaning of the GDPR Racial or ethnic origin Political opinions Religious or philosophical beliefs Trade union membership Genetic data Biometric data Data concerning health Sex life or sexual orientation This sensitive data is subject to greater attention and it use is strictly regulated With the development of digital technology, new types of data have emerged : Cookies These are trackers that collect information related to browsing activity Sesame ID / Username IP address Browsing history When, alone or combined with other data, they can identify an individual, cookies are considered personal data and must comply with the regulations Now that we have seen what personal data is, let us turn to the concept of data processing Personal data processing is a use of that data, which can take several forms Collection Recording Modification Viewing Distribution The concept of \"processing\" is very broad : the simple fact of collecting or accessing data is considered as processing! This applies to both digital and paper files Examples of processing Payroll management Creation of a directory Direct marketing Physical access management The GDPR applies to organisations (companies associations, etc.) according to their location and/or the location of the individuals whose data they process An organisation located in the EEA is affected by the GDPR regardless of the location of the individuals whose data it processes By harmonising European legislation, the GDPR facilitates the free movement of personal data within the EEA However, transfers of personal data outside the EEA are strictly regulated Transfers of personal data to a non-EEA country are authorised if that country is recognised as \"adequate\" by the European Commission To be \"adequate\", a non-EEA country must be have legislation equivalent to the GDPR Even when personal data is stored within the EEA, the mere fact that it can be accessed from outside the EEA is considered to be a transfer outside the EEA, and must therefore be regulated!","title":"GDPR : Who, What, How?"},{"location":"office/myLearning/protectionOfPersonalData/#gdpr-participants","text":"Let's now look at the various participants involved in the protection of personal data Data Subject Data subjects are the natural persons whose personal data is processed. Examples Customer User Employee Shareholder Data controller A \"data controller\" is any natural or legal person who manages personal data The Group has identified more than 100 different Data Controllers, corresponding to different legal statuses (subsidiaries, branches, Service Units within SGPM, etc.) Collects the data Decides how the data is processed Data processor Any natural or legal person (supplier, service provider, etc.) who carries out all or part of the processing on behalf of a data controller is considered a data processor Data processors may be external or internal to the Group Thus, a Group entity may act both as data controller and data processor depending on the processing carried out The data processor's obligations in terms of personal data protection must be mentioned in the contract between the data processor and the data controller Data Protection Authority Data Protection Authorities are independent public authorities that monitor the application of data protection legislation Each EU Member State has its own Data Protection Authority Role of a Data Protection Authority Provide expert advice (guidelines, recommendations, etc.) on data protection issues Monitor the application of the regulations and impose sanctions in the event of non-compliance Deal with complaints about breaches of the GDPR and national data protection laws Data Protection Officer The Data Protection Officer (DPO) is designated by a data controller as the point of contract for the Data Protection Authority of their country DPO must be able to carry out their duties independently Within the Societe Generale Group, the DPOs are attached to the Compliance department The Group DPO (CPLE/DPO) reports to the Group Head of Compliance DPO's role Manage GDPR compliance within their organisation Support and advise the organisation's internal departments Cooperate with the Data Protection AUthorities Be the point of contact for data subjects","title":"GDPR participants"},{"location":"office/myLearning/protectionOfPersonalData/#main-principles","text":"Processing of personal data must respect the following principles: Be lawful (lawfulness) Let's start with the lawfulness of a processing activity In order to be lawful, a processing activity must be based on one of the six legal bases provided for by the GDPR Performance of a contract Processing is necessary for the performance of a contract to which the data subject is party This legal basis may apply When a contract is signed Example : Processing related to payroll (performance of the employment contract) For the purpose of signing a contract Example : Processing related to the provision of a quote Legal obligation Processing is necessary for compliance with a legal obligation to which the data controller is subject This legal basis is often used by the Group, as the bank operates in a highly regulated environment Example : KYC process, anti-money laundering, etc. Protecting the vital interests of the individual Processing is necessary in order to protect the vital interests of a natural person This legal basis is limited to situations where the lives of individuals are at stake, it is very rarely used in a banking context Example : Hospital admission, health crisis situation, etc. Performance of a public interest risk Processing is necessary for the performance of a public interest responsibility conferred on the data controller The use of this legal basis mainly concerns public authorities and is very rarely used within the bank Example : Specific processing related to the activities of public bodies, such as ministries, town halls, tax authorities, etc. Consent Data subjects must give free, specific and informed consent to the processing of their data They must be able to withdraw their consent at any time as easily as they gave it Consent must result from a positive act (no pre-ticked box) Legitimate interest This legal basis applies to processing activities that do not fall under the previous legal bases but are nonetheless necessary for the activity of the data controller The use of this legal basis requires the data controller to demonstrate and document that the interests pursued do not create an imbalance to the detriment of the rights and interests of the persons whose data is processed Example : Ensuring business development, guaranteeting the security of your assets Pursue defined and limited objectives (purpose limitation) Processing must have a specific and explicit purpose The data must not be used for purposes other than those for which it was collected Be carried out in a transparent manner (transparency) The controller must inform the data subjects of the processing it carries out on their data This information must be Concise Expressed in clear, simple, and easily understandable terms Easily accessible Use only the data that is strictly necessary (minimisation) Only data strictly necessary for the processing may be collected and used No data may be collected \"just in case\" Use accurate and up-to-data (accuracy) The personal data processed must be accurate and kept up to date Keep data for a limited time (storage limitation) The data collected must be kept for a limited period This period must be consistent and justified in relation to the purpose of the processing The data controller must therefore put in place a data erasure mechanism and ensure that the data is completely deleted at the end of this period Be secure (security) Personal data must be processed and stored in a secure manner to protect it from any risk of loss, disclosure, alteration, or destruction Examples : Password Backup Encryption A policy governing the security of personal data has been defined by the Group's IT Security department One of the main compliance tools is the record of processing activities The data controller lists all the personal data processing activities carried out by the organisation, gives a detailed description (purpose of the processing, data processed, operational methods, etc.) and ensures they are kept up to date Employee training management Management of customer's electronic account statements Organisation and management of competitions Management of access to premises Several participants are involved in this process Business / Operational staff For the needs of its activity, implements personal data processing in compliance with the Group's rules Alerts in the event of a data breach Participates, if necessary, in the processing of data subjects' rights requests Data management office Keeps the register of personal data processing activities of the entity concerned Provides level 1 support to operational staff Data Protection Officer / Data Protection Correspondent (LOD2 Compliance) Checks compliance, advises and supports those involved throughout the life of a processing activity Is the main contact for data protection authorities, particularly in the event of an inspection or complaint","title":"Main principles"},{"location":"office/myLearning/protectionOfPersonalData/#rights-of-individuals","text":"The GDPR has strengthened the rights of individuals in relation to the uses made of their data Individuals can exercise their rights with data controllers in a variety of ways : by post or email, orally (e.g. with an adviser), using dedicated digital pathways, etc. Right Of access The right of access allows the data subjects: To find out weather data relating to them is being processed by the data controller To obtain a copy in an intelligle format To obtain information about the processing of their data To rectification The right to rectification allows data subjects to obtain correction of inaccurate or incomplete information concerning them Modification or addition of data To object The right to object allows data subjects to object, on legitimate grounds, to the processing of their personal data by a data controller In the event of objection to direct marketing, the customer does not need to give reasons for the request To erasure The right to erasure allows data subjects to ask the data controller to erase personal data concerning them The data controller may refuse where legal or regulatory requirements require it to retain the data To restriction of processing The right to restriction of processing allows data subjects to request a temporart freeze on the use of some of their personal data in cases provided for by the regulations Data subjects must specify the data whose use they wish to limit and give reasons for the request For example, the processing of data may be \"frozen\" for the time needed to resolve a dispute or a challenge To portability The right to portability allows data subjects to request the recovery of some of their data, collected with their consent or for the purposes of a contract, in a structured digital format (e.g. Excel file) They may request that their data be transmitted directly to another organisation The data controller has one month to respond to a rights request This period may be extended by two months in certain cases (complex requests or volume of requests) and after notifying the data subject","title":"Rights of individuals"},{"location":"office/myLearning/protectionOfPersonalData/#summary","text":"Data protection regulations give rights to individuals whose data os being processed The organisation has one month to respond to requests to exercise these rights Upon receipt of a request to exercise a right, it should be forwarded to the line manager or directly to the Data Protection Correspondent (DPC) or the Data Protection Officer (DPO) of the relevant entity","title":"Summary"},{"location":"office/myLearning/protectionOfPersonalData/#data-breach","text":"The GDPR requires a data controller to: have mechanisms for detecting personal data breaches record breaches in a register analyse the impact of a breach on data subjects notify the Data Protection Authority in the event of a breach with a significant impact or even to notify the data subjects themselves If it detects a personal data breach, a data processor must notify its data controller activity After detecting a personal data breach, the data processor has 72 hours to notify the Data Protection Authority It is therefore essential to raise an alert immediately in case of a breach A personal data breach is a security incident : Of malicious origin or otherwise Occurring intentionally or unintentionally That comprises confidentiality, integrity or availability of personal data Examples of data breach include : Theft or loss of laptop containing customer information Mistakenly sending an email containing personal data to the wrong recipient A server failure preventing customers from accessing their personal data for a significant period Ransomware (taking personal data \"hostage\" by malicious encryption and then demanding a ransom)","title":"Data Breach"},{"location":"office/myLearning/protectionOfPersonalData/#summary_1","text":"A data breach in the sense of the GDPR is any type of incident resulting in a loss of confidentiality, integrity or availability of personal data As soon as a breach is identified, it should be reported as soon as possible to the Data Protection Correspondent of the area concerned The Correspondent is responsible for assessing the severity of the breach, in conjunction with the relevant teams, and for making a recommendation on the need to notify the Data Protection Authority and where appropriate, the data subjects When required, the notification must be made within 72 hours of the identification of the breach The Data Protection Correspondent must document the data breach in a register","title":"Summary"},{"location":"office/myLearning/sustainableITAwareness/","text":"Sustainable IT Awareness Learn about Sustainable IT The objective of this Sustainable IT awareness module is to: become aware of the digital world around us and its impacts understand the need to reconcile digital, ecological and societal transition identify the mechanisms and advantages of the convergence of these transitions, helping your organisation to grow, both in the present and the future and understand that a sustainable IT approach is part of the solution Qualities of Sustainable IT Innovative Sustainable Resilient Value-creating Sober Inclusive Note: Sustainable IT draws a present and a future for all citizens and organisations, it paints a world that is both human and economic, and ensures that our societies develop sustainably on our planet that has been deeply changed by human activity. The State of the Planet Although we all have a subjective vision of the world in which we live, we need to try and get to know our world better if we want to find the ambition and will to improve it So let's open out eyes to some of the facts that we have caused and that are degrading our Earth Climate Human activity and the greenhouse gas(GHG) emissions generated consequently have increased the Earth's temperature by 11 degrees Celsius since the beginning of the twentieth century. Biodiversity Terrestrial and marine species decreased by 39% between 1970 and 2010 as a result of overexploitation. Resources At the current rate of consumption, there will be no more gold, copper Humanity As early as 1972, the Meadows report, prepared by a team of MIT scientists and published by the Club of Rome, predicted that the limits to our growth would be reached in 2020. Fortunately, these facts stand alongside more optimistic ones, and it is not too late to act. On the environment side, there have also been some successes: if the current momentum of action is maintained, the ozone layer will be completely recovered by 2050. Digital technology, which can seem immaterial, also has effects on out planet We have more and more connected devices Before exploring the impacts of digital technology in thorough detail, let's pause for a minute and get a better perspective of our personal relationship with digital technology The number of smartphones bought in the world every second : 40 The number of emails sent every day : 281 billion The number of tweets posted every day : 50 million (More than 25 billion a year) The number of sheets of paper printed per day and per employee : 31 The number of connected devices in 2020 : 50 billion The number of watts consumed by each employee over 8 hours : 600 In the office, the amount of electronic waste generated is equivalent to throwing out a smartphone every 10 days Our use of the Internet also has a strong impact. Today, videos make up 80% of the data circulating online Digital technology and its environmental impacts Behind all these services, and beyond users and devices, we need data centres, telecommunications networks, servers, etc. Although devices are becoming more efficient, the growing amount of devices being produced makes their impact on the environment greater too. The environmental impacts of digital 3.8% of greenhouse gas emissions are produced by digital technology 0.2% of water consumption is used for digital purposes 10% of electricity is consumed by digital technology Environmental impact of an equipment Manufacturing : 80% Use : 15% End of life : 5% Despite these negative aspects, we mustn't forget that digital technology enables us to develop digital tools and services that are essential for the energetic transition to other sources of energy, as they help to: Massively limiting travel(throough video-conferencing, teleworking) Increase effeciency and optimise our energy consumption Model biodiversity so that we can protect it better Make territories and organisations more Resilient Digital technology therefore provides both problems and solutions. The two-sided nature goes beyond the effects on natural environments Digital technology has economic and societal impacts This dual aspect manifests itself : At a economical level Devices, which can be less robust, are becoming disposable goods Consumptionis higher because these products are more affordable. This is what we call the 'rebound effect' But the progress we are making menas that new, more robust and more sustainable devices are being made New economies and new ways of working are emerging Jobs are being created At a societal level In some countries, across the entire production chain manufacturing devices, the workers rights are not respected Digital technology can be addictive and socially isolating We do not know the full extent of the effects that our screens and their waves(SAR) can have in our health Some unrecycled electronic waste travels tens of thousands of kilometres, sometimes illegally to be destroyed Digital technology isolates those living in geographical areas without coverage. This is known as digital divide But digital technology enables us to work or to search for work remotely. This means we can develop differenct areas. And that we can stay in touch with our loved ones all over the world Digital technology can be a way of inclusion, especially for people with visual, hearing disabilities. This is known as e-accessibility Digital technology has political impacts In terms of politics, digital technology also has positive and negative effects The need to procure materials for digital technology, some of which are increasingly rare, such as cobalt and lithium, causes political tensions between countries Digital technology is not only regulated for companies but also for suppliers and within the supply chain However, European and International bodies have worked to make digital technology increasingly regulated International Conventions There are several global conventions that minimise the impact of digital technologies, including the Baset Convention, which stipulates that European hazardous waste must be managed within Europe European directives and regulations There are several European directives, both current and in development (directive ecoconception 2009/125/CE), that help to regulate digital technology The 'Ecodesign' directive to give some servers environmental labelling in the near future The 'Batteries' directive to make batteries replaceable by the user The RoHS directive (Restriction of the use of certain Hazardous Substances) to limit harmful products in our electrical and electronic devices In France, there are now laws on circular economies and planned obsolescence Standards For organisations wanting to take a more voluntary approach, there are sevaral standards that can help them create more sustainable devices and services, such as the ISO 26000 standard on societal responsibility, ISO 14000, etc. Online data, GDPR, RGAA, digital sovereignty, etc. Digital technology makes it possible to collect a considerable amount of data about our lives, how we use the technology, our customer interests, etc. and makes us question the ways in which we use these digital technologies The GDPR is a European regulatory text that has governed the processing of personal data on an equal basis across the European Union since May 2018 The RGAA is a standard to make digital tools accessible The principle of digital sovereignty means avoiding any dominance relating to the use of our online data Video surveillance We are being filmed by and ever-increasing number of cameras, which raises questions about the interaction with our private life To control this, several regulations govern the use of video surveillance, particularly in public spaces Taking environmental, economic and social aspects into account is the essence of Sustainable development Sustainable development and Sustainable IT Sustainable development is the framework of thinking that has emerged as people have become more aware of the ecological impacts, incorporating the constraints of how society operates It's about 'development that meets the needs of the present without compromising the ability of future generations to meet their own needs'. Society : Meeting needs in health, education, housing, employment, prevention of exclusion, equity Economy : To create wealth and improve material living conditions Environment : Preserve species diversity and natural and energy resources Fair : Society/Economy Liveable : Society/Environment Viable : Economy/Environment Sustainable : Society/Economy/Environment At corporate level, sustainable development is implemented within the framework of a Corporate Social Responsibility (CSR) policy CSR refers to when companies voluntarily take into consideration the social and ethical issues involved in their activities, which are broadly understood to include : economic activities, internet interactions(employees, managers, shareholders) and external interactions (suppliers, customers, others). The solutions : Sustainable IT IT for Green Use digital technology to limit the environmental impact of other activities Produce detailed maps to monitor Swedish forests threatened by the bark beetle Green for IT The Voltaire project consists in immersing servers in liquid to cool them down. This has numerous benefits (cost, maintenance) Human for IT Limit the social impact of digital technology, such as by providing Internet access to as many people as possible Committing to trustworthy artificial intelligence IT for Human Use digital technology to reduce the social impact of other activities Using an application to manage the light intensity in open-plan offices to prevent visual fatigue How can we act? Now it's time to take action. We have shown you why it's in your interests to take action for more Sustainable IT Convinced? Then let's move on to the actions you can take : as you're about to see, the first steps are simple and natural Avoid systematically purchasing and replacing unnecessary equipement Ensure that the services we use and create are eco-designed to prevent the equipment becoming obsolete and having to be replaced Then we can look at : Repairing Reusing Identifying labels Buying secondhand goods As for services, bearing in mind that online video accounts for more than 80% of the data circulating on the Internet, we can : Avoid video streaming and go for audio streaming instead Stop videos from playing automatically Decrease the quality of our photos and videos, circulate less data, on the cloud, for instance. We can also : limit and clean our email inboxes and our cloud turn off our devices So that we feel confortable online, we need to protect our personal data When your organization (companies, VSBs/SMEs, associations, institutions, suppliers, but also farmers, distributors, communities, employees, etc.) next takes on a digital project, you will now be able to: Present the benefits of Sustainable IT : innovation, cost reduction, digital sobriety, image, compliance with regulations, etc. Include social and environmental impact indicators Encourage the use of this approach Propose to eco-design new objects and services To conclude, what needs to be remembered? Our aim in this awareness capsule was to present Sustainable IT as a framework for thining and action, helping to bring together environmental and digital transitions We started by showing you the two-sided nature of digital technology and its social, environmental, economic and political impacts We summarised what Sustainable Development is and how Sustainable IT can be a digital offshoot of it Then we gave you a quick overview of what it's about and the actions involved, the eco-tips that you can put into practice within your organisations (company, VSBs/SMEs, associations, etc.) We can easily summarize these eco-gestures as : Refuse Reduce Reuse Recycle But Sustainable IT is about much more than that Digital inclusion Circular Economy Ecodesign e-accessibility","title":"Sustainable IT Awareness"},{"location":"office/myLearning/sustainableITAwareness/#sustainable-it-awareness","text":"","title":"Sustainable IT Awareness"},{"location":"office/myLearning/sustainableITAwareness/#learn-about-sustainable-it","text":"The objective of this Sustainable IT awareness module is to: become aware of the digital world around us and its impacts understand the need to reconcile digital, ecological and societal transition identify the mechanisms and advantages of the convergence of these transitions, helping your organisation to grow, both in the present and the future and understand that a sustainable IT approach is part of the solution Qualities of Sustainable IT Innovative Sustainable Resilient Value-creating Sober Inclusive Note: Sustainable IT draws a present and a future for all citizens and organisations, it paints a world that is both human and economic, and ensures that our societies develop sustainably on our planet that has been deeply changed by human activity.","title":"Learn about Sustainable IT"},{"location":"office/myLearning/sustainableITAwareness/#the-state-of-the-planet","text":"Although we all have a subjective vision of the world in which we live, we need to try and get to know our world better if we want to find the ambition and will to improve it So let's open out eyes to some of the facts that we have caused and that are degrading our Earth Climate Human activity and the greenhouse gas(GHG) emissions generated consequently have increased the Earth's temperature by 11 degrees Celsius since the beginning of the twentieth century. Biodiversity Terrestrial and marine species decreased by 39% between 1970 and 2010 as a result of overexploitation. Resources At the current rate of consumption, there will be no more gold, copper Humanity As early as 1972, the Meadows report, prepared by a team of MIT scientists and published by the Club of Rome, predicted that the limits to our growth would be reached in 2020. Fortunately, these facts stand alongside more optimistic ones, and it is not too late to act. On the environment side, there have also been some successes: if the current momentum of action is maintained, the ozone layer will be completely recovered by 2050. Digital technology, which can seem immaterial, also has effects on out planet","title":"The State of the Planet"},{"location":"office/myLearning/sustainableITAwareness/#we-have-more-and-more-connected-devices","text":"Before exploring the impacts of digital technology in thorough detail, let's pause for a minute and get a better perspective of our personal relationship with digital technology The number of smartphones bought in the world every second : 40 The number of emails sent every day : 281 billion The number of tweets posted every day : 50 million (More than 25 billion a year) The number of sheets of paper printed per day and per employee : 31 The number of connected devices in 2020 : 50 billion The number of watts consumed by each employee over 8 hours : 600 In the office, the amount of electronic waste generated is equivalent to throwing out a smartphone every 10 days Our use of the Internet also has a strong impact. Today, videos make up 80% of the data circulating online","title":"We have more and more connected devices"},{"location":"office/myLearning/sustainableITAwareness/#digital-technology-and-its-environmental-impacts","text":"Behind all these services, and beyond users and devices, we need data centres, telecommunications networks, servers, etc. Although devices are becoming more efficient, the growing amount of devices being produced makes their impact on the environment greater too. The environmental impacts of digital 3.8% of greenhouse gas emissions are produced by digital technology 0.2% of water consumption is used for digital purposes 10% of electricity is consumed by digital technology Environmental impact of an equipment Manufacturing : 80% Use : 15% End of life : 5% Despite these negative aspects, we mustn't forget that digital technology enables us to develop digital tools and services that are essential for the energetic transition to other sources of energy, as they help to: Massively limiting travel(throough video-conferencing, teleworking) Increase effeciency and optimise our energy consumption Model biodiversity so that we can protect it better Make territories and organisations more Resilient Digital technology therefore provides both problems and solutions. The two-sided nature goes beyond the effects on natural environments","title":"Digital technology and its environmental impacts"},{"location":"office/myLearning/sustainableITAwareness/#digital-technology-has-economic-and-societal-impacts","text":"This dual aspect manifests itself : At a economical level Devices, which can be less robust, are becoming disposable goods Consumptionis higher because these products are more affordable. This is what we call the 'rebound effect' But the progress we are making menas that new, more robust and more sustainable devices are being made New economies and new ways of working are emerging Jobs are being created At a societal level In some countries, across the entire production chain manufacturing devices, the workers rights are not respected Digital technology can be addictive and socially isolating We do not know the full extent of the effects that our screens and their waves(SAR) can have in our health Some unrecycled electronic waste travels tens of thousands of kilometres, sometimes illegally to be destroyed Digital technology isolates those living in geographical areas without coverage. This is known as digital divide But digital technology enables us to work or to search for work remotely. This means we can develop differenct areas. And that we can stay in touch with our loved ones all over the world Digital technology can be a way of inclusion, especially for people with visual, hearing disabilities. This is known as e-accessibility","title":"Digital technology has economic and societal impacts"},{"location":"office/myLearning/sustainableITAwareness/#digital-technology-has-political-impacts","text":"In terms of politics, digital technology also has positive and negative effects The need to procure materials for digital technology, some of which are increasingly rare, such as cobalt and lithium, causes political tensions between countries Digital technology is not only regulated for companies but also for suppliers and within the supply chain However, European and International bodies have worked to make digital technology increasingly regulated International Conventions There are several global conventions that minimise the impact of digital technologies, including the Baset Convention, which stipulates that European hazardous waste must be managed within Europe European directives and regulations There are several European directives, both current and in development (directive ecoconception 2009/125/CE), that help to regulate digital technology The 'Ecodesign' directive to give some servers environmental labelling in the near future The 'Batteries' directive to make batteries replaceable by the user The RoHS directive (Restriction of the use of certain Hazardous Substances) to limit harmful products in our electrical and electronic devices In France, there are now laws on circular economies and planned obsolescence Standards For organisations wanting to take a more voluntary approach, there are sevaral standards that can help them create more sustainable devices and services, such as the ISO 26000 standard on societal responsibility, ISO 14000, etc. Online data, GDPR, RGAA, digital sovereignty, etc. Digital technology makes it possible to collect a considerable amount of data about our lives, how we use the technology, our customer interests, etc. and makes us question the ways in which we use these digital technologies The GDPR is a European regulatory text that has governed the processing of personal data on an equal basis across the European Union since May 2018 The RGAA is a standard to make digital tools accessible The principle of digital sovereignty means avoiding any dominance relating to the use of our online data Video surveillance We are being filmed by and ever-increasing number of cameras, which raises questions about the interaction with our private life To control this, several regulations govern the use of video surveillance, particularly in public spaces Taking environmental, economic and social aspects into account is the essence of Sustainable development","title":"Digital technology has political impacts"},{"location":"office/myLearning/sustainableITAwareness/#sustainable-development-and-sustainable-it","text":"Sustainable development is the framework of thinking that has emerged as people have become more aware of the ecological impacts, incorporating the constraints of how society operates It's about 'development that meets the needs of the present without compromising the ability of future generations to meet their own needs'. Society : Meeting needs in health, education, housing, employment, prevention of exclusion, equity Economy : To create wealth and improve material living conditions Environment : Preserve species diversity and natural and energy resources Fair : Society/Economy Liveable : Society/Environment Viable : Economy/Environment Sustainable : Society/Economy/Environment At corporate level, sustainable development is implemented within the framework of a Corporate Social Responsibility (CSR) policy CSR refers to when companies voluntarily take into consideration the social and ethical issues involved in their activities, which are broadly understood to include : economic activities, internet interactions(employees, managers, shareholders) and external interactions (suppliers, customers, others).","title":"Sustainable development and Sustainable IT"},{"location":"office/myLearning/sustainableITAwareness/#the-solutions-sustainable-it","text":"IT for Green Use digital technology to limit the environmental impact of other activities Produce detailed maps to monitor Swedish forests threatened by the bark beetle Green for IT The Voltaire project consists in immersing servers in liquid to cool them down. This has numerous benefits (cost, maintenance) Human for IT Limit the social impact of digital technology, such as by providing Internet access to as many people as possible Committing to trustworthy artificial intelligence IT for Human Use digital technology to reduce the social impact of other activities Using an application to manage the light intensity in open-plan offices to prevent visual fatigue","title":"The solutions : Sustainable IT"},{"location":"office/myLearning/sustainableITAwareness/#how-can-we-act","text":"Now it's time to take action. We have shown you why it's in your interests to take action for more Sustainable IT Convinced? Then let's move on to the actions you can take : as you're about to see, the first steps are simple and natural Avoid systematically purchasing and replacing unnecessary equipement Ensure that the services we use and create are eco-designed to prevent the equipment becoming obsolete and having to be replaced Then we can look at : Repairing Reusing Identifying labels Buying secondhand goods As for services, bearing in mind that online video accounts for more than 80% of the data circulating on the Internet, we can : Avoid video streaming and go for audio streaming instead Stop videos from playing automatically Decrease the quality of our photos and videos, circulate less data, on the cloud, for instance. We can also : limit and clean our email inboxes and our cloud turn off our devices So that we feel confortable online, we need to protect our personal data When your organization (companies, VSBs/SMEs, associations, institutions, suppliers, but also farmers, distributors, communities, employees, etc.) next takes on a digital project, you will now be able to: Present the benefits of Sustainable IT : innovation, cost reduction, digital sobriety, image, compliance with regulations, etc. Include social and environmental impact indicators Encourage the use of this approach Propose to eco-design new objects and services","title":"How can we act?"},{"location":"office/myLearning/sustainableITAwareness/#to-conclude-what-needs-to-be-remembered","text":"Our aim in this awareness capsule was to present Sustainable IT as a framework for thining and action, helping to bring together environmental and digital transitions We started by showing you the two-sided nature of digital technology and its social, environmental, economic and political impacts We summarised what Sustainable Development is and how Sustainable IT can be a digital offshoot of it Then we gave you a quick overview of what it's about and the actions involved, the eco-tips that you can put into practice within your organisations (company, VSBs/SMEs, associations, etc.) We can easily summarize these eco-gestures as : Refuse Reduce Reuse Recycle But Sustainable IT is about much more than that Digital inclusion Circular Economy Ecodesign e-accessibility","title":"To conclude, what needs to be remembered?"},{"location":"pluralsight/pluralsight/","text":"PluralSight courses This documentation contains the contents of PluralSight courses. List of PluralSight Courses Blinc Phase 1 Fundamentals of Java Generics GIT JDBC Java Platform Multi Threading Shell Scripting TDD The Big Picture Phase 2 Java Web Fundamentals Spring : The Big Picture Paths Domain Driven Design Beginner Clean Architecture : Patterns, Practices and Principles Modern Software Architecture: Domain Models, CQRS, and Event Sourcing Java Language Fundamentals Beginner Modern Java - The Big Picture PMI-ACP Agile exam Introduction to Agile Project Management and the PMI-ACP Exam Solo Courses Java From Collections to Streams using Lambda Expressions","title":"PluralSight Contents"},{"location":"pluralsight/pluralsight/#pluralsight-courses","text":"This documentation contains the contents of PluralSight courses.","title":"PluralSight courses"},{"location":"pluralsight/pluralsight/#list-of-pluralsight-courses","text":"Blinc Phase 1 Fundamentals of Java Generics GIT JDBC Java Platform Multi Threading Shell Scripting TDD The Big Picture Phase 2 Java Web Fundamentals Spring : The Big Picture Paths Domain Driven Design Beginner Clean Architecture : Patterns, Practices and Principles Modern Software Architecture: Domain Models, CQRS, and Event Sourcing Java Language Fundamentals Beginner Modern Java - The Big Picture PMI-ACP Agile exam Introduction to Agile Project Management and the PMI-ACP Exam Solo Courses Java From Collections to Streams using Lambda Expressions","title":"List of PluralSight Courses"},{"location":"pluralsight/blinc/phase1/fundamentalsOfJava/","text":"Fundamentals of Java Introduction and setting up the environment Creating and running Java Apps Java file Java Developement kit tools Java App Java Runtime Environment Host Environment Summary Java is a language and a runtime environment Specific environment features may vary (Java SE/ME/EE, JavaFX, Android) Language remains pretty consistent End-users require the Java Runtime Environment(JRE) Developers require the Java Development Kit(JDK) Many Integrated Developement Environemts(IDE) are available Eclipse IntelliJ Netbeans Creating a Simple App Summary Execute programs from tnhe command line with the \"java\" command Remember to use the full class name including the package name On Windows must include the JRE bin folder in the Path environment variable Programs are made up of statements Statements end with a semicolon Parts separated by zero or more whitespaces Use comments to add notes and hide statements from the compiler Packages provide organization Assure uniqueness Modt IDEs tie source code file structure to package name Variables, Data types and Math Operator Variables Named data storage Strongly typed Value can be modified Naming Variables Variable na ing is based on a combination of rules and conventions Rules allow the use of letters, numbers, $ and _ By convention only letters and numbers are used Rules require that first character is not a numbers By convention it is always a letter By convention follow the style often referred to as \"Camel Case\" First letter is lower case Start of each word after the first is upper case All other letters are lower case Primitive data types Built into the language Foundation of all other types Four categories of primitive types Integer Floating point Character Boolean Integer types byte (8 bits) short (16 bits) int (32 bits) long (64 bits) Floating point types Implementation of IEEE 754 floating point standard Stores values containing a fractional portion Supports positive, negative and zero values Types Float (32 bits) Double (64 bits) Character and Boolean Types The char type stores a single Unicode character Literal values placed between single quotes For Unicode code points, use \\u followed by 4-digit hex value The boolean type stores true/false values Literal values are true and false Arithmetic operators Basic operators Add (+) Substract (-) Multiply (*) Divide (/) Modulus (%) Prefix/postfix operators ++ increments value by 1 -- decrements value by 1 As prefix applies operation before returning value As postfix applies operation after returning value Compound assignment operators Combines an operationand assignment Applies result of right side to left side Stores that result in variable on left side Operator precedence Operators are evaluated in a well-defined order Postfix Prefix Multiplicative Additive Operators of equal precedence are evaluated from left to right Can override precedence with parenthesis Nested parenthesis evaluated from the inside out Type conversion Implicit type conversion Conversions performed automatically by the compiler Widening conversions are automatic Mixed integer sizes Uses largest integer in equation Mixed floating point sizes Uses double Mixed integer and floating point Uses largest floating point in equation Explicit type conversion Conversions performed explicitly in code with cast operator Can perform widening and narrowing Floating point to integer drops fraction Use caution with narrowing conversions Integer to floating point can lose precision Summary Variables are stringly typed in Java Primitive types Integer types, floating point types, char type, boolean type Math operators Basic operators, postfix/prefix operators, compound assignment operators Math operators follow a well-defined order of precedence Type conversions Compiler can automatically apply widening type conversions Use type casting to explicitly perform type conversions Conditional Logic, Looping and Arrays Adding conditional logic Relational operators Conditional assignments The if statement Logical operators Relational operators Greater than (>) Greater than or equal to (>=) Less than (<) Less than or equal to (<=) Equal to (==) Not equal to (!=) Conditional assignment Assign a value to a variable based on the result of a condition result = condition ? true-value : false-value ; If-else Statement An if statement conditionally executes a statement if (condition) true-statement; else false-statement; * The optional else clause executes a statement when the if condition is false * If-else statements chained together are evaluated in order until one is true if (condition-1) true-statement; else if (condition-2) true-statement; . . . else if (condition-N) true-statement; else false-statement; Block statement A block statement groups statements into a compound statement { statement-1; statement-2; . . . statement-N; } Block statements and Variable Scope A variable declared within a block is not visible outside of the block A variable's range of visibility is known as the variable's scope Logical operators And (&) Or (|) Exclusive or (XOR) (^) Negation (!) Conditional logical operators * Conditional and (&&) * Conditional or (||) Resolve following conceptually similar rules as non-conditional and/or Only execute the right-side if needed to determine the result && only executes right-side if left-side is true || only executes right-side if left-side is false While Loop Repeatedly executes a statement as long as the condition is true Condition checked at loop Start Statement may never execute while (condition) statement; Do-while Loop Repeatedly executes a statement as long as the condition is true Condition checked at loop end Statement always executes at least once do statement; while (condition); For Loop Repeatedly executes a statement as long as the condition is true Condition checked at loop start Provides simplified notation for loop control values for(initialize; condition; update) statement; Arrays Provides an ordered collection of elements Each element accessed via an index Indexes range from 0 to number-of-elemets minus 1 Number of elements can be found via array's length value For-each Loop Executes a statement once for each member in an array Handles getting collection length Handles accessing each value for (loop-variable-declaration : array) statement ; Switch Transfers control to a statement based on a value Simplifies testing against multiple possible matches Only primitive types supported are char and integers A match can execute more than one statement Use break to avoid \"falling through\" Can optionally include default to handle any unmatches values switch (test-value) { case value-1: statements case value-2: statements . . . case value-n: statements } Summary Use the if-else statement to provide conditional logic If-else statements can be chained together Block statements use brackets to group statements Variables declared within a block are not visible outside of the block Both while and do-while loops execute as long as a condition is true The do-while loop body always executes at least once The for loop provides simplified notation for loop initialization and control For-each statement handles details of executing once for each array member Switch statement simplifies notation of testing against multiple matches Representing Complex Types with Classes Classes in Java Java is an object-orientated language Objects encapsulates data, operations, and usage semantics Allows storage and manipulation details to be hidden Separates \"what\" is to be done from \"how\" it is done Classes provide a structure for describing and creating Objects A class is a template for creating an object Declared with the class keyword followed by the class name Java source file name nornally has same name as the class Body of the class is contained within brackets A class is made up of both state and executable code Fields Store object state Methods Executable code that manipulates state and performs operations Constructors Executable code used during object creation to set the initial state Using Classes Use the new keyword to create a class instance (a.k.a an object) Allocates the memory described by the class Returns a reference to the allocated memory Encapsulation and Access Modifiers The internal representation of an object is generally hidden This concept is known as encapsulation Java uses access modifiers to achieve encapsulation Basic access modifiers Public Private Protected Default Naming classes Class names follow the same rules as variable names Class name conventions are similar to variables with some diferrences Use only letters and numbers First character is always a letter Follow the style often referred to as \"Pascal Case\" Start of each word, including the first, is upper case All other letters are lower case Use simple, descriptive nouns Avoid abbreviations unless abbreviation's use is more common than full name Method basics Executable code that manipulates state and performs operations Name Same rules and conventions as variables Should be a verb or action Return type Use void when no value returned Types parameter list Can be empty Body contained with brackets return-type name (typwd-parameter-list){ statements } Exiting from a Method A method exits for one of the three reasons The end of the method is reached A return statement is encountered An error occuers Unless there's an error, control returns to the method caller Methods return values A method returns a single value A primitive value A reference to an object A reference to an array Arrays are objects Special references : this and null Java provides special references with predefined meanings this is an implicit reference to the current object Useful for reducing ambiguity Allows an object to pass itself as a parameter null is a reference literal Represents an uncreated object Can be assigned to any reference variable Field encapsulation In most cases, a class fields should not be directly accessible outside of the class Helps to hide implementation details Use methods to control field access Accessors and Mutators Use the accessor/mutator pattern to control field access Accessor retrieves field value Also called getter Method name : getFieldName Mutator modifies field value Also called setter Method name : setFieldName Summary A class is a template for creating an object Declared wuth class keyword Class instances (a.k.a objects) allocated with new keyword Classes are reference types Use access modifiers to control encapsulation Methods manipulates state and performs operations Use return keyword to exit and/or return a value Fields store object state Interaction normally controlled through accessors(getters) and mutators(setters) Class Initializers and Constructors Establishing Initial State When an object is created, it is expected to be in a useful state Often the default state established by Java is not enough The object may need to set values or execute code Mechanisms for Establishing Initial State Java provides 3 mechanisms for establishing initial state Field initializers Constructors Initialization blocks Field Initial State A field's initial state is established as part of object construction Fields receive a \"zero\" value by default Field initializers Allow us to specify a field's initial value as part of its declaration Can be a simple assignment Can be an equation Can reference other fields Can be a method call Constructors Executable code used during object creation to set the initial state Have no return type Every class has at least one constructor If no explicit constructors, Java provides one A class can have multiple constructors Each with a different parameter list Chaining constructors One constructor can call another Use the this keyword followed by parameter list Must be the first line Constructor visibility Use access modifiers to control constructor visibility Limits what code can perform specific creations Initialization blocks Initilization blocks shared across all constructors Executed as if the code were placed at the start of each constructor Enclose statements in brackets outside of any method or constructor Initialization and Construction Order Field Initilization * Initilization Block * Constructor Summary Objects should be created in some useful state Field initializers provide an initial value as part of the declaration Every class has at least one constructor If no explicit constructor, Java provides one with no arguments You can provide multiple constructors with different argument lists One constructor can call another Call must be first line Initilization blocks share code across constructors Keep the initialization and construction order in mind A Closer Look at Parameters Parameter Immutability Parameters are passed by making a copy of the value Known as passing \"by-value\" Changes made to passed value are not visible outside of method Changes made to members of passed class instances are visible outside of method Overloading A class may have multiple versions of its constructor or methods Known as \"overloading\" Each constructor and method must have a unique signature Signature is made up of 3 parts Affected by number of parameters Affected by type of each parameter Affected by name Variable Number of Parameters A method can be declared to accept a varying number of parameter values Place an ellipse after parameter type Can only be the last parameter Method receives values as an array Summary Parameters are immutable Changes made to passed value are not visible outside of method Changes made to members os passed class instances are visible outside of method A class may have multiple versions of its constructor or methods Each must have a unique signature Sugnature includes name, number of parameters, type of each parameter A method can be declared to accept varying number of parameter values Values received as an array Must be last parameter Class Inheritance Class Inheritance A class can be declared to inherit from another class Use the \"extends\" keyword Derived class has the characteristics of basic class Can add specialization Can be assigned to base class types references Fields hide base class fields with same name Methods can override base class methods with same signature Object class The object class is the rootof the Java class hierarchy Every class has the characteristics of the Object class Useful for declaring variables, fields and parameters that can reference any class or array instance Defines a number of methods that are inherited by al objects Every class inherits directly or indeirectly from the Object class Object class methods clone Create a new object instance that duplicates the current instance hashCode Get a hash code for the current instance getClass Return type information for the current instance finalize Handle special resource cleanup scenarios toString Return string of characters representing the current instance equals Compare another object to the current instancec for equality Special reference : super Similar to this, super is an implicit reference to the current object super treats the object as if it is an instance of its base class Useful for accessing base class members that have been overridden Control inheritance and overriding By default all classes can be extended and derived classes have the option to use or override inherited methods A class can change these defaults Use final to prevent inheriting and/or overriding Use abstract to require inheriting and/or overriding Inheritance and Constructors Constructors are not inherited A base class constructor must always be called By default, base class' no-argument constructor is called Can explicitly call a base class constructor using super followed by parameter list Must be first line of constructor Summary Inheritance allows a new class to be defined with the characteristics of another Use the extend keyword Derived class can override base class methods Optionally use @Override annotation All classes derive from Object class either directly or indirectly By default, object references are only equal when referencing the same instance Can override Object.equals to provide new behavior super accesses current object as if instance of base class final and abstract provide control over class inheritance and method overriding Constructors are not inherited More About Data Types String class The string class stores a sequence of Unicode characters Stored using UTF-16 encoding Literals are enclosed in double quotes (\" \") Values can be concatenated using + and += String objects are immutable String class methods Length length String for non-string valueof Create new strings from existing concat replace toLowerCase toUpperCase trim split Formatting format Extract substring chatAt substring Test substring contains endsWith startWith indexOf lastIndexOf Comparison compareTo compareToIgnoreCase isEmpty equals equalsIgnoreCase Converting non-string types to strings We often need to convert non-string types into strings String.valueOf provides overrides to handle most types Conversions often happen implicitly Class conversions controlled by the class' toString method StringBuilder StringBuilder provides mutable string buffer For best performance pre-size buffer Will automatically grow if needed Most common methods append insert Classes vs Primitives Classes provide convenience Common interaction through Object class Fields and methods specific to the type Incurs an overhead cost Primitives provide efficiency Cannot be treated as Object Cannot expose fields or methods Lightweight Primitive wrapper classes Capabilities and overhead of classes Hold primitive values All wrapper classes are immutable Primitive wrapper class hierarchy Object Boolean Number Byte Short Integer Long Float Double Character Wrapper class and primitive conversion Java provides a number of ways to handle conversions Common conversions handled automatically Wrapper classes provide methods for explicit conversions Primitive to wrapper (Boxing) Wrapper to primitive (Unboxing) String to primitive (Parse) Wrapper class members Byte, Short, Integer, Long MIN_VALUE MAX_VALUE bitCount toBinaryString Float, Double MIN_VALUE MAX_VALUE isInfinite isNaN Character MIN_VALUE MAX_VALUE isDigit isLetter Boolean TRUE FALSE Wrapper class equality Boxing conversions that always return the same wrapper class instance Final fields Marking a field as final prevents it from being changed once assigned A simple final field must be set during creation of an object instance Can be set with field initializer, initialization block, or constructor Adding the static modifier makes a final field a named constant Cannot be set by an object instance Enumeration types Enumeration types useful for defining a type with a finite list of valid values Declare with enum keyword Provide a comma-separated value list Summary String class stores an immutable sequence of Unicode characters Implement toString method to provide conversion to a string StringBuilder class provides an efficient way to manipulate string values Primitive wrapper classes bring class capabilities to primitive values Wrapper classes much less efficient than primitive types Final fields prevent a value from being changed once assigned Simple final fields must be set during object instance creation Static final fields act as named constants Enumeration types useful for defining a type with a finite list of values Exceptions and Error Handling Error handling with Exceptions Error handling needs to be implicit in application development The traditional approach of checking error codes/ flags is too intursive Exceptions provide a non-intursive way to signal errors try/catch/finally provides a structured way to handle exceptions The try block contains the \"normal\" code to execute Block executes to completion unless an exception is thrown The catch block contains the error handling code Block executes only if matching exception is thrown The finally block contains cleanup code if needed Runs in all cases following try or catch block Exception class hierarchy Object Throwable Error (Virtual machine related errors) Exception Runtime exception (Unchecked exception) Checked exception Types exceptions Exceptions can be handled by type Each exception type can have a separate catch block Each catch is tested in order from top to bottom First assignable catch is selected Start catch blocks with most specific exception types Exceptions and methods Exceptions propagate up the call stack Can cross method boundaries Exceptions are part of a methods's contract Method is responsible for any checked exceptions that might occur Catch the exception Document that the exception might occur use the throws clause Exceptions and method overriding The throws clause of an overriding method must be compatible with the throws clause of the overriden method Can exclude exceptions Can have the same exception Can have a derived exception Throwing exceptions Our code can throw exceptions (Using the throw keyword) Must create exception instance before throwing Most exception classes provide a constructor that accepts a String message or other detail When caused by another exception, include originating exception All exception classes support initCause method Many provide a constructor that accepts the originating exception Creating a custom exception type In most cases better to use esisting exception type Normally inherit directly from Exception class Makes them checked exceptions Constructors are often their only members Mostly required functionality is inherited Constructor that accepts required detail Constructor that accepts required detaila and originating exception Summary Exceptions provide a non-intrusive way to signal errors try/catch/finally provide a structured way to handle exceptions Exceptions are caught by type Can have separate vatch statement for differing exception types Catch from most specific type to least specific Raise exceptions using throw Methods must declare any unhandled checked exceptions using throws Can create custom exception types Normally inherit from Exception Working with Packages What is a Package? A package is a group of related types Create a namespace Provide an access boundary Act as a unit of distribution Declaring packages Each source file identifies the associated package Use the package keyword Package declaration must appear before any type declarations Applies to all types within that source file Package creates a Namespace Package name is part of the type-name Convention creates unique package name Follows reverse domain name structure Type name is qualified by package name Detemnining a Type's Package Compiler needs to know each type's package Explicitly qualifying each type is impractical Java offers several alternatives to explicitly qualifying types Allows use of a type's simple name in code Types in current package do not need to be qualified Types in the java.lang package do no need to be qualified Use type imports Type imports Type imports guide compiler to map simple names to qualified names (use import keyword) Single type import Provides mapping for a single type Preferred way to import types Most modern IDEs will add automatically Import on demand Provides mapping for all types in a package Use with caution Exposes code to potential breakage from changes in referenced packages Limiting access to Package Content Packages can serve as an access boundary Often referred to as package private Useful for creatingtypes and features to support functionality provided by the package Types and features are not meant to be used stand-alone Can apply to a type Entire type is inaccessible outside of the package Can apply to type members Specific members of an otherwise accessible type are inaccessible outside of the package Access modifiers public private protected Packages provide a Unit of distribution packages provide a predictable software structure Class files organized in hierarchical folders reflecting the package name Each part of the package name is a separate folder Archive files Package folder structure can be placed into an acrhive file (jar file) Places package fo,der structure into a single file Optionally includes a manifest providing information regarding archive content List of name-vale pairs Commonly used to define startup class Summary A package is a group of related types Package declaration must appear in source file before any type declarations Type name qualified by package name Use import statements to map simple names to qualified names Packages serve as an access boundary Packages simplify distribution Types organized hierarchically according to the package name Archive files store package hierarchy in a single file Creating abstract relationships with Interfaces What is an interface An interface defines a contract and provides no implementation Classes implement interfaces Express that the class conforms to the contract Interfaces dont limit other aspects of the class implementation Some interfaces require additional type information (like generics) Classes are free to implement multiple interfaces Summary An interface defines a contract Provides no implementation Can include methods and constants Classes implement interfaces Classes are able to implement multiple interfaces Interfaces are able to extend other interfaces Implementing an extended interface implicitly implements the base Stitic members, nested types, and anonymous classes Static members Static members are shared class-wide Declared using the static keyword Field A value not associated with a specific instance All instance access the same value Method Performs an action not tied to a specific instance Can access static fields only Static import Provides short hand for accessing static members Statuc initialization blocks Static initialization blocks perform one-time type initialization Statements enclosed in brackets outside of any method or constructor Cannot access instance members Must handle all checked exceptions Nested types A nested type is a type declared within another type Classes can be declared within classes and interfaces Interfaces can be declared within classes and interfaces Nested types are members od the enclosing type private members of the enclosing type are visible to the nested type Nested types support all member access modifiers public package private protected private Nested types serve differing purposes Structure and scoping Static classes nested within classes All classes nested within interfaces All nested interfaces Inner classes Non-static classes nested within classes Anonymous classes Anonymous classes are declared as part of the creation Anonymous classes are inner classes Create as if you are constructing an instance of the interface or base class Place opening and closing brackets after the interface or base class place implementation code within brackets Summary Static methods and fields are shared class-wide Not associated with an individual instance Static initialization blocks provide one-time type declaration A nested tpe is a type declared within another type Can be used to provide structure and scoping Inner classes create an association between nested and enclosing instances Anonymous classes are declared as part of their creation Useful for simple interface implementations and class extensions","title":"Fundamentals of Java"},{"location":"pluralsight/blinc/phase1/fundamentalsOfJava/#fundamentals-of-java","text":"","title":"Fundamentals of Java"},{"location":"pluralsight/blinc/phase1/fundamentalsOfJava/#introduction-and-setting-up-the-environment","text":"Creating and running Java Apps Java file Java Developement kit tools Java App Java Runtime Environment Host Environment Summary Java is a language and a runtime environment Specific environment features may vary (Java SE/ME/EE, JavaFX, Android) Language remains pretty consistent End-users require the Java Runtime Environment(JRE) Developers require the Java Development Kit(JDK) Many Integrated Developement Environemts(IDE) are available Eclipse IntelliJ Netbeans","title":"Introduction and setting up the environment"},{"location":"pluralsight/blinc/phase1/fundamentalsOfJava/#creating-a-simple-app","text":"Summary Execute programs from tnhe command line with the \"java\" command Remember to use the full class name including the package name On Windows must include the JRE bin folder in the Path environment variable Programs are made up of statements Statements end with a semicolon Parts separated by zero or more whitespaces Use comments to add notes and hide statements from the compiler Packages provide organization Assure uniqueness Modt IDEs tie source code file structure to package name","title":"Creating a Simple App"},{"location":"pluralsight/blinc/phase1/fundamentalsOfJava/#variables-data-types-and-math-operator","text":"Variables Named data storage Strongly typed Value can be modified Naming Variables Variable na ing is based on a combination of rules and conventions Rules allow the use of letters, numbers, $ and _ By convention only letters and numbers are used Rules require that first character is not a numbers By convention it is always a letter By convention follow the style often referred to as \"Camel Case\" First letter is lower case Start of each word after the first is upper case All other letters are lower case Primitive data types Built into the language Foundation of all other types Four categories of primitive types Integer Floating point Character Boolean Integer types byte (8 bits) short (16 bits) int (32 bits) long (64 bits) Floating point types Implementation of IEEE 754 floating point standard Stores values containing a fractional portion Supports positive, negative and zero values Types Float (32 bits) Double (64 bits) Character and Boolean Types The char type stores a single Unicode character Literal values placed between single quotes For Unicode code points, use \\u followed by 4-digit hex value The boolean type stores true/false values Literal values are true and false Arithmetic operators Basic operators Add (+) Substract (-) Multiply (*) Divide (/) Modulus (%) Prefix/postfix operators ++ increments value by 1 -- decrements value by 1 As prefix applies operation before returning value As postfix applies operation after returning value Compound assignment operators Combines an operationand assignment Applies result of right side to left side Stores that result in variable on left side Operator precedence Operators are evaluated in a well-defined order Postfix Prefix Multiplicative Additive Operators of equal precedence are evaluated from left to right Can override precedence with parenthesis Nested parenthesis evaluated from the inside out Type conversion Implicit type conversion Conversions performed automatically by the compiler Widening conversions are automatic Mixed integer sizes Uses largest integer in equation Mixed floating point sizes Uses double Mixed integer and floating point Uses largest floating point in equation Explicit type conversion Conversions performed explicitly in code with cast operator Can perform widening and narrowing Floating point to integer drops fraction Use caution with narrowing conversions Integer to floating point can lose precision Summary Variables are stringly typed in Java Primitive types Integer types, floating point types, char type, boolean type Math operators Basic operators, postfix/prefix operators, compound assignment operators Math operators follow a well-defined order of precedence Type conversions Compiler can automatically apply widening type conversions Use type casting to explicitly perform type conversions","title":"Variables, Data types and Math Operator"},{"location":"pluralsight/blinc/phase1/fundamentalsOfJava/#conditional-logic-looping-and-arrays","text":"Adding conditional logic Relational operators Conditional assignments The if statement Logical operators Relational operators Greater than (>) Greater than or equal to (>=) Less than (<) Less than or equal to (<=) Equal to (==) Not equal to (!=) Conditional assignment Assign a value to a variable based on the result of a condition result = condition ? true-value : false-value ; If-else Statement An if statement conditionally executes a statement if (condition) true-statement; else false-statement; * The optional else clause executes a statement when the if condition is false * If-else statements chained together are evaluated in order until one is true if (condition-1) true-statement; else if (condition-2) true-statement; . . . else if (condition-N) true-statement; else false-statement; Block statement A block statement groups statements into a compound statement { statement-1; statement-2; . . . statement-N; } Block statements and Variable Scope A variable declared within a block is not visible outside of the block A variable's range of visibility is known as the variable's scope Logical operators And (&) Or (|) Exclusive or (XOR) (^) Negation (!) Conditional logical operators * Conditional and (&&) * Conditional or (||) Resolve following conceptually similar rules as non-conditional and/or Only execute the right-side if needed to determine the result && only executes right-side if left-side is true || only executes right-side if left-side is false While Loop Repeatedly executes a statement as long as the condition is true Condition checked at loop Start Statement may never execute while (condition) statement; Do-while Loop Repeatedly executes a statement as long as the condition is true Condition checked at loop end Statement always executes at least once do statement; while (condition); For Loop Repeatedly executes a statement as long as the condition is true Condition checked at loop start Provides simplified notation for loop control values for(initialize; condition; update) statement; Arrays Provides an ordered collection of elements Each element accessed via an index Indexes range from 0 to number-of-elemets minus 1 Number of elements can be found via array's length value For-each Loop Executes a statement once for each member in an array Handles getting collection length Handles accessing each value for (loop-variable-declaration : array) statement ; Switch Transfers control to a statement based on a value Simplifies testing against multiple possible matches Only primitive types supported are char and integers A match can execute more than one statement Use break to avoid \"falling through\" Can optionally include default to handle any unmatches values switch (test-value) { case value-1: statements case value-2: statements . . . case value-n: statements } Summary Use the if-else statement to provide conditional logic If-else statements can be chained together Block statements use brackets to group statements Variables declared within a block are not visible outside of the block Both while and do-while loops execute as long as a condition is true The do-while loop body always executes at least once The for loop provides simplified notation for loop initialization and control For-each statement handles details of executing once for each array member Switch statement simplifies notation of testing against multiple matches","title":"Conditional Logic, Looping and Arrays"},{"location":"pluralsight/blinc/phase1/fundamentalsOfJava/#representing-complex-types-with-classes","text":"Classes in Java Java is an object-orientated language Objects encapsulates data, operations, and usage semantics Allows storage and manipulation details to be hidden Separates \"what\" is to be done from \"how\" it is done Classes provide a structure for describing and creating Objects A class is a template for creating an object Declared with the class keyword followed by the class name Java source file name nornally has same name as the class Body of the class is contained within brackets A class is made up of both state and executable code Fields Store object state Methods Executable code that manipulates state and performs operations Constructors Executable code used during object creation to set the initial state Using Classes Use the new keyword to create a class instance (a.k.a an object) Allocates the memory described by the class Returns a reference to the allocated memory Encapsulation and Access Modifiers The internal representation of an object is generally hidden This concept is known as encapsulation Java uses access modifiers to achieve encapsulation Basic access modifiers Public Private Protected Default Naming classes Class names follow the same rules as variable names Class name conventions are similar to variables with some diferrences Use only letters and numbers First character is always a letter Follow the style often referred to as \"Pascal Case\" Start of each word, including the first, is upper case All other letters are lower case Use simple, descriptive nouns Avoid abbreviations unless abbreviation's use is more common than full name Method basics Executable code that manipulates state and performs operations Name Same rules and conventions as variables Should be a verb or action Return type Use void when no value returned Types parameter list Can be empty Body contained with brackets return-type name (typwd-parameter-list){ statements } Exiting from a Method A method exits for one of the three reasons The end of the method is reached A return statement is encountered An error occuers Unless there's an error, control returns to the method caller Methods return values A method returns a single value A primitive value A reference to an object A reference to an array Arrays are objects Special references : this and null Java provides special references with predefined meanings this is an implicit reference to the current object Useful for reducing ambiguity Allows an object to pass itself as a parameter null is a reference literal Represents an uncreated object Can be assigned to any reference variable Field encapsulation In most cases, a class fields should not be directly accessible outside of the class Helps to hide implementation details Use methods to control field access Accessors and Mutators Use the accessor/mutator pattern to control field access Accessor retrieves field value Also called getter Method name : getFieldName Mutator modifies field value Also called setter Method name : setFieldName Summary A class is a template for creating an object Declared wuth class keyword Class instances (a.k.a objects) allocated with new keyword Classes are reference types Use access modifiers to control encapsulation Methods manipulates state and performs operations Use return keyword to exit and/or return a value Fields store object state Interaction normally controlled through accessors(getters) and mutators(setters)","title":"Representing Complex Types with Classes"},{"location":"pluralsight/blinc/phase1/fundamentalsOfJava/#class-initializers-and-constructors","text":"Establishing Initial State When an object is created, it is expected to be in a useful state Often the default state established by Java is not enough The object may need to set values or execute code Mechanisms for Establishing Initial State Java provides 3 mechanisms for establishing initial state Field initializers Constructors Initialization blocks Field Initial State A field's initial state is established as part of object construction Fields receive a \"zero\" value by default Field initializers Allow us to specify a field's initial value as part of its declaration Can be a simple assignment Can be an equation Can reference other fields Can be a method call Constructors Executable code used during object creation to set the initial state Have no return type Every class has at least one constructor If no explicit constructors, Java provides one A class can have multiple constructors Each with a different parameter list Chaining constructors One constructor can call another Use the this keyword followed by parameter list Must be the first line Constructor visibility Use access modifiers to control constructor visibility Limits what code can perform specific creations Initialization blocks Initilization blocks shared across all constructors Executed as if the code were placed at the start of each constructor Enclose statements in brackets outside of any method or constructor Initialization and Construction Order Field Initilization * Initilization Block * Constructor Summary Objects should be created in some useful state Field initializers provide an initial value as part of the declaration Every class has at least one constructor If no explicit constructor, Java provides one with no arguments You can provide multiple constructors with different argument lists One constructor can call another Call must be first line Initilization blocks share code across constructors Keep the initialization and construction order in mind","title":"Class Initializers and Constructors"},{"location":"pluralsight/blinc/phase1/fundamentalsOfJava/#a-closer-look-at-parameters","text":"Parameter Immutability Parameters are passed by making a copy of the value Known as passing \"by-value\" Changes made to passed value are not visible outside of method Changes made to members of passed class instances are visible outside of method Overloading A class may have multiple versions of its constructor or methods Known as \"overloading\" Each constructor and method must have a unique signature Signature is made up of 3 parts Affected by number of parameters Affected by type of each parameter Affected by name Variable Number of Parameters A method can be declared to accept a varying number of parameter values Place an ellipse after parameter type Can only be the last parameter Method receives values as an array Summary Parameters are immutable Changes made to passed value are not visible outside of method Changes made to members os passed class instances are visible outside of method A class may have multiple versions of its constructor or methods Each must have a unique signature Sugnature includes name, number of parameters, type of each parameter A method can be declared to accept varying number of parameter values Values received as an array Must be last parameter","title":"A Closer Look at Parameters"},{"location":"pluralsight/blinc/phase1/fundamentalsOfJava/#class-inheritance","text":"Class Inheritance A class can be declared to inherit from another class Use the \"extends\" keyword Derived class has the characteristics of basic class Can add specialization Can be assigned to base class types references Fields hide base class fields with same name Methods can override base class methods with same signature Object class The object class is the rootof the Java class hierarchy Every class has the characteristics of the Object class Useful for declaring variables, fields and parameters that can reference any class or array instance Defines a number of methods that are inherited by al objects Every class inherits directly or indeirectly from the Object class Object class methods clone Create a new object instance that duplicates the current instance hashCode Get a hash code for the current instance getClass Return type information for the current instance finalize Handle special resource cleanup scenarios toString Return string of characters representing the current instance equals Compare another object to the current instancec for equality Special reference : super Similar to this, super is an implicit reference to the current object super treats the object as if it is an instance of its base class Useful for accessing base class members that have been overridden Control inheritance and overriding By default all classes can be extended and derived classes have the option to use or override inherited methods A class can change these defaults Use final to prevent inheriting and/or overriding Use abstract to require inheriting and/or overriding Inheritance and Constructors Constructors are not inherited A base class constructor must always be called By default, base class' no-argument constructor is called Can explicitly call a base class constructor using super followed by parameter list Must be first line of constructor Summary Inheritance allows a new class to be defined with the characteristics of another Use the extend keyword Derived class can override base class methods Optionally use @Override annotation All classes derive from Object class either directly or indirectly By default, object references are only equal when referencing the same instance Can override Object.equals to provide new behavior super accesses current object as if instance of base class final and abstract provide control over class inheritance and method overriding Constructors are not inherited","title":"Class Inheritance"},{"location":"pluralsight/blinc/phase1/fundamentalsOfJava/#more-about-data-types","text":"String class The string class stores a sequence of Unicode characters Stored using UTF-16 encoding Literals are enclosed in double quotes (\" \") Values can be concatenated using + and += String objects are immutable String class methods Length length String for non-string valueof Create new strings from existing concat replace toLowerCase toUpperCase trim split Formatting format Extract substring chatAt substring Test substring contains endsWith startWith indexOf lastIndexOf Comparison compareTo compareToIgnoreCase isEmpty equals equalsIgnoreCase Converting non-string types to strings We often need to convert non-string types into strings String.valueOf provides overrides to handle most types Conversions often happen implicitly Class conversions controlled by the class' toString method StringBuilder StringBuilder provides mutable string buffer For best performance pre-size buffer Will automatically grow if needed Most common methods append insert Classes vs Primitives Classes provide convenience Common interaction through Object class Fields and methods specific to the type Incurs an overhead cost Primitives provide efficiency Cannot be treated as Object Cannot expose fields or methods Lightweight Primitive wrapper classes Capabilities and overhead of classes Hold primitive values All wrapper classes are immutable Primitive wrapper class hierarchy Object Boolean Number Byte Short Integer Long Float Double Character Wrapper class and primitive conversion Java provides a number of ways to handle conversions Common conversions handled automatically Wrapper classes provide methods for explicit conversions Primitive to wrapper (Boxing) Wrapper to primitive (Unboxing) String to primitive (Parse) Wrapper class members Byte, Short, Integer, Long MIN_VALUE MAX_VALUE bitCount toBinaryString Float, Double MIN_VALUE MAX_VALUE isInfinite isNaN Character MIN_VALUE MAX_VALUE isDigit isLetter Boolean TRUE FALSE Wrapper class equality Boxing conversions that always return the same wrapper class instance Final fields Marking a field as final prevents it from being changed once assigned A simple final field must be set during creation of an object instance Can be set with field initializer, initialization block, or constructor Adding the static modifier makes a final field a named constant Cannot be set by an object instance Enumeration types Enumeration types useful for defining a type with a finite list of valid values Declare with enum keyword Provide a comma-separated value list Summary String class stores an immutable sequence of Unicode characters Implement toString method to provide conversion to a string StringBuilder class provides an efficient way to manipulate string values Primitive wrapper classes bring class capabilities to primitive values Wrapper classes much less efficient than primitive types Final fields prevent a value from being changed once assigned Simple final fields must be set during object instance creation Static final fields act as named constants Enumeration types useful for defining a type with a finite list of values","title":"More About Data Types"},{"location":"pluralsight/blinc/phase1/fundamentalsOfJava/#exceptions-and-error-handling","text":"Error handling with Exceptions Error handling needs to be implicit in application development The traditional approach of checking error codes/ flags is too intursive Exceptions provide a non-intursive way to signal errors try/catch/finally provides a structured way to handle exceptions The try block contains the \"normal\" code to execute Block executes to completion unless an exception is thrown The catch block contains the error handling code Block executes only if matching exception is thrown The finally block contains cleanup code if needed Runs in all cases following try or catch block Exception class hierarchy Object Throwable Error (Virtual machine related errors) Exception Runtime exception (Unchecked exception) Checked exception Types exceptions Exceptions can be handled by type Each exception type can have a separate catch block Each catch is tested in order from top to bottom First assignable catch is selected Start catch blocks with most specific exception types Exceptions and methods Exceptions propagate up the call stack Can cross method boundaries Exceptions are part of a methods's contract Method is responsible for any checked exceptions that might occur Catch the exception Document that the exception might occur use the throws clause Exceptions and method overriding The throws clause of an overriding method must be compatible with the throws clause of the overriden method Can exclude exceptions Can have the same exception Can have a derived exception Throwing exceptions Our code can throw exceptions (Using the throw keyword) Must create exception instance before throwing Most exception classes provide a constructor that accepts a String message or other detail When caused by another exception, include originating exception All exception classes support initCause method Many provide a constructor that accepts the originating exception Creating a custom exception type In most cases better to use esisting exception type Normally inherit directly from Exception class Makes them checked exceptions Constructors are often their only members Mostly required functionality is inherited Constructor that accepts required detail Constructor that accepts required detaila and originating exception Summary Exceptions provide a non-intrusive way to signal errors try/catch/finally provide a structured way to handle exceptions Exceptions are caught by type Can have separate vatch statement for differing exception types Catch from most specific type to least specific Raise exceptions using throw Methods must declare any unhandled checked exceptions using throws Can create custom exception types Normally inherit from Exception","title":"Exceptions and Error Handling"},{"location":"pluralsight/blinc/phase1/fundamentalsOfJava/#working-with-packages","text":"What is a Package? A package is a group of related types Create a namespace Provide an access boundary Act as a unit of distribution Declaring packages Each source file identifies the associated package Use the package keyword Package declaration must appear before any type declarations Applies to all types within that source file Package creates a Namespace Package name is part of the type-name Convention creates unique package name Follows reverse domain name structure Type name is qualified by package name Detemnining a Type's Package Compiler needs to know each type's package Explicitly qualifying each type is impractical Java offers several alternatives to explicitly qualifying types Allows use of a type's simple name in code Types in current package do not need to be qualified Types in the java.lang package do no need to be qualified Use type imports Type imports Type imports guide compiler to map simple names to qualified names (use import keyword) Single type import Provides mapping for a single type Preferred way to import types Most modern IDEs will add automatically Import on demand Provides mapping for all types in a package Use with caution Exposes code to potential breakage from changes in referenced packages Limiting access to Package Content Packages can serve as an access boundary Often referred to as package private Useful for creatingtypes and features to support functionality provided by the package Types and features are not meant to be used stand-alone Can apply to a type Entire type is inaccessible outside of the package Can apply to type members Specific members of an otherwise accessible type are inaccessible outside of the package Access modifiers public private protected Packages provide a Unit of distribution packages provide a predictable software structure Class files organized in hierarchical folders reflecting the package name Each part of the package name is a separate folder Archive files Package folder structure can be placed into an acrhive file (jar file) Places package fo,der structure into a single file Optionally includes a manifest providing information regarding archive content List of name-vale pairs Commonly used to define startup class Summary A package is a group of related types Package declaration must appear in source file before any type declarations Type name qualified by package name Use import statements to map simple names to qualified names Packages serve as an access boundary Packages simplify distribution Types organized hierarchically according to the package name Archive files store package hierarchy in a single file","title":"Working with Packages"},{"location":"pluralsight/blinc/phase1/fundamentalsOfJava/#creating-abstract-relationships-with-interfaces","text":"What is an interface An interface defines a contract and provides no implementation Classes implement interfaces Express that the class conforms to the contract Interfaces dont limit other aspects of the class implementation Some interfaces require additional type information (like generics) Classes are free to implement multiple interfaces Summary An interface defines a contract Provides no implementation Can include methods and constants Classes implement interfaces Classes are able to implement multiple interfaces Interfaces are able to extend other interfaces Implementing an extended interface implicitly implements the base","title":"Creating abstract relationships with Interfaces"},{"location":"pluralsight/blinc/phase1/fundamentalsOfJava/#stitic-members-nested-types-and-anonymous-classes","text":"Static members Static members are shared class-wide Declared using the static keyword Field A value not associated with a specific instance All instance access the same value Method Performs an action not tied to a specific instance Can access static fields only Static import Provides short hand for accessing static members Statuc initialization blocks Static initialization blocks perform one-time type initialization Statements enclosed in brackets outside of any method or constructor Cannot access instance members Must handle all checked exceptions Nested types A nested type is a type declared within another type Classes can be declared within classes and interfaces Interfaces can be declared within classes and interfaces Nested types are members od the enclosing type private members of the enclosing type are visible to the nested type Nested types support all member access modifiers public package private protected private Nested types serve differing purposes Structure and scoping Static classes nested within classes All classes nested within interfaces All nested interfaces Inner classes Non-static classes nested within classes Anonymous classes Anonymous classes are declared as part of the creation Anonymous classes are inner classes Create as if you are constructing an instance of the interface or base class Place opening and closing brackets after the interface or base class place implementation code within brackets Summary Static methods and fields are shared class-wide Not associated with an individual instance Static initialization blocks provide one-time type declaration A nested tpe is a type declared within another type Can be used to provide structure and scoping Inner classes create an association between nested and enclosing instances Anonymous classes are declared as part of their creation Useful for simple interface implementations and class extensions","title":"Stitic members, nested types, and anonymous classes"},{"location":"pluralsight/blinc/phase1/generics/","text":"Generics The What and Why of Java Generics Introduction Generics stop runtime errors at compile time Java's Generic Collections and Friends Interface -----> Implementation Multiple Data Structure -----> Specific Data Structure Functional Characteristics -----> Performance Characteristics Prefer as Variable Type -----> Concrete and Instantiable Often has a popular implementation Types of Collections Lists Sets Maps Generics Classes and Interfaces Implementing a Generic Type AgeComparator implements Comparator Passing a parameter to a generic Type Reverser implements Comparator Type Bounds SortedPair > Generics on Methods public static T min(List values, Comparator comparator) Wildcards Types of wildcards Upper bounded (List<? extends Cls>) Lower bounded (List<? super Cls>) Unbounded (List<?>)","title":"Generics"},{"location":"pluralsight/blinc/phase1/generics/#generics","text":"","title":"Generics"},{"location":"pluralsight/blinc/phase1/generics/#the-what-and-why-of-java-generics","text":"Introduction Generics stop runtime errors at compile time","title":"The What and Why of Java Generics"},{"location":"pluralsight/blinc/phase1/generics/#javas-generic-collections-and-friends","text":"Interface -----> Implementation Multiple Data Structure -----> Specific Data Structure Functional Characteristics -----> Performance Characteristics Prefer as Variable Type -----> Concrete and Instantiable Often has a popular implementation Types of Collections Lists Sets Maps","title":"Java's Generic Collections and Friends"},{"location":"pluralsight/blinc/phase1/generics/#generics-classes-and-interfaces","text":"Implementing a Generic Type AgeComparator implements Comparator Passing a parameter to a generic Type Reverser implements Comparator Type Bounds SortedPair >","title":"Generics Classes and Interfaces"},{"location":"pluralsight/blinc/phase1/generics/#generics-on-methods","text":"public static T min(List values, Comparator comparator)","title":"Generics on Methods"},{"location":"pluralsight/blinc/phase1/generics/#wildcards","text":"Types of wildcards Upper bounded (List<? extends Cls>) Lower bounded (List<? super Cls>) Unbounded (List<?>)","title":"Wildcards"},{"location":"pluralsight/blinc/phase1/git/","text":"Git What is Git and How Does it Works What is Git? Version Control System Software designed to record changes made to files over time Ability to revert back to a previous file version or project version Compare changes made to files from one version to another Version control any plain text file, not just source code Git uses snapshots, not differences Everything in Git is check-summed SHA1 hashing algorithm The three stages of a file Committed - Unmodified changes from the last commit snapshot Modified - Changes made to files since last commit Staged - Changes marked to be added into the next commit snapshot","title":"Git"},{"location":"pluralsight/blinc/phase1/git/#git","text":"","title":"Git"},{"location":"pluralsight/blinc/phase1/git/#what-is-git-and-how-does-it-works","text":"What is Git? Version Control System Software designed to record changes made to files over time Ability to revert back to a previous file version or project version Compare changes made to files from one version to another Version control any plain text file, not just source code Git uses snapshots, not differences Everything in Git is check-summed SHA1 hashing algorithm The three stages of a file Committed - Unmodified changes from the last commit snapshot Modified - Changes made to files since last commit Staged - Changes marked to be added into the next commit snapshot","title":"What is Git and How Does it Works"},{"location":"pluralsight/blinc/phase1/jdbcjavaPlatform/","text":"JDBC Java Platform Introduction Introduction to JDBC JDBC is an API for the Java programming language that defines how a client may access a Database. Architecture of JDBC JDBC supports Two Tier Architecture Three Tier Architecture JDBC contains 2 layers JDBC API - Application-to-JDBC Manager Connection JDBC Driver API - JDBC Manager-to-Driver Connection Role of Driver Manager The basic service for managing a set of JDBC drivers Driver Manager updates from JDBC 4.0 getConnection and getDrivers methods have been enhanced No need to load JDBC Drivers explicitly Application using Class.forName() will work without modification getConnection method of DriverManager will locate suitable Driver Understanding JDBC Driver Types A JDBC driver is a set of Java classes that implement the JDBC interfaces, targeting a specific Database The JDBC interfaces comes with standard Java Implementation of these interfaces is specific to the Database Types of JDBC drivers Type 1 : JDBC-ODBC bridge Advantages It is very easy to use Almost any database is supported Limitations Performance will not be efficient ODBC driver needs to be installed Type 1 drivers are not portable Not suitable for applets Type 2 : Native-API driver Advantages Faster than Type 1 driver Limitations Client Side Library is not available for all databases Vendor Client Library needs to be installed It is a Platform Dependent Not Thread Safe Type 3 : Network-Protocol driver (Middleware driver) Advantages No additional library installation is required on client system No changes are required at client for any Database Supports Caching of Connection, Query Results, Load Balancing, Logging and Auditing etc. A single driver can handle any database provided the middleware supports it Limitations Performace will be slow Requires Database-specific coding Maintenance of Network Protocol driver becomes costly Type 4 : Database-Protocol driver (Pure Java driver) Advantages Platform independent No intermediate format is required Application connects directly to the database server Performance will be very fast JVM manage all aspects Limitations Drivers are database dependent Performing basic CRUD operations using JDBC Executing static SQL statements Statement interface Used for executing a static SQL statement Methods: ResultSet executeQuery(String SQL) int executeUpdate(String SQL) boolean execute(String SQL) Iterating through ResultSets Java.Sql.ResultSet interface represents the result set of a database Query When the ResultSet is first returned, the starting cursor position is before the first row of data Methods of the ResultSet can be divided into 3 categories Navugational methods Get methods Update methods Common methods of ResultSet interface beforeFirst() afterLast() first() last() previous() next() getRow() ResultSet interface get methods get method for each data type Each get method has two versions One that takes in a column name One that takes in a column index Understanding Scrollable ResultSets ResultSet Types Type_Forward_Only Type_Scroll_Insensitive Type_Scroll_Sensitive ResultSet Concurrency Types Concur_Read_Only Concur_Updatable Understanding Updatable ResultSets Updatable ResultSet allows modification to data in a table through the ResultSet Each Update method has two versions One that takes in a column name One that takes in a column index To update a String Column of the current row public void updateString(int columnIndex, String s) public void updateString(String columnName, String s) Methods to reflect updates to database updateRow() deleteRow() refreshRow() cancelRowUpdates() insertRow() Understanding PreparedStatement Benefits Improves performance of an Application Easy to set SQL parameter value Prevents SQL dependency injection attacks Working with Stored Procedures Understanding CallableStatements A Stored Procedure is a group of SQL statements that perform a particular task Stored Procedures created by DBA Every database has its own language for creating Stored Procedures CallableStatements are used to make a call to the Stored Procedures Types of parameters Input (Default) Output Input Output Batch Processing Supported by Statement PreparedStatement CallableStatement Methods addBatch() : Returns void executeBatch() : Returns an array of integer IN OUT Parameter Both appropriate setter and RegisterOutParameter method should be used Supplied setter value type 4 JDBC type supplied to the method RegisterOutParameter should be same Working with CLOB and BLOB What is CLOB A CLOB(Character Large Object) is a collection of character data stored as a single entity in a database What is BLOB A BLOB (Binary Large Object) is a collection of Binary data stored as a single entity in a database BLOBs are typically documents, images, audio or other binary objects Working with Metadata Metadata Programming is useful to know the capabilities, limitations and facilities of underlying database software and its resources JDBC Metadata programming concepts Databse Metadata ResultSet Metadata Parameter Metadata","title":"JDBC Java Platform"},{"location":"pluralsight/blinc/phase1/jdbcjavaPlatform/#jdbc-java-platform","text":"","title":"JDBC Java Platform"},{"location":"pluralsight/blinc/phase1/jdbcjavaPlatform/#introduction","text":"Introduction to JDBC JDBC is an API for the Java programming language that defines how a client may access a Database. Architecture of JDBC JDBC supports Two Tier Architecture Three Tier Architecture JDBC contains 2 layers JDBC API - Application-to-JDBC Manager Connection JDBC Driver API - JDBC Manager-to-Driver Connection Role of Driver Manager The basic service for managing a set of JDBC drivers Driver Manager updates from JDBC 4.0 getConnection and getDrivers methods have been enhanced No need to load JDBC Drivers explicitly Application using Class.forName() will work without modification getConnection method of DriverManager will locate suitable Driver Understanding JDBC Driver Types A JDBC driver is a set of Java classes that implement the JDBC interfaces, targeting a specific Database The JDBC interfaces comes with standard Java Implementation of these interfaces is specific to the Database Types of JDBC drivers Type 1 : JDBC-ODBC bridge Advantages It is very easy to use Almost any database is supported Limitations Performance will not be efficient ODBC driver needs to be installed Type 1 drivers are not portable Not suitable for applets Type 2 : Native-API driver Advantages Faster than Type 1 driver Limitations Client Side Library is not available for all databases Vendor Client Library needs to be installed It is a Platform Dependent Not Thread Safe Type 3 : Network-Protocol driver (Middleware driver) Advantages No additional library installation is required on client system No changes are required at client for any Database Supports Caching of Connection, Query Results, Load Balancing, Logging and Auditing etc. A single driver can handle any database provided the middleware supports it Limitations Performace will be slow Requires Database-specific coding Maintenance of Network Protocol driver becomes costly Type 4 : Database-Protocol driver (Pure Java driver) Advantages Platform independent No intermediate format is required Application connects directly to the database server Performance will be very fast JVM manage all aspects Limitations Drivers are database dependent","title":"Introduction"},{"location":"pluralsight/blinc/phase1/jdbcjavaPlatform/#performing-basic-crud-operations-using-jdbc","text":"Executing static SQL statements Statement interface Used for executing a static SQL statement Methods: ResultSet executeQuery(String SQL) int executeUpdate(String SQL) boolean execute(String SQL) Iterating through ResultSets Java.Sql.ResultSet interface represents the result set of a database Query When the ResultSet is first returned, the starting cursor position is before the first row of data Methods of the ResultSet can be divided into 3 categories Navugational methods Get methods Update methods Common methods of ResultSet interface beforeFirst() afterLast() first() last() previous() next() getRow() ResultSet interface get methods get method for each data type Each get method has two versions One that takes in a column name One that takes in a column index Understanding Scrollable ResultSets ResultSet Types Type_Forward_Only Type_Scroll_Insensitive Type_Scroll_Sensitive ResultSet Concurrency Types Concur_Read_Only Concur_Updatable Understanding Updatable ResultSets Updatable ResultSet allows modification to data in a table through the ResultSet Each Update method has two versions One that takes in a column name One that takes in a column index To update a String Column of the current row public void updateString(int columnIndex, String s) public void updateString(String columnName, String s) Methods to reflect updates to database updateRow() deleteRow() refreshRow() cancelRowUpdates() insertRow() Understanding PreparedStatement Benefits Improves performance of an Application Easy to set SQL parameter value Prevents SQL dependency injection attacks","title":"Performing basic CRUD operations using JDBC"},{"location":"pluralsight/blinc/phase1/jdbcjavaPlatform/#working-with-stored-procedures","text":"Understanding CallableStatements A Stored Procedure is a group of SQL statements that perform a particular task Stored Procedures created by DBA Every database has its own language for creating Stored Procedures CallableStatements are used to make a call to the Stored Procedures Types of parameters Input (Default) Output Input Output Batch Processing Supported by Statement PreparedStatement CallableStatement Methods addBatch() : Returns void executeBatch() : Returns an array of integer IN OUT Parameter Both appropriate setter and RegisterOutParameter method should be used Supplied setter value type 4 JDBC type supplied to the method RegisterOutParameter should be same","title":"Working with Stored Procedures"},{"location":"pluralsight/blinc/phase1/jdbcjavaPlatform/#working-with-clob-and-blob","text":"What is CLOB A CLOB(Character Large Object) is a collection of character data stored as a single entity in a database What is BLOB A BLOB (Binary Large Object) is a collection of Binary data stored as a single entity in a database BLOBs are typically documents, images, audio or other binary objects","title":"Working with CLOB and BLOB"},{"location":"pluralsight/blinc/phase1/jdbcjavaPlatform/#working-with-metadata","text":"Metadata Programming is useful to know the capabilities, limitations and facilities of underlying database software and its resources JDBC Metadata programming concepts Databse Metadata ResultSet Metadata Parameter Metadata","title":"Working with Metadata"},{"location":"pluralsight/blinc/phase1/multithreading/","text":"Multi Threading Understanding Concurrency, Threading and Synchronization What is a Thread A thread is defined at the Operating System level A thread is a set of instructions An application can be composed of several threads Different threads can be executed \"at the same time\" The Java Virtual Machine works with several threads (GC, JIT, etc) Who is responsible for the CPU sharing A special element called a scheduler There are three reasons for the scheduler to pause a thread The CPU should be shared equally among threads The thread is waiting for some more data The thread is waiting for another thread to do something Race condition It means that two different threads are trying to read and write the same variable at the same time Synchronization Prevents a block of code to be executed by more than one thread at the same time Locks are reentrant When a thread holds a lock, it can enter a block synchronized on the lock it is holding Deadlock A deadlock is a situation where a thread T1 holds a key needed by a thread T2, and T2 holds the key needed by T1 The JVM is able to detect deadlock situations, and can log information to help debug the application Runnable interface The most basic way to create threads is Java is to use the Runnable pattern First create an instance of Runnable Then pass it to the constructor of the Thread class Then call the start() method of this thread object Implementing the Producer/Consumer pattern using Wait/Notify Stopping a thread The call to interrupt() causes the isInterrupted() method to return true If the thread is blocked, or waiting, then the corresponding method will throw an InterruptedException The wait()/notify(), join() throw InterruptedException Producer/ Consumer A producer produces values in a buffer A consumer consumes the values from this buffer Be careful : the buffer can be empty, or full Producers and consumers are run in their own thread Fixing the producer/ consumer We need a way to \"park\" a thread while he is waiting for some data to be produced Without blocking all the other threads So the key held by this thread should be released while this thread is \"parked\" This is the wait/notify pattern wait()/notify() wait() and notify() are two methods from the Object class They are invoked an a given object The thread executing the invocation should hold the key of that object wait() and notify() cannot be invoked outside a synchronized block Calling wait() Calling wait() releases the key held by this thread And puts that thread in a WAIT thread The only way to release a thread from a WAIT state is to notify it Calling notify() Calling notify() releases a Thread in WAIT state and puts it in RUNNABLE state This is the only way to release a waiting thread The released thread is chosen randomly There is also a notifyAll() method A thread has a state The thread scheduler can run the threads in the state RUNNABLE A BLOCKED thread can only run again when the key is released A WAITING thread can only run again when the notify() method is called Ordering Read and Write Operations on a MultiCore CPU Synchronization Synchronization protects a block of code Guarantees this code is executed by one thread at a time Prevents race condition Memory Access A CPU does not read a variable from the main memory, but from a cache Because access to caches is much faster than access to main memory Access to the main memory : 100ns Access to the L2 cache : 7ns Access to the L1 cache : 0.5ns Tradeoffs Size of the main memory : several GB Size of the L2 cahce : 256kB Size of the L1 cache : 32kB Visibility A variable is said visible if the writes made on it are visible All the synchronized writes are visible Happens before link A \"Happens before\" link exists between all synchronized or volatile write operations and all synchronized or volatile read operations that follow What is \"False Sharing\" False sharing happens because of the way the CPU caches works It is a side effect, that can have a tremendous effect on performance","title":"Multi Threading"},{"location":"pluralsight/blinc/phase1/multithreading/#multi-threading","text":"","title":"Multi Threading"},{"location":"pluralsight/blinc/phase1/multithreading/#understanding-concurrency-threading-and-synchronization","text":"What is a Thread A thread is defined at the Operating System level A thread is a set of instructions An application can be composed of several threads Different threads can be executed \"at the same time\" The Java Virtual Machine works with several threads (GC, JIT, etc) Who is responsible for the CPU sharing A special element called a scheduler There are three reasons for the scheduler to pause a thread The CPU should be shared equally among threads The thread is waiting for some more data The thread is waiting for another thread to do something Race condition It means that two different threads are trying to read and write the same variable at the same time Synchronization Prevents a block of code to be executed by more than one thread at the same time Locks are reentrant When a thread holds a lock, it can enter a block synchronized on the lock it is holding Deadlock A deadlock is a situation where a thread T1 holds a key needed by a thread T2, and T2 holds the key needed by T1 The JVM is able to detect deadlock situations, and can log information to help debug the application Runnable interface The most basic way to create threads is Java is to use the Runnable pattern First create an instance of Runnable Then pass it to the constructor of the Thread class Then call the start() method of this thread object","title":"Understanding Concurrency, Threading and Synchronization"},{"location":"pluralsight/blinc/phase1/multithreading/#implementing-the-producerconsumer-pattern-using-waitnotify","text":"Stopping a thread The call to interrupt() causes the isInterrupted() method to return true If the thread is blocked, or waiting, then the corresponding method will throw an InterruptedException The wait()/notify(), join() throw InterruptedException Producer/ Consumer A producer produces values in a buffer A consumer consumes the values from this buffer Be careful : the buffer can be empty, or full Producers and consumers are run in their own thread Fixing the producer/ consumer We need a way to \"park\" a thread while he is waiting for some data to be produced Without blocking all the other threads So the key held by this thread should be released while this thread is \"parked\" This is the wait/notify pattern wait()/notify() wait() and notify() are two methods from the Object class They are invoked an a given object The thread executing the invocation should hold the key of that object wait() and notify() cannot be invoked outside a synchronized block Calling wait() Calling wait() releases the key held by this thread And puts that thread in a WAIT thread The only way to release a thread from a WAIT state is to notify it Calling notify() Calling notify() releases a Thread in WAIT state and puts it in RUNNABLE state This is the only way to release a waiting thread The released thread is chosen randomly There is also a notifyAll() method A thread has a state The thread scheduler can run the threads in the state RUNNABLE A BLOCKED thread can only run again when the key is released A WAITING thread can only run again when the notify() method is called","title":"Implementing the Producer/Consumer pattern using Wait/Notify"},{"location":"pluralsight/blinc/phase1/multithreading/#ordering-read-and-write-operations-on-a-multicore-cpu","text":"Synchronization Synchronization protects a block of code Guarantees this code is executed by one thread at a time Prevents race condition Memory Access A CPU does not read a variable from the main memory, but from a cache Because access to caches is much faster than access to main memory Access to the main memory : 100ns Access to the L2 cache : 7ns Access to the L1 cache : 0.5ns Tradeoffs Size of the main memory : several GB Size of the L2 cahce : 256kB Size of the L1 cache : 32kB Visibility A variable is said visible if the writes made on it are visible All the synchronized writes are visible Happens before link A \"Happens before\" link exists between all synchronized or volatile write operations and all synchronized or volatile read operations that follow What is \"False Sharing\" False sharing happens because of the way the CPU caches works It is a side effect, that can have a tremendous effect on performance","title":"Ordering Read and Write Operations on a MultiCore CPU"},{"location":"pluralsight/blinc/phase1/shellScripting/","text":"Shell Scripting Introduction Bash shell scripts Execute bash commands from a file Automate sequences of shell commands Run them later or at scheduled times Take advantage of UNIX toolset Who needs it? System administrators Developers Power users Bash scripts are very good at File manipulation Running programs Processing text Sometimes other languages are better Examples : mathematical calculations, binary data, graphics A First Look at Shell Scripts Creating a script A text file containing code To be run by an interpreter In this course, the interpreter will be Bash Will run each command in the file in order Choose a good text editor Emacs, vi Linux : Kate, gedit Mac OS : TextWrangler Executable permissions Use chmod command \"chmod u+x filename\" \"chmod a+x filename\" to make it executable for everyone \"chmod a+x filename\" to remove the permission Calling the script If the script is not on you PATH Include the directory when calling it ./hw /home/reindert/hw If the script is on you path Just call it like a regular command Tip : make a bin folder in your home Put your scripts in there Add it to you path PATH=\"$PATH:~/bin\" Shebang Shebang line First line of file Starts with #! Specifies which interpreter should run the code Specify options for interpreter Bash scripts !/bin/bash Other systems than Linux or Mac OS May have bash in a different location !/usr/bin/env bash This will find bash on the user's PATH Cannot give options Result depends on the user's configuration Naming you script Don't name your script \"test\", \"if\" or \"ls\" Conflicts with existing commands Does a command with the same name exist? Use \"type\" Variables Variables Used to store data by name To create : just assign a value x=10 If x already existed, it is assigned the new value Values containing spaces : use quotes Don't use whitespace around = To get the value Prefix with $ echo $x Bash variables have no data type Basically just store a string Names Only letters, numbers and underscore are allowed First character should be a letter or an underscore Variable names are case-sensitive Uppercase variables Bash has many pre-defined variables PATH, HOME, SECONDS, IFS, etc. You don't override them by mistake Good habit Use lowercase names for you variables Using variables Good habit : surround your variables with quotes Use \"$x\" instead of $x Prevent surprises when it contains spaces Use double quotes : keep meaning of dollar sign intact Braces: echo \"${foo}bar\" prints value of var \"foo\" followed by string \"bar\" echo \"$foobar\" prints value of \"foobar\" Using braces a lot is a good habit Another good habit Use $HOME instead of ~ Reading input Reads a line of input into a variable read var is a shell bulletin \"help read\" \"man builtins\" read -p\"Type your name:\"name If, Then, Else If if testcode; then #Code here gets executed #When testcode succeeds fi if testcode; then #Code here gets executed #When testcode succeeds else #Code here gets executed #When testcode fails fi if testcode; then successcode; else failcode; fi Else if is written as elif Can have multiple elifs Return codes Return code or exit status Value returned by program on exit 0 to 255 0 means success other values are error codes Shell script return values with exit exit 0 Good habit : make sure your program exits with a correct value ALways call exit with a value If statement just looks at return code for \"testcode\" Conditional expressions Conditional expressions Tests on files and directories Tests on strings Arithmetic tests [[ Expression]] [[ $str ]] \\True if str is not empty [[ $str = \"something\" ]] \\True if str equals string \"something\" [[ $str=\"something\" ]] \\True if always returns true! [[ -e $filename ]] \\True if file $filename exists [[ -d $dirname ]] \\True if $dirname is a directory Spaces around the expression are very important! Same for swithces (-e) and equals sign Classical command: \"test\" Also : [ Harder to use, easier to make mistakes Only use for portability [[...]] is a bash extension Not a command but special syntax No quotes needed around variables Good habit : use [[..]] instead of [..] Getting help \"help test\" will show you most important info \"help [[\" will tell you about the extension Arithmetic tests For comparing integers Only [[ arg1 OP arg2]] Where OP is: -eq: equality -ne: not equal -lt: less than -gt: greater than Special variables $# contains number of script arguments S? contains exit status for last command To get the length of the string in a variable Use ${#var} And, Or, Not In a conditional expression Use ! to negate a test [[ ! -e $file ]] Use spaces around ! Use && for \"and\" [[ $# -eq 1 && $1 = \"foo\" ]] True if there is exactly 1 argument with value foo Use || for \"or\" [[ $a || $b ]] True if a or b contains a value (or both) Dont even use -a, -o for and, or Input and Output echo Prints its arguments to standard output followed by a newline -n suppresses the newline -e allows use of escape sequences \\t : tab \\b : backspace These options are not portable to non-bash shells printf Can do more sophisticated output than echo Uses a format string for formatting Will not append a newline by default read Reads input into a variable \"read x\" No variable specified? will use REPLY -n or -N specifies number of characters to read -s will suppress output (useful for passwords) -r disallows escape sequences, line continuation Good habit : always use -r Several more useful options read can read words in a line into multiple variables read x y input\"1 2 3\": x=1, y=\"2 3\" Uses IFS variable for delimiters Standard streams Three standard streams input, output, error Represented by number (file descriptor), or special file 0 : Standard Input (stdin) /dev/stdin 1 : Standard Output (stdout) /dev/stdout 2 : Standard Error (stderr) /dev/stderr Used for diagonistic or error message /dev/null discards all data sent to it Redirection Get input from somewhere else, send output or errors somewhere else Input redirection : < grep milk < shoppingnotes.txt Output redirection : > ls > listing.txt Will overwrite existing files Although this can be customized with the set command appends to the end of a file Pipes ls | grep x Redirect a specific stream with N> \"cmd 2> /dev/null\" discards all errors Redirect to a specific stream with >&N &2 sends output to stderr (Equivalent to 1>&2) 2>&1 redirects stderr into stdout Sending both error and output to a single file cmd > logfile 2>&1 Allowed anywhere on the command line, but order matters \"cmd < inputfile > outputfile\" is similar to \">outputfile cmd < inputfile\" cmd >logfile 2>&1 (Sends errors to the logfile) 2>&1 >logfile cmd (Sends errors to stdout) Control Flows while while test; do ;; code to be repeated done until until test; do ;; code to be repeated done Repeats code in the block Continues as long as test returns false The classic for loop for VAR in WORDS; do ;; code to be repeated done Assign each word in WORDS to var in turn Will stop when no words are left Do NOT quote words The C-style for loop for (( INIT; TEST; UPDATE )); do ;; loop code done Use double parentheses First expression : initialize your loop variables Second expression : a test. The loop will run as long as this is true Third expression : update the loop variables Expression use syntax for arithmetic evaluation Break and Continue break quits the loop continue skips the rest of the current iteration continues with the next iteration Both can be used in for, while and until case case WORD in PATTERN1) code for pattern 1;; PATTERN2) code for pattern 2;; ... PATTERNn) code for pattern n;; esac Matches word with patterns Pattern matching is the same as with matching filename patterns Use 8, ?, [] Code for first pattern that mathes gets executed End code with ;; SO you can use multiple statements separated by ; Multiple patterns separated by | Command groups Group commands with {} Will group them into a single statement Can use I/O redirection for the whole group Use the group in an if statement or while loop Return status is that of the last command in the group { cmd1;cmd2;cmd3 } Separate the commands with newlines or semicolons Use spaces around braces Ending semicolon or newline not optional || and && Execute next statement depending on return status of previous statement Basically : short for if && Will execute next statement only if previous one succeeded mkdir newdir && cd newdir || Will execute next statement only if previous one failed [[ $1 ]] || echo\"missing argument\">&2 [[ $1 ]] || echo\"missing argument\">&2&& exit 1 Dont do this: will always exit [[ $1 ]] || {echo\"\"missing argument\">&2; exit 1;} Variables 2 Variable attributes Variables hold simple string values But can also have extra attributes Turn these on/off with declare You can also use \"typeset\" (but that is deprecated) Print attributes for a variable declare -p var Integer Variables Interger variable declare -i num Now $num can hold only numbers Trying to set it to something else will NOT give an error Instead, this will set a value of 0 Unset an attribute with + declare +i num Triggers arithmetic evaluation Arithmetic expressions C-like syntax for doing calculations let command let n=100/2 (( .. )) ((++x)) ((p=x/100)) (( p=$(ls |wc-1)*10 )) This is a command equivalent to let $(( .. )) This is substitution, not a command p=$((x / 100)) With a variable declared as an integer num=\"30 % 8\" No need to quote variables (( .. )) can be used in if, while 0 is false, anything greater than 0 is true (( 0 )) || echo \"false\" Pitfall : numbers with leading zeroes are interpreted as octal So 010 = 8 (( ..; ..; .. )) syntax in for loop is not an arithmetic expression but the three expressions separated by ; are Read only variables declare -r constant=\"some value\" Cannot give $constant another value Bach will report an error Exporting variables By default, variables are local to you script Or terminal session Export a variable To make it available to subprocesses You cannot pass a variable to the program that runs you script export var export var=\"value\" declare -x var declare -x var=\"value\" Arrays An array can hold multiple values Stored and retrieved by index Storing a value x[0] = \"some\" x[1] = \"word\" Retrieving a value ${x[0]} : same ${x[1]} : word ${x[@]} or ${x[ ]} retrieve all values (quoting works like $ , $@) declare -a x Or simply assign with an index like above Intializing an array ar = (1 2 3 a b c) Count the number of elements in $array ${#array[@]} The indices in $array ${!array[@]} The can be gaps in the indices You cannot export an array Bash 4 supports associative Arrays Where elements are stored and retrieved by a name, not an index declare -A array Handling script parameters Special variables Hold the n-th command line argument : $1, $2, etc. Above 9 use braces : ${10}, ${25} $0 Holds name of the script as it was called $@ : All Equivalent to $1 $2 $3 ... $N But when double quoted : \"$1\" \"$2\" \"$3\" ... \"$N\" So parameters containing multiple words stay intact $* Equivalent to $1 $2 $3 ... $N But when double quoted : \"$1 $2 $3 ... $N\" Dont use this, use $@ instead $# Holds the number of arguments passed to the script Shift Removes the first argument All positions paramters shift $2 -> $1 $3 -> $2 $4 -> $3 etc. $# lowered by 1 Getopts Utility to help parse argument lists Expects options to start with a dash (-x) Allows options that take an argument (-f file) getopts optstring name optstring A list of expected options \"ab\" will let your script handle an option -a and/or -b Append : to options that take an argument \"a:b\" will let a take an argument, but not b name The name of a variable Every time you get getopts, it will place the next option into $name getopts returns false when no more options are left Any word not starting with a dash will end option processing So anything after the options, you have to parse for yourself An option \"--\" will be seen as the end of options as well Arguments for options will be put in OPTARG OPTIND holds the index of the next argument to be processed Shell Functions Functions Define your own command name () { ... } You can run the code in the braces as a new command Other equivalent syntax (not recommended) function name () { ... } function name { ... } Execute it like any command Give it arguments Use redirection Positional parameters are available for function arguments $1, $2, ... Naming your functions Same rules as for naming scripts : don't override existing commands Bash variables are globally visible In a function, you can make a variable local to that function Use declare or local Exit a function with return returns a status code, like exit Without a return statement, function returns status of last statement Returning any other value Use a global variable Or send the data to output and use command substitution Exporting a function export -f fun Miscellaneous Functions and redirection Redirection is allowed immediately after function definition Will be executed when function is run A command in a pipeline runs in a subshell Here documents Have a command read its input from the source file << Tag Tag defines end of input Fun with Strings Parameter Expansion Allows powerful string manipulation ${#var} : length of $var Removing a pattern Removing part of a string ${var#pattern} : Removes shortest match from begin of string ${var##pattern} : Removes longest match from begin of string ${var%pattern} : Removes shortest macth from end of string ${var%%pattern} : Removes longest match from end of string Pattern matching is like pathname matching with *, ? and [] Example : i=\"/Users/reindert/demo.txt\" ${i# /} returns \"Users/reindert/demo.ext\" ${i## /} returns \"demo.txt\" ${i%. } returns \"/Users/reindert/demo\" ${i%/ } returns \"/Users/reindert\" Search and replace Search and replace ${var/pattern/string} : Substitute first match with string ${var//pattern/string} : Substitute all matches with string Anchor your pattern ${var/#pattern/string} : Matches beginning of the string ${var/%pattern/string} : Matches end of the string Default values Default value ${var:-value} : Will evaluate to \"value\" if var is empty or unset ${var-value} : Similar, but only if var is unset Assign a default value ${var:=value} : If var was empty or unset, this evaluates to \"value\" and assigns it to var ${var=value} : Similar, but only if var is unset Conditional Expression Patterns ==, != operators in [[ .. ]] do pattern matching == is the same operator as = [[ $var == pattern ]] : Returns true wehn $var matches the pattern Pattern matching is like pathname matching with *, ? and [] Use quotes to force string matching =~ does regular expression matching Very powerful Uses POSIX extended regular expressions ? matches the token before it 0 or 1 times [0-9]? will match a single digit or nothing at all matches the token before it for any number of times [a-z]* will match any lowercase text or nothing at all matches the token before it for one or more times [0-9]+ will match 1 or more digits ^ matches start of string $ macthes end of string End of options Is denoted by -- Supported by many UNIX commands Arguments after this will not be interpreted as options Makes it safe when working with data that starts with a dash Good habit : When you use a variable as an argument for a command And the contents of the variable are not under you Control Use -- with the commands you call Many Ways to Run Your Scripts Running code from a file Using hash-bang and running it as a command Will start a bash subprocess Executable permission has to be set Or when it does not have a hash-bang bash myscript No permission necessary bash -x myscript : Debugs myscript TO import code in the current shell process source myscript .myscript This is basically what happens with .bashrc Background and nohup Put a command in the background with & myscript & It will be disconnected from the interactive session Will be suspended if it tries to read input from the terminal Long-running scripts Keep your script running when you exit the terminal session nohup myscript & Run your script with a lower priority nice myscript Redurecting with exec Redirect I/O for the whole script Useful for logging Running your script another time At Will execute your script at a specific time Cron Will execute your script according to a schedule On Mac OS, use launchd On Ubuntu, you may want to look at Upstart set and shopt Customize bash behaviour with set and shopt set -x prints each command with its arguments as it is executed -u gives an error when using an uninitialised variable and exits script -n read commands but do not execute -v print each command as it is read -e exits script whenever a command fails shopt Can set many options with -s, unset with -u shopt -s nocaseglob : Ignore case with pathname expansion shopt -s extglob : Enable extended pattern matching shopt -s dotglob : Include hidden files with pathname expansion set -o noclobber : Don;t overwrite files on redirection operations","title":"Shell Scripting"},{"location":"pluralsight/blinc/phase1/shellScripting/#shell-scripting","text":"","title":"Shell Scripting"},{"location":"pluralsight/blinc/phase1/shellScripting/#introduction","text":"Bash shell scripts Execute bash commands from a file Automate sequences of shell commands Run them later or at scheduled times Take advantage of UNIX toolset Who needs it? System administrators Developers Power users Bash scripts are very good at File manipulation Running programs Processing text Sometimes other languages are better Examples : mathematical calculations, binary data, graphics","title":"Introduction"},{"location":"pluralsight/blinc/phase1/shellScripting/#a-first-look-at-shell-scripts","text":"Creating a script A text file containing code To be run by an interpreter In this course, the interpreter will be Bash Will run each command in the file in order Choose a good text editor Emacs, vi Linux : Kate, gedit Mac OS : TextWrangler Executable permissions Use chmod command \"chmod u+x filename\" \"chmod a+x filename\" to make it executable for everyone \"chmod a+x filename\" to remove the permission Calling the script If the script is not on you PATH Include the directory when calling it ./hw /home/reindert/hw If the script is on you path Just call it like a regular command Tip : make a bin folder in your home Put your scripts in there Add it to you path PATH=\"$PATH:~/bin\" Shebang Shebang line First line of file Starts with #! Specifies which interpreter should run the code Specify options for interpreter Bash scripts","title":"A First Look at Shell Scripts"},{"location":"pluralsight/blinc/phase1/shellScripting/#binbash","text":"Other systems than Linux or Mac OS May have bash in a different location","title":"!/bin/bash"},{"location":"pluralsight/blinc/phase1/shellScripting/#usrbinenv-bash","text":"This will find bash on the user's PATH Cannot give options Result depends on the user's configuration Naming you script Don't name your script \"test\", \"if\" or \"ls\" Conflicts with existing commands Does a command with the same name exist? Use \"type\"","title":"!/usr/bin/env bash"},{"location":"pluralsight/blinc/phase1/shellScripting/#variables","text":"Variables Used to store data by name To create : just assign a value x=10 If x already existed, it is assigned the new value Values containing spaces : use quotes Don't use whitespace around = To get the value Prefix with $ echo $x Bash variables have no data type Basically just store a string Names Only letters, numbers and underscore are allowed First character should be a letter or an underscore Variable names are case-sensitive Uppercase variables Bash has many pre-defined variables PATH, HOME, SECONDS, IFS, etc. You don't override them by mistake Good habit Use lowercase names for you variables Using variables Good habit : surround your variables with quotes Use \"$x\" instead of $x Prevent surprises when it contains spaces Use double quotes : keep meaning of dollar sign intact Braces: echo \"${foo}bar\" prints value of var \"foo\" followed by string \"bar\" echo \"$foobar\" prints value of \"foobar\" Using braces a lot is a good habit Another good habit Use $HOME instead of ~ Reading input Reads a line of input into a variable read var is a shell bulletin \"help read\" \"man builtins\" read -p\"Type your name:\"name","title":"Variables"},{"location":"pluralsight/blinc/phase1/shellScripting/#if-then-else","text":"If if testcode; then #Code here gets executed #When testcode succeeds fi if testcode; then #Code here gets executed #When testcode succeeds else #Code here gets executed #When testcode fails fi if testcode; then successcode; else failcode; fi Else if is written as elif Can have multiple elifs Return codes Return code or exit status Value returned by program on exit 0 to 255 0 means success other values are error codes Shell script return values with exit exit 0 Good habit : make sure your program exits with a correct value ALways call exit with a value If statement just looks at return code for \"testcode\" Conditional expressions Conditional expressions Tests on files and directories Tests on strings Arithmetic tests [[ Expression]] [[ $str ]] \\True if str is not empty [[ $str = \"something\" ]] \\True if str equals string \"something\" [[ $str=\"something\" ]] \\True if always returns true! [[ -e $filename ]] \\True if file $filename exists [[ -d $dirname ]] \\True if $dirname is a directory Spaces around the expression are very important! Same for swithces (-e) and equals sign Classical command: \"test\" Also : [ Harder to use, easier to make mistakes Only use for portability [[...]] is a bash extension Not a command but special syntax No quotes needed around variables Good habit : use [[..]] instead of [..] Getting help \"help test\" will show you most important info \"help [[\" will tell you about the extension Arithmetic tests For comparing integers Only [[ arg1 OP arg2]] Where OP is: -eq: equality -ne: not equal -lt: less than -gt: greater than Special variables $# contains number of script arguments S? contains exit status for last command To get the length of the string in a variable Use ${#var} And, Or, Not In a conditional expression Use ! to negate a test [[ ! -e $file ]] Use spaces around ! Use && for \"and\" [[ $# -eq 1 && $1 = \"foo\" ]] True if there is exactly 1 argument with value foo Use || for \"or\" [[ $a || $b ]] True if a or b contains a value (or both) Dont even use -a, -o for and, or","title":"If, Then, Else"},{"location":"pluralsight/blinc/phase1/shellScripting/#input-and-output","text":"echo Prints its arguments to standard output followed by a newline -n suppresses the newline -e allows use of escape sequences \\t : tab \\b : backspace These options are not portable to non-bash shells printf Can do more sophisticated output than echo Uses a format string for formatting Will not append a newline by default read Reads input into a variable \"read x\" No variable specified? will use REPLY -n or -N specifies number of characters to read -s will suppress output (useful for passwords) -r disallows escape sequences, line continuation Good habit : always use -r Several more useful options read can read words in a line into multiple variables read x y input\"1 2 3\": x=1, y=\"2 3\" Uses IFS variable for delimiters Standard streams Three standard streams input, output, error Represented by number (file descriptor), or special file 0 : Standard Input (stdin) /dev/stdin 1 : Standard Output (stdout) /dev/stdout 2 : Standard Error (stderr) /dev/stderr Used for diagonistic or error message /dev/null discards all data sent to it Redirection Get input from somewhere else, send output or errors somewhere else Input redirection : < grep milk < shoppingnotes.txt Output redirection : > ls > listing.txt Will overwrite existing files Although this can be customized with the set command appends to the end of a file Pipes ls | grep x Redirect a specific stream with N> \"cmd 2> /dev/null\" discards all errors Redirect to a specific stream with >&N &2 sends output to stderr (Equivalent to 1>&2) 2>&1 redirects stderr into stdout Sending both error and output to a single file cmd > logfile 2>&1 Allowed anywhere on the command line, but order matters \"cmd < inputfile > outputfile\" is similar to \">outputfile cmd < inputfile\" cmd >logfile 2>&1 (Sends errors to the logfile) 2>&1 >logfile cmd (Sends errors to stdout)","title":"Input and Output"},{"location":"pluralsight/blinc/phase1/shellScripting/#control-flows","text":"while while test; do ;; code to be repeated done until until test; do ;; code to be repeated done Repeats code in the block Continues as long as test returns false The classic for loop for VAR in WORDS; do ;; code to be repeated done Assign each word in WORDS to var in turn Will stop when no words are left Do NOT quote words The C-style for loop for (( INIT; TEST; UPDATE )); do ;; loop code done Use double parentheses First expression : initialize your loop variables Second expression : a test. The loop will run as long as this is true Third expression : update the loop variables Expression use syntax for arithmetic evaluation Break and Continue break quits the loop continue skips the rest of the current iteration continues with the next iteration Both can be used in for, while and until case case WORD in PATTERN1) code for pattern 1;; PATTERN2) code for pattern 2;; ... PATTERNn) code for pattern n;; esac Matches word with patterns Pattern matching is the same as with matching filename patterns Use 8, ?, [] Code for first pattern that mathes gets executed End code with ;; SO you can use multiple statements separated by ; Multiple patterns separated by | Command groups Group commands with {} Will group them into a single statement Can use I/O redirection for the whole group Use the group in an if statement or while loop Return status is that of the last command in the group { cmd1;cmd2;cmd3 } Separate the commands with newlines or semicolons Use spaces around braces Ending semicolon or newline not optional || and && Execute next statement depending on return status of previous statement Basically : short for if && Will execute next statement only if previous one succeeded mkdir newdir && cd newdir || Will execute next statement only if previous one failed [[ $1 ]] || echo\"missing argument\">&2 [[ $1 ]] || echo\"missing argument\">&2&& exit 1 Dont do this: will always exit [[ $1 ]] || {echo\"\"missing argument\">&2; exit 1;}","title":"Control Flows"},{"location":"pluralsight/blinc/phase1/shellScripting/#variables-2","text":"Variable attributes Variables hold simple string values But can also have extra attributes Turn these on/off with declare You can also use \"typeset\" (but that is deprecated) Print attributes for a variable declare -p var Integer Variables Interger variable declare -i num Now $num can hold only numbers Trying to set it to something else will NOT give an error Instead, this will set a value of 0 Unset an attribute with + declare +i num Triggers arithmetic evaluation Arithmetic expressions C-like syntax for doing calculations let command let n=100/2 (( .. )) ((++x)) ((p=x/100)) (( p=$(ls |wc-1)*10 )) This is a command equivalent to let $(( .. )) This is substitution, not a command p=$((x / 100)) With a variable declared as an integer num=\"30 % 8\" No need to quote variables (( .. )) can be used in if, while 0 is false, anything greater than 0 is true (( 0 )) || echo \"false\" Pitfall : numbers with leading zeroes are interpreted as octal So 010 = 8 (( ..; ..; .. )) syntax in for loop is not an arithmetic expression but the three expressions separated by ; are Read only variables declare -r constant=\"some value\" Cannot give $constant another value Bach will report an error Exporting variables By default, variables are local to you script Or terminal session Export a variable To make it available to subprocesses You cannot pass a variable to the program that runs you script export var export var=\"value\" declare -x var declare -x var=\"value\" Arrays An array can hold multiple values Stored and retrieved by index Storing a value x[0] = \"some\" x[1] = \"word\" Retrieving a value ${x[0]} : same ${x[1]} : word ${x[@]} or ${x[ ]} retrieve all values (quoting works like $ , $@) declare -a x Or simply assign with an index like above Intializing an array ar = (1 2 3 a b c) Count the number of elements in $array ${#array[@]} The indices in $array ${!array[@]} The can be gaps in the indices You cannot export an array Bash 4 supports associative Arrays Where elements are stored and retrieved by a name, not an index declare -A array","title":"Variables 2"},{"location":"pluralsight/blinc/phase1/shellScripting/#handling-script-parameters","text":"Special variables Hold the n-th command line argument : $1, $2, etc. Above 9 use braces : ${10}, ${25} $0 Holds name of the script as it was called $@ : All Equivalent to $1 $2 $3 ... $N But when double quoted : \"$1\" \"$2\" \"$3\" ... \"$N\" So parameters containing multiple words stay intact $* Equivalent to $1 $2 $3 ... $N But when double quoted : \"$1 $2 $3 ... $N\" Dont use this, use $@ instead $# Holds the number of arguments passed to the script Shift Removes the first argument All positions paramters shift $2 -> $1 $3 -> $2 $4 -> $3 etc. $# lowered by 1 Getopts Utility to help parse argument lists Expects options to start with a dash (-x) Allows options that take an argument (-f file) getopts optstring name optstring A list of expected options \"ab\" will let your script handle an option -a and/or -b Append : to options that take an argument \"a:b\" will let a take an argument, but not b name The name of a variable Every time you get getopts, it will place the next option into $name getopts returns false when no more options are left Any word not starting with a dash will end option processing So anything after the options, you have to parse for yourself An option \"--\" will be seen as the end of options as well Arguments for options will be put in OPTARG OPTIND holds the index of the next argument to be processed","title":"Handling script parameters"},{"location":"pluralsight/blinc/phase1/shellScripting/#shell-functions","text":"Functions Define your own command name () { ... } You can run the code in the braces as a new command Other equivalent syntax (not recommended) function name () { ... } function name { ... } Execute it like any command Give it arguments Use redirection Positional parameters are available for function arguments $1, $2, ... Naming your functions Same rules as for naming scripts : don't override existing commands Bash variables are globally visible In a function, you can make a variable local to that function Use declare or local Exit a function with return returns a status code, like exit Without a return statement, function returns status of last statement Returning any other value Use a global variable Or send the data to output and use command substitution Exporting a function export -f fun Miscellaneous Functions and redirection Redirection is allowed immediately after function definition Will be executed when function is run A command in a pipeline runs in a subshell Here documents Have a command read its input from the source file << Tag Tag defines end of input","title":"Shell Functions"},{"location":"pluralsight/blinc/phase1/shellScripting/#fun-with-strings","text":"Parameter Expansion Allows powerful string manipulation ${#var} : length of $var Removing a pattern Removing part of a string ${var#pattern} : Removes shortest match from begin of string ${var##pattern} : Removes longest match from begin of string ${var%pattern} : Removes shortest macth from end of string ${var%%pattern} : Removes longest match from end of string Pattern matching is like pathname matching with *, ? and [] Example : i=\"/Users/reindert/demo.txt\" ${i# /} returns \"Users/reindert/demo.ext\" ${i## /} returns \"demo.txt\" ${i%. } returns \"/Users/reindert/demo\" ${i%/ } returns \"/Users/reindert\" Search and replace Search and replace ${var/pattern/string} : Substitute first match with string ${var//pattern/string} : Substitute all matches with string Anchor your pattern ${var/#pattern/string} : Matches beginning of the string ${var/%pattern/string} : Matches end of the string Default values Default value ${var:-value} : Will evaluate to \"value\" if var is empty or unset ${var-value} : Similar, but only if var is unset Assign a default value ${var:=value} : If var was empty or unset, this evaluates to \"value\" and assigns it to var ${var=value} : Similar, but only if var is unset Conditional Expression Patterns ==, != operators in [[ .. ]] do pattern matching == is the same operator as = [[ $var == pattern ]] : Returns true wehn $var matches the pattern Pattern matching is like pathname matching with *, ? and [] Use quotes to force string matching =~ does regular expression matching Very powerful Uses POSIX extended regular expressions ? matches the token before it 0 or 1 times [0-9]? will match a single digit or nothing at all matches the token before it for any number of times [a-z]* will match any lowercase text or nothing at all matches the token before it for one or more times [0-9]+ will match 1 or more digits ^ matches start of string $ macthes end of string End of options Is denoted by -- Supported by many UNIX commands Arguments after this will not be interpreted as options Makes it safe when working with data that starts with a dash Good habit : When you use a variable as an argument for a command And the contents of the variable are not under you Control Use -- with the commands you call","title":"Fun with Strings"},{"location":"pluralsight/blinc/phase1/shellScripting/#many-ways-to-run-your-scripts","text":"Running code from a file Using hash-bang and running it as a command Will start a bash subprocess Executable permission has to be set Or when it does not have a hash-bang bash myscript No permission necessary bash -x myscript : Debugs myscript TO import code in the current shell process source myscript .myscript This is basically what happens with .bashrc Background and nohup Put a command in the background with & myscript & It will be disconnected from the interactive session Will be suspended if it tries to read input from the terminal Long-running scripts Keep your script running when you exit the terminal session nohup myscript & Run your script with a lower priority nice myscript Redurecting with exec Redirect I/O for the whole script Useful for logging Running your script another time At Will execute your script at a specific time Cron Will execute your script according to a schedule On Mac OS, use launchd On Ubuntu, you may want to look at Upstart set and shopt Customize bash behaviour with set and shopt set -x prints each command with its arguments as it is executed -u gives an error when using an uninitialised variable and exits script -n read commands but do not execute -v print each command as it is read -e exits script whenever a command fails shopt Can set many options with -s, unset with -u shopt -s nocaseglob : Ignore case with pathname expansion shopt -s extglob : Enable extended pattern matching shopt -s dotglob : Include hidden files with pathname expansion set -o noclobber : Don;t overwrite files on redirection operations","title":"Many Ways to Run Your Scripts"},{"location":"pluralsight/blinc/phase1/tddTheBigPicture/","text":"TDD - The Big Picture What is Test-Driven Development (TDD) Software Development Challenges Costs of developing software Maintenance accounts for 65% of all software development costs. Maintenance Challenges Code entropy Brittle over time Increased rigidness Isolated Ownership Coder-owned silos Lack of team empowerment Infrequent Validation Regression-prone High risk of code changes Legacy code Source code inherited from someone else SOurce code inherited from on older version of the software Code without tests What is Test-Droven Development? Test A procedure intended to establish the quality, performance, or reliability of something, especially before it is taken into widespread use Satisfies requirements Responds correctly to all input Acceptable performance Test-Driven Development A software development process that relies on the repetition of a very short development cycle : requirements are turned into very specific test cases, the the software is improved to pass the new tests, only. Motto : Red-Green-Refactor Red : Write test that fails Green : Make test pass Refactor : Refactor/cleanup code Why practice TDD? Business benefits Requirements verification Regression catching Lower maintenance costs Developer benefits Design-first Avoid over-engineering Momentum Confidence Code kata Kata A system of individual training exercises for practitioners of karate and other martial arts Practice Learning Keeping focused on the customer What was spec'd What was delivered What customer wanted Different ways of Testing Applications Types of Testing Unit testing Integration testing Acceptance testing Testing styles Black box testing White box testing Testing frameworks and tools xUnit frameworks SUnit (Smalltalk) JUnit (Java) User interface frameworks Selenium Watir System frameworks Simian Army Testing concepts Framework concepts Test Before Test After Test Test Suite Before Suite After Suite Verification concepts Assert Test Execution Test Runner Synchronous vs Asynchronous Strategies and Techniques for Testing Code Dependency Injection In software engineering, dependency injection is a technique whereby one object supplies the dependencies of another object A dependency is an object that can be used An injection is the passing of a dependency to a dependent object that would use it Types of dependency injection Constructor injection Providing dependencies through a class constructor Property/Setter injection Using a property or setter method to inject a dependency Interface injection Client defines interface that describes how dependencies are injected into it. Test doubles Test double is a \"generic term for any kind of pretend object used in place of a real object for testing purposes\" Types of test doubles Stubs : Provide canned answers to calls made during the test. Mocks : Pre-programmed with expectations which form a specification. Fakes Spies Best practices Treat test code like production code Write readable and maintainable test code Address bpth positive and negative test cases Separate common set-up and teardown logic Focus only on necessary values and results Only assert on values required to verify the test is passing Review tests and test practices with team Effective techniques Catching bad habits Common challenges TDD Gotchas Testing anti-patterns Dependencies between tests Execution order of tests should not matter Interdependent tests cause cascading failures and false positives Serial execution versus parallel execution Testing implementation details Tests should focus on the \"what\" not the \"how\" Testing implementation details leads to brittle tests that break when refactoring Slow-running tests Prevents rapid red/green/refactor cycles Warning-sign that code might be too coupled Warning-sign that code might not be very testable Long-running tests Lower developer confidence Slower release cycles Less agile Limitations of TDD Possible holes in TDD TDD is not sufficient by itself Deployment verification Network changes Integration testing Management support is vital","title":"TDD The Big Picture"},{"location":"pluralsight/blinc/phase1/tddTheBigPicture/#tdd-the-big-picture","text":"","title":"TDD - The Big Picture"},{"location":"pluralsight/blinc/phase1/tddTheBigPicture/#what-is-test-driven-development-tdd","text":"Software Development Challenges Costs of developing software Maintenance accounts for 65% of all software development costs. Maintenance Challenges Code entropy Brittle over time Increased rigidness Isolated Ownership Coder-owned silos Lack of team empowerment Infrequent Validation Regression-prone High risk of code changes Legacy code Source code inherited from someone else SOurce code inherited from on older version of the software Code without tests What is Test-Droven Development? Test A procedure intended to establish the quality, performance, or reliability of something, especially before it is taken into widespread use Satisfies requirements Responds correctly to all input Acceptable performance Test-Driven Development A software development process that relies on the repetition of a very short development cycle : requirements are turned into very specific test cases, the the software is improved to pass the new tests, only. Motto : Red-Green-Refactor Red : Write test that fails Green : Make test pass Refactor : Refactor/cleanup code Why practice TDD? Business benefits Requirements verification Regression catching Lower maintenance costs Developer benefits Design-first Avoid over-engineering Momentum Confidence Code kata Kata A system of individual training exercises for practitioners of karate and other martial arts Practice Learning Keeping focused on the customer What was spec'd What was delivered What customer wanted","title":"What is Test-Driven Development (TDD)"},{"location":"pluralsight/blinc/phase1/tddTheBigPicture/#different-ways-of-testing-applications","text":"Types of Testing Unit testing Integration testing Acceptance testing Testing styles Black box testing White box testing Testing frameworks and tools xUnit frameworks SUnit (Smalltalk) JUnit (Java) User interface frameworks Selenium Watir System frameworks Simian Army Testing concepts Framework concepts Test Before Test After Test Test Suite Before Suite After Suite Verification concepts Assert Test Execution Test Runner Synchronous vs Asynchronous","title":"Different ways of Testing Applications"},{"location":"pluralsight/blinc/phase1/tddTheBigPicture/#strategies-and-techniques-for-testing-code","text":"Dependency Injection In software engineering, dependency injection is a technique whereby one object supplies the dependencies of another object A dependency is an object that can be used An injection is the passing of a dependency to a dependent object that would use it Types of dependency injection Constructor injection Providing dependencies through a class constructor Property/Setter injection Using a property or setter method to inject a dependency Interface injection Client defines interface that describes how dependencies are injected into it. Test doubles Test double is a \"generic term for any kind of pretend object used in place of a real object for testing purposes\" Types of test doubles Stubs : Provide canned answers to calls made during the test. Mocks : Pre-programmed with expectations which form a specification. Fakes Spies Best practices Treat test code like production code Write readable and maintainable test code Address bpth positive and negative test cases Separate common set-up and teardown logic Focus only on necessary values and results Only assert on values required to verify the test is passing Review tests and test practices with team Effective techniques Catching bad habits Common challenges","title":"Strategies and Techniques for Testing Code"},{"location":"pluralsight/blinc/phase1/tddTheBigPicture/#tdd-gotchas","text":"Testing anti-patterns Dependencies between tests Execution order of tests should not matter Interdependent tests cause cascading failures and false positives Serial execution versus parallel execution Testing implementation details Tests should focus on the \"what\" not the \"how\" Testing implementation details leads to brittle tests that break when refactoring Slow-running tests Prevents rapid red/green/refactor cycles Warning-sign that code might be too coupled Warning-sign that code might not be very testable Long-running tests Lower developer confidence Slower release cycles Less agile Limitations of TDD Possible holes in TDD TDD is not sufficient by itself Deployment verification Network changes Integration testing Management support is vital","title":"TDD Gotchas"},{"location":"pluralsight/blinc/phase2/javaWebFundamentals/","text":"Java Web Fundamentals Course Overview Topics covered : Using Servlets to build web applications Using Java ServerPages to return HTML content Using Servlets and Java ServerPages together Using filters to compress data Using event handlers Prerequisites Programming in Java Introduction Java Web Programming Java web typically made up of Servlets and Java Server Pages Many frameworks, e.g. Struts build on top of these specifications There are other aspects such as Filters and Listeners Deploying to a weeb server Unit od deployment is called a 'web application' A web application is a deployable unit of content and configuration Request routed to application using URL base Web applications may contain static content Web applications may contain dynamically generated content Deployment Java web applications have a standard structure Applications can be deployed by simply copying files Can also deploy as a .war file Web Archive Writing Servlets Servlet interface Method index destroy() Cleans up whatever resources are being held (e.g., memory, file handles, threads) and makes sure that any persistent state is synchronized with the servlet's current in-memory state. getServletConfig() Returns a servlet config object, which contains any initialization parameters and startup configuration for this servlet. getServletInfo() Returns a string containing information about the servlet, such as its author, version, and copyright. init(ServletConfig) Initializes the servlet. service(ServletRequest, ServletResponse) Carries out a single request from the client. Request Routing Server routes request to servlet using configuration info Held in web.xml By default, one servlet instance handles all requests to associated URL Servlet mapping in web.xml <web-app> <servlet> <servlet-name>Home</servlet-name> <servlet-class>com.pronit.OurServlet</servlet-class> </servlet> <servlet-mapping> <servlet-name>Home</servlet-name> <url-pattern>/Bar</url-pattern> </servlet-mapping> <servlet-mapping> <servlet-name>Home</servlet-name> <url-pattern>*.abc</url-pattern> </servlet-mapping> </web-app> HTTP Request Processing HttpServletRequest wraps an HTTP request HttpServletResponse wraps the potential HTTP response Using Initialisation Parameters <web-app> <servlet> <servlet-name>Foo</servlet-name> <servlet-class>con.pronit.OutServlet</servlet-class> </servlet> <init-param> <param-name>connstr</param-name> <param-value>server=home;catalog=pubs;uid=sa;pwd=;</param-value> </init-param> </web-app> import javax.servlet.*; import javax.servlet.http.*; import java.IO.*; @WebServlet(urlPatterns = {\"/home\", \"*.do\"} initParams = { @WebInitParam(name = \"connstr\", value=\"server=...\") }) public class OurServlet extend HttpServlet { public init() { connstr = getInitParameter(\"connstr\"); } ... } ServletContext <web-app> <context-param> <param-name>connstr</param-name> <param-value>server=home;catalog=pubs;uid=sa;pwd=;</param-value> </context-param> </web-app> public class OurServlet extends HttpServlet { String connstr; public void init() { connstr = getServletContext().getInitParameter(\"connstr\"); } } JavaServer Pages Summary JSPs are a mixture of Text Script Directives JSP is the View in an MVC style web application Hide the pages in WEB-INF The Expression Language Why an Expression Language? Previous versions on JSP relied on Java as the scripting language Made it difficult to produce dynamic pages JSP 2.0 introduced an EL EL is very 'page-author' friendly Allows page authors a limited form of page scripting Using the Expression Language Syntax Always use ${expr} contruct EL can be used on page This will simply output the value of the expression <span>Name: ${user.name}</span> Accessing JavaBeans Can get bean property's use either .(dot) or [] syntax user.name user[\"name\"] can use [] for access to lists, maps, arrays and beans can nest arbitrarily a[\"name\"].first a[\"name\"][\"first\"] Implicit Objects EL has access to a set of implicit objects All Maps (except pageContext) requestScope applicationScope paramValues headerValues initParam pageScope sessionScope param header cookie Expression Language Operators Expressions can use operators Mathematical / div % mod == eq != ne < lt > gt <= le >= ge Logical && and ! not || or Empty operator Empty Summary The Expression Language Not a \"full\" language Gives access to properties on JavaBeans Can use the '.' or '[]' syntax Has access to built in intrinsics Has a set of operators Can access collections The Java Standard Tag Library Why Tags? Provide encapsulation of (UI) logic Replace script on a page Better for page designers than having to write Java code What is a 'TagLibrary'? Tag libraries are collections of tags The Java Standard Tag Library (JSTL) is a set of standard tags used in JavaServer Pages Using Tags Tags are managed as libraries Individual tags are Java classes Tag metadata held in Tag Library Desciptor file Collected together in a JAR file Core tags Conditional If Choose - when or otherwise Iteration Two tags, for-each and for-tokens that support Exporting an object that holds the current value Ranges to iterator Exposure of a status variable Import Managing text is an important part of JSP == ++ Can import from This context Another context on this server Another server Imported data can be Written to page Stored in a string 'stored' in a Reader URL There are issues with relative URLs in a web application No concept of a 'web application' Using '/[url' give server relative URLs /somepage.jsp http://myserver.com/somepage.jsp Using '[url]' somewhere.jsp is relative to the page From foo/index.jsp would give http://myserver.com/myapp/foo/somepage.jsp Allows the creation of application relative URLs Also adds session encoding where necessary Can specify 'value' of URL 'params' to be added Can create application relative URLs Application relative URLs start with a '/' Set 'context' param if importing from a foreign context Summary JSTL provides a core set of tags These allow page authors control over 'view' logic Allow better control over URLs Other functionality also provided SQL XML Writing Tag Libraries Tags are a great way of extending JSP functionality Tags can be written in Java Tags can be written in JSP Tags can be passed 'simple' data as attributes Tags can be passed as fragments of HTML as attributes Tags can be variables Event listeners Annotations - Reminder Can replace or augment settings web.xml Only these are scanned classes in WEB-INF/classes JARs in WEB-INF/lib Can set metadata-complete=\"true\" on web-app Stops any scanning for annotations What Annotations exist? @WebServlet @WebFilter @WebInitParam @WebListener @MultipartConfig Event Listeners Events are fired at users at appropriate times Application Events at app start/end Session Events at Session start/end Request Events at Request start/end Attribute events when attribute added/removed Listeners listen for events Listener Implementation Listeners Implement Appropriate Interface ServletContextListener ServletContextAttributeListener HttpSessionActivationListener HttpSessionAttributeListener ServletRequestListener ServletRequestAttributeListener Passed appropriate \"Event\" object Registering Listeners Listeners are registered in web.xml Fire in order of listing for activation Fire in reverse order for deactivation <listener> <listener-class> com.mantisso.WhitePagesListener </listener-class> </listener> Listeners Annotations @WebListener Application Listener Implements ServletContextListener Fired at application Start/End Passed a ServletContextEvent Gives access to ServletContext Session Listener Fired after Session start Fired before Session ends In servlet 2.3 spec fired after session ended Passed and HttpSessionEvent gives access to HttpSession Request Listener Fired before request comes into scope Before it enters first filter in the chain Fired before request goes out of scope After it's left the last filter ServletRequestEvent gives access to ServletContext ServletRequest Listener issues - Exceptions Application initiated Exceptions e.g. adding an object to a session causes listener to throw exception Exception passed to application No more listeners fired Container initiated exceptions e.g. Application listener causes exception at start-up Not handled by application May cause container to make application unavilable Container will return HTTP 500 status code Summary Web applications fire 'events' EventListeners can respond to these Manage application/ session/ request start/ end Configure in web.xml or annotations Writing filters What is a filter? Code that intercepts a request and does extra processing They are executed before / after the request is executed The request could be to a servlet / JSP / HTML etc. Request / Response could be modified in the filter Filters can be executed as a part of a chain Filters can intercept original request Filters can intercept forwards and includes Can use filters to provide : Session management Logging Security XML transforms The filters are called synchronously, so this trace all happens on the same thread Writing filters Filter writers implement javax.servlet.Filter doFilter() may \"wrap\" Request and/or Response Call chain.doFilter(...) to pass on the request doFilter can dispatch the request to a different resource doFilter may return to the caller without chaining the request Filter configuration Filter Configures in Deployment Descriptor Maybe associated with a URL Maybe associated with a named resource Initialisation Method Called once when the filter is loaded Passed a reference to a FilterConfig Use this to get a reference to the ServletContext if necessary diFilter is passed the request, response and the filter chain Wrapping Request Can extend HttpServletRequestWrapper Adaptor class that takes original request object as constructor parameter Default behaviour is to simply call the original request Override necessary methods Can : invent headers, change attributes, log calls, etc. Wrapping Response Filter may want to change response Can create HttpServletResponseWrapper More interesting than HttpServletRequestWrapper Have to cope with (at least) content length, content type, getWriter and getOutputStream Filters under Forward and Include Default behaviour for filters is to not work under forward/include Servlet 2.4 specificatios intorduces this ability Annotations @WebFilter name urlPatterns (required) dispatcherType servletName asyncSupported ...and others @WebInitParam Used to parameterize the filter Summary Filters allow us to add services to Web applications Extremely powerful addition to the servlet specification Request Wrappers allow us to change the request data that a resource sees Response Wrappers allow us to filter responses before they are sent to the client Asynchronous Programming Why Asynchronous Servlets? Slow backend resources Reuse of threads Server Push How do Asynchronous Servlets work? Get and asynchronous context Start the context to handle the request Use the context to return the responses (Optionally) Add a 'listener' to handle events Async filters Filters can also be asynchronous Mechanism similar to Servlet Summary Servlet 3 specification introduced asynchronous behaviour Servlets Filters Be careful while using May end up offloading one thread to another with no benefit","title":"Java Wev Fundamentals"},{"location":"pluralsight/blinc/phase2/javaWebFundamentals/#java-web-fundamentals","text":"","title":"Java Web Fundamentals"},{"location":"pluralsight/blinc/phase2/javaWebFundamentals/#course-overview","text":"Topics covered : Using Servlets to build web applications Using Java ServerPages to return HTML content Using Servlets and Java ServerPages together Using filters to compress data Using event handlers Prerequisites Programming in Java","title":"Course Overview"},{"location":"pluralsight/blinc/phase2/javaWebFundamentals/#introduction","text":"Java Web Programming Java web typically made up of Servlets and Java Server Pages Many frameworks, e.g. Struts build on top of these specifications There are other aspects such as Filters and Listeners Deploying to a weeb server Unit od deployment is called a 'web application' A web application is a deployable unit of content and configuration Request routed to application using URL base Web applications may contain static content Web applications may contain dynamically generated content Deployment Java web applications have a standard structure Applications can be deployed by simply copying files Can also deploy as a .war file Web Archive","title":"Introduction"},{"location":"pluralsight/blinc/phase2/javaWebFundamentals/#writing-servlets","text":"Servlet interface Method index destroy() Cleans up whatever resources are being held (e.g., memory, file handles, threads) and makes sure that any persistent state is synchronized with the servlet's current in-memory state. getServletConfig() Returns a servlet config object, which contains any initialization parameters and startup configuration for this servlet. getServletInfo() Returns a string containing information about the servlet, such as its author, version, and copyright. init(ServletConfig) Initializes the servlet. service(ServletRequest, ServletResponse) Carries out a single request from the client. Request Routing Server routes request to servlet using configuration info Held in web.xml By default, one servlet instance handles all requests to associated URL Servlet mapping in web.xml <web-app> <servlet> <servlet-name>Home</servlet-name> <servlet-class>com.pronit.OurServlet</servlet-class> </servlet> <servlet-mapping> <servlet-name>Home</servlet-name> <url-pattern>/Bar</url-pattern> </servlet-mapping> <servlet-mapping> <servlet-name>Home</servlet-name> <url-pattern>*.abc</url-pattern> </servlet-mapping> </web-app> HTTP Request Processing HttpServletRequest wraps an HTTP request HttpServletResponse wraps the potential HTTP response Using Initialisation Parameters <web-app> <servlet> <servlet-name>Foo</servlet-name> <servlet-class>con.pronit.OutServlet</servlet-class> </servlet> <init-param> <param-name>connstr</param-name> <param-value>server=home;catalog=pubs;uid=sa;pwd=;</param-value> </init-param> </web-app> import javax.servlet.*; import javax.servlet.http.*; import java.IO.*; @WebServlet(urlPatterns = {\"/home\", \"*.do\"} initParams = { @WebInitParam(name = \"connstr\", value=\"server=...\") }) public class OurServlet extend HttpServlet { public init() { connstr = getInitParameter(\"connstr\"); } ... } ServletContext <web-app> <context-param> <param-name>connstr</param-name> <param-value>server=home;catalog=pubs;uid=sa;pwd=;</param-value> </context-param> </web-app> public class OurServlet extends HttpServlet { String connstr; public void init() { connstr = getServletContext().getInitParameter(\"connstr\"); } }","title":"Writing Servlets"},{"location":"pluralsight/blinc/phase2/javaWebFundamentals/#javaserver-pages","text":"Summary JSPs are a mixture of Text Script Directives JSP is the View in an MVC style web application Hide the pages in WEB-INF","title":"JavaServer Pages"},{"location":"pluralsight/blinc/phase2/javaWebFundamentals/#the-expression-language","text":"Why an Expression Language? Previous versions on JSP relied on Java as the scripting language Made it difficult to produce dynamic pages JSP 2.0 introduced an EL EL is very 'page-author' friendly Allows page authors a limited form of page scripting Using the Expression Language Syntax Always use ${expr} contruct EL can be used on page This will simply output the value of the expression <span>Name: ${user.name}</span> Accessing JavaBeans Can get bean property's use either .(dot) or [] syntax user.name user[\"name\"] can use [] for access to lists, maps, arrays and beans can nest arbitrarily a[\"name\"].first a[\"name\"][\"first\"] Implicit Objects EL has access to a set of implicit objects All Maps (except pageContext) requestScope applicationScope paramValues headerValues initParam pageScope sessionScope param header cookie Expression Language Operators Expressions can use operators Mathematical / div % mod == eq != ne < lt > gt <= le >= ge Logical && and ! not || or Empty operator Empty Summary The Expression Language Not a \"full\" language Gives access to properties on JavaBeans Can use the '.' or '[]' syntax Has access to built in intrinsics Has a set of operators Can access collections","title":"The Expression Language"},{"location":"pluralsight/blinc/phase2/javaWebFundamentals/#the-java-standard-tag-library","text":"Why Tags? Provide encapsulation of (UI) logic Replace script on a page Better for page designers than having to write Java code What is a 'TagLibrary'? Tag libraries are collections of tags The Java Standard Tag Library (JSTL) is a set of standard tags used in JavaServer Pages Using Tags Tags are managed as libraries Individual tags are Java classes Tag metadata held in Tag Library Desciptor file Collected together in a JAR file Core tags Conditional If Choose - when or otherwise Iteration Two tags, for-each and for-tokens that support Exporting an object that holds the current value Ranges to iterator Exposure of a status variable Import Managing text is an important part of JSP == ++ Can import from This context Another context on this server Another server Imported data can be Written to page Stored in a string 'stored' in a Reader URL There are issues with relative URLs in a web application No concept of a 'web application' Using '/[url' give server relative URLs /somepage.jsp http://myserver.com/somepage.jsp Using '[url]' somewhere.jsp is relative to the page From foo/index.jsp would give http://myserver.com/myapp/foo/somepage.jsp Allows the creation of application relative URLs Also adds session encoding where necessary Can specify 'value' of URL 'params' to be added Can create application relative URLs Application relative URLs start with a '/' Set 'context' param if importing from a foreign context Summary JSTL provides a core set of tags These allow page authors control over 'view' logic Allow better control over URLs Other functionality also provided SQL XML","title":"The Java Standard Tag Library"},{"location":"pluralsight/blinc/phase2/javaWebFundamentals/#writing-tag-libraries","text":"Tags are a great way of extending JSP functionality Tags can be written in Java Tags can be written in JSP Tags can be passed 'simple' data as attributes Tags can be passed as fragments of HTML as attributes Tags can be variables","title":"Writing Tag Libraries"},{"location":"pluralsight/blinc/phase2/javaWebFundamentals/#event-listeners","text":"Annotations - Reminder Can replace or augment settings web.xml Only these are scanned classes in WEB-INF/classes JARs in WEB-INF/lib Can set metadata-complete=\"true\" on web-app Stops any scanning for annotations What Annotations exist? @WebServlet @WebFilter @WebInitParam @WebListener @MultipartConfig Event Listeners Events are fired at users at appropriate times Application Events at app start/end Session Events at Session start/end Request Events at Request start/end Attribute events when attribute added/removed Listeners listen for events Listener Implementation Listeners Implement Appropriate Interface ServletContextListener ServletContextAttributeListener HttpSessionActivationListener HttpSessionAttributeListener ServletRequestListener ServletRequestAttributeListener Passed appropriate \"Event\" object Registering Listeners Listeners are registered in web.xml Fire in order of listing for activation Fire in reverse order for deactivation <listener> <listener-class> com.mantisso.WhitePagesListener </listener-class> </listener> Listeners Annotations @WebListener Application Listener Implements ServletContextListener Fired at application Start/End Passed a ServletContextEvent Gives access to ServletContext Session Listener Fired after Session start Fired before Session ends In servlet 2.3 spec fired after session ended Passed and HttpSessionEvent gives access to HttpSession Request Listener Fired before request comes into scope Before it enters first filter in the chain Fired before request goes out of scope After it's left the last filter ServletRequestEvent gives access to ServletContext ServletRequest Listener issues - Exceptions Application initiated Exceptions e.g. adding an object to a session causes listener to throw exception Exception passed to application No more listeners fired Container initiated exceptions e.g. Application listener causes exception at start-up Not handled by application May cause container to make application unavilable Container will return HTTP 500 status code Summary Web applications fire 'events' EventListeners can respond to these Manage application/ session/ request start/ end Configure in web.xml or annotations","title":"Event listeners"},{"location":"pluralsight/blinc/phase2/javaWebFundamentals/#writing-filters","text":"What is a filter? Code that intercepts a request and does extra processing They are executed before / after the request is executed The request could be to a servlet / JSP / HTML etc. Request / Response could be modified in the filter Filters can be executed as a part of a chain Filters can intercept original request Filters can intercept forwards and includes Can use filters to provide : Session management Logging Security XML transforms The filters are called synchronously, so this trace all happens on the same thread Writing filters Filter writers implement javax.servlet.Filter doFilter() may \"wrap\" Request and/or Response Call chain.doFilter(...) to pass on the request doFilter can dispatch the request to a different resource doFilter may return to the caller without chaining the request Filter configuration Filter Configures in Deployment Descriptor Maybe associated with a URL Maybe associated with a named resource Initialisation Method Called once when the filter is loaded Passed a reference to a FilterConfig Use this to get a reference to the ServletContext if necessary diFilter is passed the request, response and the filter chain Wrapping Request Can extend HttpServletRequestWrapper Adaptor class that takes original request object as constructor parameter Default behaviour is to simply call the original request Override necessary methods Can : invent headers, change attributes, log calls, etc. Wrapping Response Filter may want to change response Can create HttpServletResponseWrapper More interesting than HttpServletRequestWrapper Have to cope with (at least) content length, content type, getWriter and getOutputStream Filters under Forward and Include Default behaviour for filters is to not work under forward/include Servlet 2.4 specificatios intorduces this ability Annotations @WebFilter name urlPatterns (required) dispatcherType servletName asyncSupported ...and others @WebInitParam Used to parameterize the filter Summary Filters allow us to add services to Web applications Extremely powerful addition to the servlet specification Request Wrappers allow us to change the request data that a resource sees Response Wrappers allow us to filter responses before they are sent to the client","title":"Writing filters"},{"location":"pluralsight/blinc/phase2/javaWebFundamentals/#asynchronous-programming","text":"Why Asynchronous Servlets? Slow backend resources Reuse of threads Server Push How do Asynchronous Servlets work? Get and asynchronous context Start the context to handle the request Use the context to return the responses (Optionally) Add a 'listener' to handle events Async filters Filters can also be asynchronous Mechanism similar to Servlet Summary Servlet 3 specification introduced asynchronous behaviour Servlets Filters Be careful while using May end up offloading one thread to another with no benefit","title":"Asynchronous Programming"},{"location":"pluralsight/blinc/phase2/springTheBigPicture/","text":"Spring - The Big Picture What is Spring 'Spring' could mean The Spring Framework Spring Boot Spring Data Spring Cloud Spring Batch Why 'Spring'? Spring started as a response to the complexity of J2EE (now Java EE) Today, Spring is so much more than an alternative to Java EE In fact, it's complimentary to Java EE Spring makes it easy to create Java enterprise applications Spring Flexible, modular, and backwards compatible Large and active community Continually innovates and evolves Getting to Know Spring with Spring Boot Spring Boot notable features Auto-configuration Standalone Opinionated Spring Boot Auto-configuration Attempts to automatically configure your Spring application based on the dependencies that you have added Auto-configurations are contextually aware and smart Setting up Auto-configuration is effortless Use the annotation @EnableAutoConfiguration Spring Boot being Standalone Spring Boot makes it easy to create stand-alone, production-grade, Spring-based applications that you can 'just run'. Typical process for running Java Web Applications Package Application Choose and Download Webserver Configure Webserver Deploy Application and Start Webserver Spring java applications deployment Package application Run the application Spring Boot being Opinionated Takes an opinionated view of building production-ready Spring applications Spring Boot favors convention over configuration and is designed to get you up and running as quickly as possible Understanding Spring's Foundations : The Spring Framework Software Framework Is a universal, reusable software environment that provides particular functionality as part of a larger software platform to facilitate development of software applications, products and solutions The Spring Framework is modular Six key areas Core Web AOP Data access Integration Testing Spring Core Spring Core provides a number of different features i18n internalization support Validation support Data binding support Type conversion support At the center of Spring Core is Dependency Injection Developers create objects to represent or model real-life things Onjects don't exist by themselves Objects are dependent on other objects Dependency Injectionmis about dealing with the way objects fulfill their dependent objects Fulfilling delendencies The object fulfills its own dependencies Seems easy but tightly coupled objects The object declares what it depends on and something else fulfills the dependency More Flexible Loosely coupled objects Spring Core is a dependency injection container Creates and maintains objects and their dependencies Less for developer to manage It is the glue Spring Web Framework for handling web requests Spring Web MVC Spring Web Webflux Spring Web MVC Java Servlet A servlet is an object that receives a request and generates a response based on that request Challenges with the Servlet API Somewhat low-level API Not as easy to use Less productive Advantages of Spring MVC Higher Level API Easier to use More productive Clear separation of concerns Model View Controller Spring Webflux Reactive programming A declarative programming paradigm concerned with data streams and the propagation of change Spring Webflux A differnt way of handling web requests Asynchronous execution Doesn't block (wait) Better resource utilisation Spring AOP Aspect-oriented Programming (AOP) A programming paradigm that aims to increase modularity by allowing the separation of cross-cutting concerns Used for Used to implement features in Spring A valuable tool for developers to handle cross-cutting concerns Spring Data Access Database transactions with the Spring Framework's Data Access module are really easy A database transaction is a series of database operations that must happen together or not at all The Spring Framework's Data Access module also provides Exception Translation Exceptions are an event within a program that disrupt execution Vendor-specific exceptions are mapped into a well-known set of exceptions Testing data is easier with the Spring Framework's Data Access module Spring Integration Applications dont live in isolation Integration is all about making different systems and applications work together The Spring Framework makes it easier to both expose and invoke web services Rest Template Abstracts away tedious details Handles Connecting to the web service Sending the command Handling the response RestTemplate makes calling web services as easy as one line Just call the service and RestTemplate takes care of the 'rest' Spring Testing Different ways of testing Unit Testing Unit Testing is a software development process in which the smallest testable parts of an application, called units, are individually and independently scrutinized for proper operation Explicit support for unit testing is minimal Benefits come from using dependency injection Testing and dependency injection Test the smallest unit of code possible Dependencies cause challenges Dependency injection forces the developer to declare dependencies Control how dependencies behave Only test the code, not the dependencies Mock dependencies Spring Framework comes with several built-in mocks to make testinf easier and faster Itegration Testing Integration Testing is the phase in software testing in which individual software modules are combined and tested as a group. It occures after unit testing. Spring Framework provides support for piecing together parts of an application for testing Inject dependencies and put everything together Spring Framework provides support for common testing scenarios Testing with data Web application testing Spring Framework provides support for cleaning up after tests Tests modify things, need to reverse modifications after test so as to not affect the next tests Is Spring a Good Fit? Advantages of Spring Rock solid and well engineered Stood the test of time Hige community Well-liked Large talent pool Whealth of existing knowledge Very actively developed Built-in IDE support Scalable Disadvantages of Spring Too much 'magic' Steep learning curve Increase the size of your deliverable Hard to debug Adds memory overhead Complexity has grown over time Spring can be too configurable Spring is 'big' Spring's community projects are hit or miss","title":"Spring The Big Picture"},{"location":"pluralsight/blinc/phase2/springTheBigPicture/#spring-the-big-picture","text":"","title":"Spring - The Big Picture"},{"location":"pluralsight/blinc/phase2/springTheBigPicture/#what-is-spring","text":"'Spring' could mean The Spring Framework Spring Boot Spring Data Spring Cloud Spring Batch Why 'Spring'? Spring started as a response to the complexity of J2EE (now Java EE) Today, Spring is so much more than an alternative to Java EE In fact, it's complimentary to Java EE Spring makes it easy to create Java enterprise applications Spring Flexible, modular, and backwards compatible Large and active community Continually innovates and evolves","title":"What is Spring"},{"location":"pluralsight/blinc/phase2/springTheBigPicture/#getting-to-know-spring-with-spring-boot","text":"Spring Boot notable features Auto-configuration Standalone Opinionated Spring Boot Auto-configuration Attempts to automatically configure your Spring application based on the dependencies that you have added Auto-configurations are contextually aware and smart Setting up Auto-configuration is effortless Use the annotation @EnableAutoConfiguration Spring Boot being Standalone Spring Boot makes it easy to create stand-alone, production-grade, Spring-based applications that you can 'just run'. Typical process for running Java Web Applications Package Application Choose and Download Webserver Configure Webserver Deploy Application and Start Webserver Spring java applications deployment Package application Run the application Spring Boot being Opinionated Takes an opinionated view of building production-ready Spring applications Spring Boot favors convention over configuration and is designed to get you up and running as quickly as possible","title":"Getting to Know Spring with Spring Boot"},{"location":"pluralsight/blinc/phase2/springTheBigPicture/#understanding-springs-foundations-the-spring-framework","text":"Software Framework Is a universal, reusable software environment that provides particular functionality as part of a larger software platform to facilitate development of software applications, products and solutions The Spring Framework is modular Six key areas Core Web AOP Data access Integration Testing Spring Core Spring Core provides a number of different features i18n internalization support Validation support Data binding support Type conversion support At the center of Spring Core is Dependency Injection Developers create objects to represent or model real-life things Onjects don't exist by themselves Objects are dependent on other objects Dependency Injectionmis about dealing with the way objects fulfill their dependent objects Fulfilling delendencies The object fulfills its own dependencies Seems easy but tightly coupled objects The object declares what it depends on and something else fulfills the dependency More Flexible Loosely coupled objects Spring Core is a dependency injection container Creates and maintains objects and their dependencies Less for developer to manage It is the glue Spring Web Framework for handling web requests Spring Web MVC Spring Web Webflux Spring Web MVC Java Servlet A servlet is an object that receives a request and generates a response based on that request Challenges with the Servlet API Somewhat low-level API Not as easy to use Less productive Advantages of Spring MVC Higher Level API Easier to use More productive Clear separation of concerns Model View Controller Spring Webflux Reactive programming A declarative programming paradigm concerned with data streams and the propagation of change Spring Webflux A differnt way of handling web requests Asynchronous execution Doesn't block (wait) Better resource utilisation Spring AOP Aspect-oriented Programming (AOP) A programming paradigm that aims to increase modularity by allowing the separation of cross-cutting concerns Used for Used to implement features in Spring A valuable tool for developers to handle cross-cutting concerns Spring Data Access Database transactions with the Spring Framework's Data Access module are really easy A database transaction is a series of database operations that must happen together or not at all The Spring Framework's Data Access module also provides Exception Translation Exceptions are an event within a program that disrupt execution Vendor-specific exceptions are mapped into a well-known set of exceptions Testing data is easier with the Spring Framework's Data Access module Spring Integration Applications dont live in isolation Integration is all about making different systems and applications work together The Spring Framework makes it easier to both expose and invoke web services Rest Template Abstracts away tedious details Handles Connecting to the web service Sending the command Handling the response RestTemplate makes calling web services as easy as one line Just call the service and RestTemplate takes care of the 'rest' Spring Testing Different ways of testing Unit Testing Unit Testing is a software development process in which the smallest testable parts of an application, called units, are individually and independently scrutinized for proper operation Explicit support for unit testing is minimal Benefits come from using dependency injection Testing and dependency injection Test the smallest unit of code possible Dependencies cause challenges Dependency injection forces the developer to declare dependencies Control how dependencies behave Only test the code, not the dependencies Mock dependencies Spring Framework comes with several built-in mocks to make testinf easier and faster Itegration Testing Integration Testing is the phase in software testing in which individual software modules are combined and tested as a group. It occures after unit testing. Spring Framework provides support for piecing together parts of an application for testing Inject dependencies and put everything together Spring Framework provides support for common testing scenarios Testing with data Web application testing Spring Framework provides support for cleaning up after tests Tests modify things, need to reverse modifications after test so as to not affect the next tests","title":"Understanding Spring's Foundations : The Spring Framework"},{"location":"pluralsight/blinc/phase2/springTheBigPicture/#is-spring-a-good-fit","text":"Advantages of Spring Rock solid and well engineered Stood the test of time Hige community Well-liked Large talent pool Whealth of existing knowledge Very actively developed Built-in IDE support Scalable Disadvantages of Spring Too much 'magic' Steep learning curve Increase the size of your deliverable Hard to debug Adds memory overhead Complexity has grown over time Spring can be too configurable Spring is 'big' Spring's community projects are hit or miss","title":"Is Spring a Good Fit?"},{"location":"pluralsight/paths/bdd/beginner/cleanArchitecture/","text":"Clean Architecture : Patterns, Practices, and Principles Course Overview Clean architecture Domain-centric architecture Application layer Commands and queries Functional organization Microservices Testable architecture Evolving the architecture Introduction Overview Purpose Philosophy of architectural essentialism Set of patterns, practices, and principles Alternative to traditional architecture Focus Enterprise applications Agile architecture Audience Developers Architects Prerequisites Basic programming experience Basic architecture experience What is Clean Code? What is Software Architecture? High-level Structure Layers Components Relationships Levels of Architectural Abstraction System Sub-systems Layers Components Classes Data and Methods What is Bad Architecture? Complex Incoherent Rigid Brittle Untestable Unmaintainable What is Good Architecture? Simple Understandable Flexible Emergent Testable Maintainable What is Clean Architecture? Architecture that is desgined for the inhabitants of the architecture... not for the architect... or the machine. Why invest in Clean Code? Why invest in Clean Architecture? Cost/Benefit Minimize cost Maximize value Maximize ROI Why Clean architecture? Focus on the essential Build only what is necessary Optimize for maintainability What do architects do? Context is king All decisions are a tradeoff Align with business goals Use the best judgement Domain Centric Architecture Introduction to Domain Centric Architecture Database-centric architecture UI Business Logic Data Access Database Domain-centric architecture Presentation + Persistence + Infrastructure Application Domain Database Essential vs. Detail in Domain Centric Architecture Domain is essential Use cases are essential Presentation is a detail Persistence is a detail Examples of such architecture Hexagonal architecture Onion architecture Clean architecture Why use Domain-centric architecture? Pros Focus on domain Less coupling Allows for DDD Cons Change is difficult Requires more thought Initial higher cost Application Layer Introduction to Application Layer What are Layers? Levels of abstraction Single-responsibility Isolate roles and skills Multiple implementations Varying rates of change What does Application Layer do? Implements use cases High-level application logic Knnows about the domain No knowledge of other layers Contains interfaces Layer dependencies Dependency inversion Inversion of control Independent deployability Flexible and maintainable Why use an Application Layer? Pros Focus on use cases Easy to understand Follows Dependency Inversion Principle Cons Additional layer cost Requires extra thought Inversion of Control is counter-intuitive Commands and Queries Introduction to Commands and Queries Command-Query Separation Command Does something Should modify state Should not return a value Query Answers a question Should not modify state Should return a value Command-Query Separation exceptions Pop a stack Remove item (command) Return top item (query) Create a new record Create record (command) Return new ID (query) Types of CQRS Single database CQRS Single database Commands use domain Queries use database Two database CQRS Read and write databases Commands use write DB Queries use read DB Eventual consistency Orders of magnitude faster Event sourcing CQRS Store events Replay events Modify entity Store new event Update read database Complete audit trail Point-in-time reconstruction Replay events Multiple read database Rebuild production database Why use CQRS? Pros More efficient design Optimised performance Event sourcing benefits Cons Inconsistent across stacks More commplex Event sourcing costs Functional Organization Introduction to Functional Organization Why use Functional Organization? Pros Spatial locality Easy to navigate Avoid vendor lock-in Cons Lose framework conventions Lose automatic scaffolding Categorical is easier at first Microservices Introduction to Microservices What do microservices do? Subdivide monoliths Clearly-defined interfaces Small teams Independent How does microservices segregate? Bounded context Cohesion/coupling Single domain of knowledge Consistent data model Independence Microservice per aggregate root Database per bounded context Why use microservices? Pros Flatter cost curve High cohesion/ low coupling Independence in development Cons Higher up-front cost Conway's low Distributed system costs Testable architecture Introduction to Testable architecture The current state of testing Very little testing Ineffective testing Inefficient testing Not enough time Not my job It's too hard Test Driven Development Create a failing test Get the test to pass Improve the code Repeat until functionality is completed Why Test Driven Development? Comprehensive suite of tests Drives testable design More maintainable Eliminates fear Types of Tests Based on what to test Unit tests Integration tests Component tests Service tests UI tests Based on why to test Functional tests Acceptance tests Smoke tests Exploratory tests Based on how to test Automated tests Semi-automated tests Manual tests Test Automation Pyramid Unit tests Service tests UI tests Manual tests Acceptance tests Verify functionality Language of the business Criteria for completeness Full tests are problematic How to perform acceptance tests Eliminate user interface Eliminate database Eliminate dependencies Focus on the essential Minimize coded UI tests Smoke test instead Minimize manual tests Exploratory test instead Why Create Testable Architecture Pros Easier to test Improves design Eliminates fear Cons Higher up-front cost TDD requires discipline Requires team buy-in","title":"Clean Architecture - Patterns, Practices and Principles"},{"location":"pluralsight/paths/bdd/beginner/cleanArchitecture/#clean-architecture-patterns-practices-and-principles","text":"","title":"Clean Architecture : Patterns, Practices, and Principles"},{"location":"pluralsight/paths/bdd/beginner/cleanArchitecture/#course-overview","text":"Clean architecture Domain-centric architecture Application layer Commands and queries Functional organization Microservices Testable architecture Evolving the architecture","title":"Course Overview"},{"location":"pluralsight/paths/bdd/beginner/cleanArchitecture/#introduction","text":"","title":"Introduction"},{"location":"pluralsight/paths/bdd/beginner/cleanArchitecture/#overview","text":"Purpose Philosophy of architectural essentialism Set of patterns, practices, and principles Alternative to traditional architecture Focus Enterprise applications Agile architecture Audience Developers Architects Prerequisites Basic programming experience Basic architecture experience","title":"Overview"},{"location":"pluralsight/paths/bdd/beginner/cleanArchitecture/#what-is-clean-code","text":"What is Software Architecture? High-level Structure Layers Components Relationships Levels of Architectural Abstraction System Sub-systems Layers Components Classes Data and Methods What is Bad Architecture? Complex Incoherent Rigid Brittle Untestable Unmaintainable What is Good Architecture? Simple Understandable Flexible Emergent Testable Maintainable What is Clean Architecture? Architecture that is desgined for the inhabitants of the architecture... not for the architect... or the machine.","title":"What is Clean Code?"},{"location":"pluralsight/paths/bdd/beginner/cleanArchitecture/#why-invest-in-clean-code","text":"Why invest in Clean Architecture? Cost/Benefit Minimize cost Maximize value Maximize ROI Why Clean architecture? Focus on the essential Build only what is necessary Optimize for maintainability What do architects do? Context is king All decisions are a tradeoff Align with business goals Use the best judgement","title":"Why invest in Clean Code?"},{"location":"pluralsight/paths/bdd/beginner/cleanArchitecture/#domain-centric-architecture","text":"","title":"Domain Centric Architecture"},{"location":"pluralsight/paths/bdd/beginner/cleanArchitecture/#introduction-to-domain-centric-architecture","text":"Database-centric architecture UI Business Logic Data Access Database Domain-centric architecture Presentation + Persistence + Infrastructure Application Domain Database Essential vs. Detail in Domain Centric Architecture Domain is essential Use cases are essential Presentation is a detail Persistence is a detail Examples of such architecture Hexagonal architecture Onion architecture Clean architecture Why use Domain-centric architecture? Pros Focus on domain Less coupling Allows for DDD Cons Change is difficult Requires more thought Initial higher cost","title":"Introduction to Domain Centric Architecture"},{"location":"pluralsight/paths/bdd/beginner/cleanArchitecture/#application-layer","text":"","title":"Application Layer"},{"location":"pluralsight/paths/bdd/beginner/cleanArchitecture/#introduction-to-application-layer","text":"What are Layers? Levels of abstraction Single-responsibility Isolate roles and skills Multiple implementations Varying rates of change What does Application Layer do? Implements use cases High-level application logic Knnows about the domain No knowledge of other layers Contains interfaces Layer dependencies Dependency inversion Inversion of control Independent deployability Flexible and maintainable Why use an Application Layer? Pros Focus on use cases Easy to understand Follows Dependency Inversion Principle Cons Additional layer cost Requires extra thought Inversion of Control is counter-intuitive","title":"Introduction to Application Layer"},{"location":"pluralsight/paths/bdd/beginner/cleanArchitecture/#commands-and-queries","text":"","title":"Commands and Queries"},{"location":"pluralsight/paths/bdd/beginner/cleanArchitecture/#introduction-to-commands-and-queries","text":"Command-Query Separation Command Does something Should modify state Should not return a value Query Answers a question Should not modify state Should return a value Command-Query Separation exceptions Pop a stack Remove item (command) Return top item (query) Create a new record Create record (command) Return new ID (query) Types of CQRS Single database CQRS Single database Commands use domain Queries use database Two database CQRS Read and write databases Commands use write DB Queries use read DB Eventual consistency Orders of magnitude faster Event sourcing CQRS Store events Replay events Modify entity Store new event Update read database Complete audit trail Point-in-time reconstruction Replay events Multiple read database Rebuild production database Why use CQRS? Pros More efficient design Optimised performance Event sourcing benefits Cons Inconsistent across stacks More commplex Event sourcing costs","title":"Introduction to Commands and Queries"},{"location":"pluralsight/paths/bdd/beginner/cleanArchitecture/#functional-organization","text":"","title":"Functional Organization"},{"location":"pluralsight/paths/bdd/beginner/cleanArchitecture/#introduction-to-functional-organization","text":"Why use Functional Organization? Pros Spatial locality Easy to navigate Avoid vendor lock-in Cons Lose framework conventions Lose automatic scaffolding Categorical is easier at first","title":"Introduction to Functional Organization"},{"location":"pluralsight/paths/bdd/beginner/cleanArchitecture/#microservices","text":"","title":"Microservices"},{"location":"pluralsight/paths/bdd/beginner/cleanArchitecture/#introduction-to-microservices","text":"What do microservices do? Subdivide monoliths Clearly-defined interfaces Small teams Independent How does microservices segregate? Bounded context Cohesion/coupling Single domain of knowledge Consistent data model Independence Microservice per aggregate root Database per bounded context Why use microservices? Pros Flatter cost curve High cohesion/ low coupling Independence in development Cons Higher up-front cost Conway's low Distributed system costs","title":"Introduction to Microservices"},{"location":"pluralsight/paths/bdd/beginner/cleanArchitecture/#testable-architecture","text":"","title":"Testable architecture"},{"location":"pluralsight/paths/bdd/beginner/cleanArchitecture/#introduction-to-testable-architecture","text":"The current state of testing Very little testing Ineffective testing Inefficient testing Not enough time Not my job It's too hard Test Driven Development Create a failing test Get the test to pass Improve the code Repeat until functionality is completed Why Test Driven Development? Comprehensive suite of tests Drives testable design More maintainable Eliminates fear Types of Tests Based on what to test Unit tests Integration tests Component tests Service tests UI tests Based on why to test Functional tests Acceptance tests Smoke tests Exploratory tests Based on how to test Automated tests Semi-automated tests Manual tests Test Automation Pyramid Unit tests Service tests UI tests Manual tests Acceptance tests Verify functionality Language of the business Criteria for completeness Full tests are problematic How to perform acceptance tests Eliminate user interface Eliminate database Eliminate dependencies Focus on the essential Minimize coded UI tests Smoke test instead Minimize manual tests Exploratory test instead Why Create Testable Architecture Pros Easier to test Improves design Eliminates fear Cons Higher up-front cost TDD requires discipline Requires team buy-in","title":"Introduction to Testable architecture"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/","text":"Modern Software Architecture: Domain Models, CQRS, and Event Sourcing DDD at a Glance Introduction Key Points Repositioning Domain-Driven Design Exploring Supporting Architectures UX-first Design Methodology DDD in History Domain-Driven Design in History Introduced 10+ years ago by Eric Evans Primary intent of tackling complexity in the heart of software Innovative guidelines and approach to design Where does the complexity comes from? Big Ball of Mud (BBM) A system that's largely unstructured, padded with hidden dependencies between parts, with a lot of data and code duplications and an unclear identification of layers and concerns - a spaghetti code jungle DDD Today Why is DDD so Intriguing? Captured known elements of design process Organized them into set of principles Made domain modeling the focus of development Different approach to building business logic DDD is still about the business logic Crunch knowledge about the domain Recognize subdomains Design a rich domain model Code by telling objects in the domain model what to do Supreme Goal of DDD Tackling complexity in the heart of software DDD represents a significant landmark in software development Took root in the Java space Blissfully ignored in .NET until recently DDD is more about analysis than about actual coding strategies The main focus of DDD has shifted Discovering the domain architecture more than organizing the business logic Domain Model remains a valid pattern to organize the business logic but other patterns can be used as well like: Object-oriented models Functional models CQRS Classic 3-tier 2-tier DDD Misconceptions Common summary of DDD Build an object model for the business domain Call it a \"domain model\" Consume the model in a layered architecture 4 layers, business logic split and renamed Application layer and domain layer DDD has two distinct parts. One is always needed but the other can be happily ignored Analytical Valuable to everybody and every project Strategic One of many supporting architectures Discovering the Domain Architecture through DDD Ubiquitous Language What is Ubiquitous Language Vocabulary of domain-specific terms Nouns, verbs, adjectives, idiomatic expressions and even adverbs Shared by all parties involved in the project Primary goal of avoiding misunderstandings Used in all forms of spoken and written communication Universal language of the business as done in the organization Motivation People use different languages Common terminology Help making sense of user requirements Definition Natural language, not artificial Comes out of interviews and brainstorming Iteratively composed and refined along the way Unambiguous and fluent Meets expectation of domain experts Meets expectations of technical people Ubiquitous language used in User Stories and RFC Meetings Emails Technical documentation Schedule Source Code Structure List of terms saved to Office documents Glossary of terms fully explained Made available to everyone Part of the project documentation Continuously updated Responsibility of the development team Defining the Ubiquitous Language Use the language model as the backbone of a language Discovering the ubiquitous language Leads you to understand the business domain In order to design a model Any model works. Not necessarily an object-oriented model Ubiquitous Language Words and verbs that truly reflect the semantics of the business domain No ambiguity No synonyms Ubiquitous Language Tips Dealing with acronyms Domain-specific Hard to remember Avoid if possible Ubiquitous language is in sync with the code Scenarios where Ubiquitous Language is key to have Really a lot of domain logic is tricky to digest Ensures all relevant terms are understood No other term is used to indicate same/similar concepts Business logic not completely defined Business is young and growing with the system (i.e. startup) Domain logic discovered along the way Ubiquitous language in Code Naming conventions Classes Members Namespaces Extension methods Domain-specific language C#, Java, Kotlin Tools Code assistants Refactoring tools Gated check-ins Agnostic No mandated technology No mandated paradigm Bounded contexts What is bounded contexts? Delimited space where an element has a well-defined meaning Any elements of the ubiquitous language Beyond the boundaries of the context, the language changes Each bounded context has its own ubiquitous language Business domain split in a web of interconnected contexts Each context has its own architecture and implementation Motivation for bounded contexts Remove ambiguity and duplication Simplify design of software designs Integration of external components Discovering bounded contexts Bounded contexts Ubiquitous language Independent implementation (eg. CQRS) External interface (to other contexts) Integrity at risk without bounded contexts Same term that means differently to different people Same term to indicate different elements Dependency on external subsystems Dependency on legacy code Functional areas of the application that are better treated separately Context mapping Web of Bounded Contexts Systems may result from the composition of multiple contexts Number of bounded context often reflects physical organization What is Context Map Context map is the diagram that provides a comprehensive view of the system being designed Direction of relationship Upstream context influences Downstream context Aspects being influenced Binaries Schedule Request-for-changes Event storming What is event storming Exploring a business domain starting from observable domain events Developers and domain experts together in a meeting room How it works Identify relevant domain events Use a sticky note of a given color to put events on the wall Find what causes the event User action? Add a sticky note of a different color Asynchronous event? Add a sticky note of a different color Another event? Add another sticky note of same color on top Look at the modeling surface as a timeline Add notes with markers Facilitator Leads the meeting Starts the meeting asking questions Sticks first notes on the wall to show the way Guides the modeling effort Asks questions to better understand the emerging model Ensure ideas are represented accurately Keep focused and moves ahead Benefits Comprehensive vision of the business domain Bounded contexts and aggregates in each context Aggregate handles commands and controls persistence Types of users in the system Personas who runs command and why Where UX is critical Sketches of relevant screens The DDD Layered Architecture Introduction Key points Layers and tiers Segmentation of a Software system Domain layer Patterns for organizing the Business Logic Other Layers From Persistence to Presentation The Layers of a Software System Spaghetti-code vs. Lasagna-code Spaghetti-code : Messy tangle of instructions leading nowhere near to any flicker of solid software. Lasagna-code : Layered block of modules easy to cut vertically and/or horizontally and easy to deploy. Layered architecture Presentation layer -> UX Application layer -> Use-cases Domain layer -> Business TX Script Table module Domain model CQRS Event sourcing Data layer -> Persistence Relational NoSQL Memory The Presentation Layer What is presentation layer? Responsible for providing the user interface to accomplish any required tasks Responsible for providing an effective, smooth and pleasant user experience Attributes of presentation layer Task based Device-friendly User friendly Faithful to real-world processes The Application Layer What does application layer do? Reports to the presentation Serves ready-to-use data in the required form Orchestrates tasks triggered by presentation elements Use-cases of the application's frontend Doubly-linked with presentation Possibly extended or duplicated when a new frontend is added The Business Logic Business Logic contains 2 parts Application logic Dependent on use cases Application entities (Data transfer objects) Application workflow components (Application services) Domain logic Invariant to use cases Business entities (Domain model) Business workflow components (Domain services) Domain logic is all about baking business rules into the code Business rule Statements that detail the implementation of a business process or describe a business policy to be taken into account The business rule is executed in the following ways: Business logic workflow Business logic components Business rule engine Domain model Rules encapsulated in the model Patterns for Organizing the Business Logic Common patterns Transaction script Table module Domain model Transaction script pattern System actions Each procedure handles a single task Logical transaction End-to-end from presentation to data Common subtasks Split into bounded sub-procedures for reuse Table module pattern One module per table in the database Module contains all methods that will process the data Both queries and commands May limit modules to \"significant\" tables Tables with only outbound foreign-key relationships Domain model pattern Aggregated objects Data and behaviour Persistence agnostic Paired with domain services The Domain Layer Domain layer Logic invariant to use cases Domain model Domain services Domain model Models for the business domain Object-oriented entity model Functional model Guidelines for classes in an entity model DDD conventions (factories, value types, private setters) Data and behaviour Anemic model Plain data containers Behaviour and rules moved to domain services Domain services Pieces of domain logic that don't fit into any of the existing entities Types of domain services Classes that group logically related behaviours Typically operating on multiple domain entities Implementation of processes that Requires access to the persistence layer for reads and writes Requires access to external services The Infrastructure Layer Infrastructure Set of the fundamental facilities needed for the operation of a software system Fundamental facilities of software systems Persistence Security Logging and tracing Inversion of control Caching Networks Down where technologies belong Necessary to fuel the system Not binding the system to specific products How it works? Concrete details of technologies Connection strings File paths TCP addresses HTTP Urls Preferably made of facades Technology details hidden from view Replaceable with a minimum effort The 'Domain Model' Supporting Architecture Holistic Model for the Business Domain Domain layer Domain model Aggregates Entities Value types Factories Domain services Cross-aggregate behaviour Repositories External services Key DDD misconceptions Perceived simply as having an object model with some special characteristics Database is just part of the infrastructure and can be neglected Ubiquitous Language is a guide to naming classes in the object model Clearing misconceptions Just an object model Context mapping is permanent Modeling the domain through objects is just one of the possible options Database agnostic The object model must be easy to persist Persistence, though, should not be the primary concern Primary concern is making sense of the business domain Ubiquitous language Understanding the language to understand the business Keep language of business in sync with code Aspects of Domain Model Aspects of Domain Model Module Value objects Entities Aggregates DDD Value types Collection of individual values Fully defined by its collection of attributes Immutable More precise and accurate than primitive types DDD Entities Need an identity Uniqueness is important to the specific object Typically made of data and behaviour Contain domain logic, but not persistence logic DDD Aggregates A few individual entities constantly used and referenced together Cluster of associated objects treated as one for data changes Aggregate roots Preserve transactional integrity Database-centric Domain Models Persistence vs. Domain Model Persistence Model Object-oriented model 1:1 with underlying relational data Reliable and familiar to most developers Doesn't include business logic (except perhaps validation) Domain Model Object-oriented model for business logic Persistence model No persistence logic inside The Crazy Little Thing Called Behaviour What's behaviour? Methods that validate the state of the object Methods that invoke business actions to perform on the object Methods that express business processes involving the object","title":"Modern Software Architecture - Domain Models, CQRS, and Event Sourcing"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#modern-software-architecture-domain-models-cqrs-and-event-sourcing","text":"","title":"Modern Software Architecture: Domain Models, CQRS, and Event Sourcing"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#ddd-at-a-glance","text":"","title":"DDD at a Glance"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#introduction","text":"Key Points Repositioning Domain-Driven Design Exploring Supporting Architectures UX-first Design Methodology","title":"Introduction"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#ddd-in-history","text":"Domain-Driven Design in History Introduced 10+ years ago by Eric Evans Primary intent of tackling complexity in the heart of software Innovative guidelines and approach to design Where does the complexity comes from? Big Ball of Mud (BBM) A system that's largely unstructured, padded with hidden dependencies between parts, with a lot of data and code duplications and an unclear identification of layers and concerns - a spaghetti code jungle","title":"DDD in History"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#ddd-today","text":"Why is DDD so Intriguing? Captured known elements of design process Organized them into set of principles Made domain modeling the focus of development Different approach to building business logic DDD is still about the business logic Crunch knowledge about the domain Recognize subdomains Design a rich domain model Code by telling objects in the domain model what to do Supreme Goal of DDD Tackling complexity in the heart of software DDD represents a significant landmark in software development Took root in the Java space Blissfully ignored in .NET until recently DDD is more about analysis than about actual coding strategies The main focus of DDD has shifted Discovering the domain architecture more than organizing the business logic Domain Model remains a valid pattern to organize the business logic but other patterns can be used as well like: Object-oriented models Functional models CQRS Classic 3-tier 2-tier","title":"DDD Today"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#ddd-misconceptions","text":"Common summary of DDD Build an object model for the business domain Call it a \"domain model\" Consume the model in a layered architecture 4 layers, business logic split and renamed Application layer and domain layer DDD has two distinct parts. One is always needed but the other can be happily ignored Analytical Valuable to everybody and every project Strategic One of many supporting architectures","title":"DDD Misconceptions"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#discovering-the-domain-architecture-through-ddd","text":"","title":"Discovering the Domain Architecture through DDD"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#ubiquitous-language","text":"What is Ubiquitous Language Vocabulary of domain-specific terms Nouns, verbs, adjectives, idiomatic expressions and even adverbs Shared by all parties involved in the project Primary goal of avoiding misunderstandings Used in all forms of spoken and written communication Universal language of the business as done in the organization Motivation People use different languages Common terminology Help making sense of user requirements Definition Natural language, not artificial Comes out of interviews and brainstorming Iteratively composed and refined along the way Unambiguous and fluent Meets expectation of domain experts Meets expectations of technical people Ubiquitous language used in User Stories and RFC Meetings Emails Technical documentation Schedule Source Code Structure List of terms saved to Office documents Glossary of terms fully explained Made available to everyone Part of the project documentation Continuously updated Responsibility of the development team","title":"Ubiquitous Language"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#defining-the-ubiquitous-language","text":"Use the language model as the backbone of a language Discovering the ubiquitous language Leads you to understand the business domain In order to design a model Any model works. Not necessarily an object-oriented model Ubiquitous Language Words and verbs that truly reflect the semantics of the business domain No ambiguity No synonyms","title":"Defining the Ubiquitous Language"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#ubiquitous-language-tips","text":"Dealing with acronyms Domain-specific Hard to remember Avoid if possible Ubiquitous language is in sync with the code Scenarios where Ubiquitous Language is key to have Really a lot of domain logic is tricky to digest Ensures all relevant terms are understood No other term is used to indicate same/similar concepts Business logic not completely defined Business is young and growing with the system (i.e. startup) Domain logic discovered along the way Ubiquitous language in Code Naming conventions Classes Members Namespaces Extension methods Domain-specific language C#, Java, Kotlin Tools Code assistants Refactoring tools Gated check-ins Agnostic No mandated technology No mandated paradigm","title":"Ubiquitous Language Tips"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#bounded-contexts","text":"What is bounded contexts? Delimited space where an element has a well-defined meaning Any elements of the ubiquitous language Beyond the boundaries of the context, the language changes Each bounded context has its own ubiquitous language Business domain split in a web of interconnected contexts Each context has its own architecture and implementation Motivation for bounded contexts Remove ambiguity and duplication Simplify design of software designs Integration of external components","title":"Bounded contexts"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#discovering-bounded-contexts","text":"Bounded contexts Ubiquitous language Independent implementation (eg. CQRS) External interface (to other contexts) Integrity at risk without bounded contexts Same term that means differently to different people Same term to indicate different elements Dependency on external subsystems Dependency on legacy code Functional areas of the application that are better treated separately","title":"Discovering bounded contexts"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#context-mapping","text":"Web of Bounded Contexts Systems may result from the composition of multiple contexts Number of bounded context often reflects physical organization What is Context Map Context map is the diagram that provides a comprehensive view of the system being designed Direction of relationship Upstream context influences Downstream context Aspects being influenced Binaries Schedule Request-for-changes","title":"Context mapping"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#event-storming","text":"What is event storming Exploring a business domain starting from observable domain events Developers and domain experts together in a meeting room How it works Identify relevant domain events Use a sticky note of a given color to put events on the wall Find what causes the event User action? Add a sticky note of a different color Asynchronous event? Add a sticky note of a different color Another event? Add another sticky note of same color on top Look at the modeling surface as a timeline Add notes with markers Facilitator Leads the meeting Starts the meeting asking questions Sticks first notes on the wall to show the way Guides the modeling effort Asks questions to better understand the emerging model Ensure ideas are represented accurately Keep focused and moves ahead Benefits Comprehensive vision of the business domain Bounded contexts and aggregates in each context Aggregate handles commands and controls persistence Types of users in the system Personas who runs command and why Where UX is critical Sketches of relevant screens","title":"Event storming"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#the-ddd-layered-architecture","text":"","title":"The DDD Layered Architecture"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#introduction_1","text":"Key points Layers and tiers Segmentation of a Software system Domain layer Patterns for organizing the Business Logic Other Layers From Persistence to Presentation","title":"Introduction"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#the-layers-of-a-software-system","text":"Spaghetti-code vs. Lasagna-code Spaghetti-code : Messy tangle of instructions leading nowhere near to any flicker of solid software. Lasagna-code : Layered block of modules easy to cut vertically and/or horizontally and easy to deploy. Layered architecture Presentation layer -> UX Application layer -> Use-cases Domain layer -> Business TX Script Table module Domain model CQRS Event sourcing Data layer -> Persistence Relational NoSQL Memory","title":"The Layers of a Software System"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#the-presentation-layer","text":"What is presentation layer? Responsible for providing the user interface to accomplish any required tasks Responsible for providing an effective, smooth and pleasant user experience Attributes of presentation layer Task based Device-friendly User friendly Faithful to real-world processes","title":"The Presentation Layer"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#the-application-layer","text":"What does application layer do? Reports to the presentation Serves ready-to-use data in the required form Orchestrates tasks triggered by presentation elements Use-cases of the application's frontend Doubly-linked with presentation Possibly extended or duplicated when a new frontend is added","title":"The Application Layer"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#the-business-logic","text":"Business Logic contains 2 parts Application logic Dependent on use cases Application entities (Data transfer objects) Application workflow components (Application services) Domain logic Invariant to use cases Business entities (Domain model) Business workflow components (Domain services) Domain logic is all about baking business rules into the code Business rule Statements that detail the implementation of a business process or describe a business policy to be taken into account The business rule is executed in the following ways: Business logic workflow Business logic components Business rule engine Domain model Rules encapsulated in the model","title":"The Business Logic"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#patterns-for-organizing-the-business-logic","text":"Common patterns Transaction script Table module Domain model Transaction script pattern System actions Each procedure handles a single task Logical transaction End-to-end from presentation to data Common subtasks Split into bounded sub-procedures for reuse Table module pattern One module per table in the database Module contains all methods that will process the data Both queries and commands May limit modules to \"significant\" tables Tables with only outbound foreign-key relationships Domain model pattern Aggregated objects Data and behaviour Persistence agnostic Paired with domain services","title":"Patterns for Organizing the Business Logic"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#the-domain-layer","text":"Domain layer Logic invariant to use cases Domain model Domain services Domain model Models for the business domain Object-oriented entity model Functional model Guidelines for classes in an entity model DDD conventions (factories, value types, private setters) Data and behaviour Anemic model Plain data containers Behaviour and rules moved to domain services Domain services Pieces of domain logic that don't fit into any of the existing entities Types of domain services Classes that group logically related behaviours Typically operating on multiple domain entities Implementation of processes that Requires access to the persistence layer for reads and writes Requires access to external services","title":"The Domain Layer"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#the-infrastructure-layer","text":"Infrastructure Set of the fundamental facilities needed for the operation of a software system Fundamental facilities of software systems Persistence Security Logging and tracing Inversion of control Caching Networks Down where technologies belong Necessary to fuel the system Not binding the system to specific products How it works? Concrete details of technologies Connection strings File paths TCP addresses HTTP Urls Preferably made of facades Technology details hidden from view Replaceable with a minimum effort","title":"The Infrastructure Layer"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#the-domain-model-supporting-architecture","text":"","title":"The 'Domain Model' Supporting Architecture"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#holistic-model-for-the-business-domain","text":"Domain layer Domain model Aggregates Entities Value types Factories Domain services Cross-aggregate behaviour Repositories External services Key DDD misconceptions Perceived simply as having an object model with some special characteristics Database is just part of the infrastructure and can be neglected Ubiquitous Language is a guide to naming classes in the object model Clearing misconceptions Just an object model Context mapping is permanent Modeling the domain through objects is just one of the possible options Database agnostic The object model must be easy to persist Persistence, though, should not be the primary concern Primary concern is making sense of the business domain Ubiquitous language Understanding the language to understand the business Keep language of business in sync with code","title":"Holistic Model for the Business Domain"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#aspects-of-domain-model","text":"Aspects of Domain Model Module Value objects Entities Aggregates DDD Value types Collection of individual values Fully defined by its collection of attributes Immutable More precise and accurate than primitive types DDD Entities Need an identity Uniqueness is important to the specific object Typically made of data and behaviour Contain domain logic, but not persistence logic DDD Aggregates A few individual entities constantly used and referenced together Cluster of associated objects treated as one for data changes Aggregate roots Preserve transactional integrity","title":"Aspects of Domain Model"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#database-centric-domain-models","text":"Persistence vs. Domain Model Persistence Model Object-oriented model 1:1 with underlying relational data Reliable and familiar to most developers Doesn't include business logic (except perhaps validation) Domain Model Object-oriented model for business logic Persistence model No persistence logic inside","title":"Database-centric Domain Models"},{"location":"pluralsight/paths/bdd/beginner/modernSoftwareArchitecture/#the-crazy-little-thing-called-behaviour","text":"What's behaviour? Methods that validate the state of the object Methods that invoke business actions to perform on the object Methods that express business processes involving the object","title":"The Crazy Little Thing Called Behaviour"},{"location":"pluralsight/paths/javaLanguageFundamentals/beginner/modernJavaTheBigPicture/","text":"Modern Java - The Big Picture Introducing the Java Platform The Java Platform Java Programming language Runtime environment Standard library Adopting Java Philosophy of Java Portability Write once run anywhere Optimized for readibility Reading code is more important than writing code Understandable code over clever code Conservative of new features Planning for the next 20 years 'First do no harm' Developer productivity Maintaining simplicity Backward compatibility Existing code on new JVMs -> Controlled deprecation Openness : Specification process Java Community Process(JCP) specifies the platform Vendor and community participation Many non-Oracle implementations : IBM, Eclipse Openness : Open source OpenJDK project GPL2 licensed Experimental subprojects Choosing Java - When and Why Popularity Estimated 10 million Java developers Web applications Backend services Data-intensive applications Scalable developement Hierarchical and structured codebases Established coding practices String tooling Wealth of libraries Productivity Type system Catch bugs early Managed runtime Automatic memory management Garbage collection Multi-threading Performance Just-in-time compilztion Specialized to underlying hardware Based on actual execution of code Choosing Java - When is Java not the right choice? Real-time systems Tight operating system integration Quick prototyping For developers who want cutting-edge languages Comparing Java : C#/.Net Similarity Common language runtime Managed language Open source Difference Faster moving language Only recently cross-platform Ecosystem dominated by Microsoft Comparing Java : C/C++ Similarity Java syntax inspired by C C++ also Object-oriented Difference Unmanaged language More language features Compiled to native code Comparing Java : Python -> Similarity * High-level managed language * Open ecosystem Difference Interpreted language Not statically typed Python 2/3 split Comparing Java : JavaScript Similarity Managed runtime : NodeJS Somewhat syntactically similar Difference Interpreted language Not statically typed Single-threaded From Desktop to Enterprise Java to the Cloud Desktop java Single machine, interactive applications AWT Abstract Windowing Toolkit native OS Controls Simple graphics primitives Swing Pue Java GUI Cross-platform look and feels Model-view-controller JavaFX Declarative UIs: FXML Advanced components Skinnable with CSS 3D graphics Enterprise Java APIs Data persistence Web applications Security Messaging JSON/XML handling Java EE application servers Wildfly (RedHat) WebSphere (IBM) WebLogic (Oracle) Tomcat (Apache) Future of Java EE Java EE 8 last release Move to Eclipse Foundation (is now Jakarta EE) Is being replaced by Spring Framework Java In The Cloud Microframeworks Spring Boot MicroProfile Vert.x Play Framework Android Java Bytecode is converted to DEX (Dalvik Executable Format) JVM is replaced by Dalvik Virtual Machine Popular Java Libraries Spring Framework J2EE Developement without EJB Dependency injection Decoupling of classes Flexible composition Cross-cutting concerns Dependency injection container Integration with data-access technologies Integration with Java EE technologies Spring WebFlux Commonly used Java libraries Utility libraries Google Guava Additional collections Caching IO helpers Apache Commons Collections CSV IO (and many more) Apache Log4J Structured application logging Distributed System Libraries Netty High-performance networking Akka Actor model for concurrency Clustering and distribution RxJava Reactive programming Async and event-based model Apache Camel Enterprise application integration Many transports and connectors Data-access libraries JDBC MySQL driver postGres driver Oracle driver H2 driver ORMs Hibernate EclipseLink SQL DSLs jOOQ QueryDSL Java-based data processing Big Data : Processing Apache Hadoop Apache Spark DL4J : Deep Learning for Java Big Data : Storage Cassandra Neo4J ElastiSearch Hadoop Distributed File System Practices and Common Tools IDEs Code completion Inline documentation Debugging Examples of IDEs Eclipse IntelliJ Unit Testing Write code to test code Individual classes and methods (JUnit) Isolate dependencies : mocking (Mockito) Build Tools Repeatable builds Managing multiple modules Managing external dependencies Running tests Example of build tools Maven Gradle Define builds with Groovy scripts Incremental builds Maven default source layout Can use Maven Central Continuouos integration and Quality Controls CI Server Build Code Run tests Analyse code Deploy CI server examples Jenkins Static code analysis Checkstyle Spotbugs PMD SonarQube : Continuous inspection Examining alternative JVM languages Why? Productive Familiarity Different paradigms Groovy Dynamic scripting language for the JVM Interpreted or compiled Opt-in type system Concise but still close to Java Scala Combines OO programming with Functional programming Compiled language Extensive type system Akka, Spark written in Scala Kotlin A 'better Java' Seamless Java interop Endorsed by Google for Android developement Also runs in the browser","title":"Modern Java, the Big Picture"},{"location":"pluralsight/paths/javaLanguageFundamentals/beginner/modernJavaTheBigPicture/#modern-java-the-big-picture","text":"","title":"Modern Java - The Big Picture"},{"location":"pluralsight/paths/javaLanguageFundamentals/beginner/modernJavaTheBigPicture/#introducing-the-java-platform","text":"The Java Platform Java Programming language Runtime environment Standard library","title":"Introducing the Java Platform"},{"location":"pluralsight/paths/javaLanguageFundamentals/beginner/modernJavaTheBigPicture/#adopting-java","text":"Philosophy of Java Portability Write once run anywhere Optimized for readibility Reading code is more important than writing code Understandable code over clever code Conservative of new features Planning for the next 20 years 'First do no harm' Developer productivity Maintaining simplicity Backward compatibility Existing code on new JVMs -> Controlled deprecation Openness : Specification process Java Community Process(JCP) specifies the platform Vendor and community participation Many non-Oracle implementations : IBM, Eclipse Openness : Open source OpenJDK project GPL2 licensed Experimental subprojects Choosing Java - When and Why Popularity Estimated 10 million Java developers Web applications Backend services Data-intensive applications Scalable developement Hierarchical and structured codebases Established coding practices String tooling Wealth of libraries Productivity Type system Catch bugs early Managed runtime Automatic memory management Garbage collection Multi-threading Performance Just-in-time compilztion Specialized to underlying hardware Based on actual execution of code Choosing Java - When is Java not the right choice? Real-time systems Tight operating system integration Quick prototyping For developers who want cutting-edge languages Comparing Java : C#/.Net Similarity Common language runtime Managed language Open source Difference Faster moving language Only recently cross-platform Ecosystem dominated by Microsoft Comparing Java : C/C++ Similarity Java syntax inspired by C C++ also Object-oriented Difference Unmanaged language More language features Compiled to native code Comparing Java : Python -> Similarity * High-level managed language * Open ecosystem Difference Interpreted language Not statically typed Python 2/3 split Comparing Java : JavaScript Similarity Managed runtime : NodeJS Somewhat syntactically similar Difference Interpreted language Not statically typed Single-threaded","title":"Adopting Java"},{"location":"pluralsight/paths/javaLanguageFundamentals/beginner/modernJavaTheBigPicture/#from-desktop-to-enterprise-java-to-the-cloud","text":"Desktop java Single machine, interactive applications AWT Abstract Windowing Toolkit native OS Controls Simple graphics primitives Swing Pue Java GUI Cross-platform look and feels Model-view-controller JavaFX Declarative UIs: FXML Advanced components Skinnable with CSS 3D graphics Enterprise Java APIs Data persistence Web applications Security Messaging JSON/XML handling Java EE application servers Wildfly (RedHat) WebSphere (IBM) WebLogic (Oracle) Tomcat (Apache) Future of Java EE Java EE 8 last release Move to Eclipse Foundation (is now Jakarta EE) Is being replaced by Spring Framework Java In The Cloud Microframeworks Spring Boot MicroProfile Vert.x Play Framework Android Java Bytecode is converted to DEX (Dalvik Executable Format) JVM is replaced by Dalvik Virtual Machine","title":"From Desktop to Enterprise Java to the Cloud"},{"location":"pluralsight/paths/javaLanguageFundamentals/beginner/modernJavaTheBigPicture/#popular-java-libraries","text":"Spring Framework J2EE Developement without EJB Dependency injection Decoupling of classes Flexible composition Cross-cutting concerns Dependency injection container Integration with data-access technologies Integration with Java EE technologies Spring WebFlux Commonly used Java libraries Utility libraries Google Guava Additional collections Caching IO helpers Apache Commons Collections CSV IO (and many more) Apache Log4J Structured application logging Distributed System Libraries Netty High-performance networking Akka Actor model for concurrency Clustering and distribution RxJava Reactive programming Async and event-based model Apache Camel Enterprise application integration Many transports and connectors Data-access libraries JDBC MySQL driver postGres driver Oracle driver H2 driver ORMs Hibernate EclipseLink SQL DSLs jOOQ QueryDSL Java-based data processing Big Data : Processing Apache Hadoop Apache Spark DL4J : Deep Learning for Java Big Data : Storage Cassandra Neo4J ElastiSearch Hadoop Distributed File System","title":"Popular Java Libraries"},{"location":"pluralsight/paths/javaLanguageFundamentals/beginner/modernJavaTheBigPicture/#practices-and-common-tools","text":"IDEs Code completion Inline documentation Debugging Examples of IDEs Eclipse IntelliJ Unit Testing Write code to test code Individual classes and methods (JUnit) Isolate dependencies : mocking (Mockito) Build Tools Repeatable builds Managing multiple modules Managing external dependencies Running tests Example of build tools Maven Gradle Define builds with Groovy scripts Incremental builds Maven default source layout Can use Maven Central Continuouos integration and Quality Controls CI Server Build Code Run tests Analyse code Deploy CI server examples Jenkins Static code analysis Checkstyle Spotbugs PMD SonarQube : Continuous inspection","title":"Practices and Common Tools"},{"location":"pluralsight/paths/javaLanguageFundamentals/beginner/modernJavaTheBigPicture/#examining-alternative-jvm-languages","text":"Why? Productive Familiarity Different paradigms Groovy Dynamic scripting language for the JVM Interpreted or compiled Opt-in type system Concise but still close to Java Scala Combines OO programming with Functional programming Compiled language Extensive type system Akka, Spark written in Scala Kotlin A 'better Java' Seamless Java interop Endorsed by Google for Android developement Also runs in the browser","title":"Examining alternative JVM languages"},{"location":"pluralsight/paths/pmiAcpExam/introductionToAgileProjectMgt/","text":"Introduction to Agile Project Mgt and the PMI-ACP Exam Becoming an Agile Project Manager and Achieving PMI-ACP Certification Why is this training important? Confusion about PMI-ACP Certification - Some people may think that: Getting PMI-ACP certification is a matter of buying an \"exam prep\" book or taking an \"exam prep\" training course and going out and taking the exam Once you've taken and passed the exam, that is your \"ticket\" to get a job working in an Agile environment as a project manager Agile Adoption has doubles since 2009 A Forrester study from 2009 observed that 35% of organizations used Agile Actuation Consulting's 2013 research shows that 73.68% have adopted agile to develop products The rapid growth and proliferation of Agile methodologies has added to the confusion that has already existed in this area \"Agile\" is becoming a hot new buzz word and everyone wants to jump on the \"Agile bandwagon\" Just becoming \"Agile\" is not necessarily the most important goal in itself depending on the nature of the business you're in Agile is very similar to Six Sigma : There was a lot of hype about it A lot of people got lost in the mechanics of Six Sigma People tended to think that Six Sigma was a panacea for any possible problem that a business could have, and They tended to regard all other previous process improvement methodologies as obsolete and no longer relevant While Agile has huge potential advantages for a business, I think it's important not to get lost in some of the hype that exists about Agile and objectively understand the differences between an Agile approach and a traditionalproject management approach and the benefits and limitations of each Agile will have a major impact on the project management profession It \"raises the bar\" significantly for project managers This training will help you understand the impact of Agile on the project management profession and adapt your career as necessary to take advantage of the new opportunities it presents Learning Path and Course Overview This course is not just a PMI-ACP \"exam prep\" course There are a lot of PMI-ACP \"exam prep\" courses out there and simply preparing for the exam has limited value Developing a course that helps you prepare for a real-world role in addition to preparing for the exam has a lot more value Putting the information in a real-world context will not only help you prepare for a real-world role, it will also make the information more meaningful and easier to retain A Big Challenge The role of an \"Agile Project Manager\" is somewhat undefined and is even somewhat controversial We need to better define and understand what that role is and it isn't limited to project managers Agile is changing the very nature of \"Project Management\". You typically won't find anyone with the title of \"Project Manager\" at the team level in an Agile project, but there is a lot of \"Project Management going on\" What is Agile Project Management Is \"Agile Project Management\" an Oxymoron? There has been a lot of polarization between the Agile community and the project management community for a number of years Many people have the opinion that Agile and traditional project management principles and practices are mutually-exclusive of each other and in conflict with each other Agile and traditional project management principles and practices have been treated as separate and independent domains of knowledge with little or no integration between the two The roots of how we do project management today go back to the 1950's and 1960's and haven't changed significantly since that time The pace of new technology has increased dramatically and calls for a new project management approach Getting a PMP and PMI-ACP are going in the right direction but much more needs to be done The agile movement forces project managers to consider a much broader range of \"recipes\" and \"ingredients to cook with\" and requires a much more customized and tailored approach The challenge for Project Managers In the not-too-distant future, a Project Manager who only knows how to do plan-driven project management will be like a carpenter who only knows how to use a hammer This course will help you reshape your career direction as needed to take advantages of some of the new opportunities in this area Summary : What is an Agile Project Manager? An Agile Project Manager is not someone who only knows how to practice Agile An Agile Project Manager understands both traditional plan-driven project management and Agile principles and practices And he/she knows how to blend them together in the right proportions to fit a given situation You have to fit the right approach to the project rather than force-fitting a project to a single approach","title":"Introduction to Agile Project Management and the PMI-ACP Exam"},{"location":"pluralsight/paths/pmiAcpExam/introductionToAgileProjectMgt/#introduction-to-agile-project-mgt-and-the-pmi-acp-exam","text":"","title":"Introduction to Agile Project Mgt and the PMI-ACP Exam"},{"location":"pluralsight/paths/pmiAcpExam/introductionToAgileProjectMgt/#becoming-an-agile-project-manager-and-achieving-pmi-acp-certification","text":"","title":"Becoming an Agile Project Manager and Achieving PMI-ACP Certification"},{"location":"pluralsight/paths/pmiAcpExam/introductionToAgileProjectMgt/#why-is-this-training-important","text":"Confusion about PMI-ACP Certification - Some people may think that: Getting PMI-ACP certification is a matter of buying an \"exam prep\" book or taking an \"exam prep\" training course and going out and taking the exam Once you've taken and passed the exam, that is your \"ticket\" to get a job working in an Agile environment as a project manager Agile Adoption has doubles since 2009 A Forrester study from 2009 observed that 35% of organizations used Agile Actuation Consulting's 2013 research shows that 73.68% have adopted agile to develop products The rapid growth and proliferation of Agile methodologies has added to the confusion that has already existed in this area \"Agile\" is becoming a hot new buzz word and everyone wants to jump on the \"Agile bandwagon\" Just becoming \"Agile\" is not necessarily the most important goal in itself depending on the nature of the business you're in Agile is very similar to Six Sigma : There was a lot of hype about it A lot of people got lost in the mechanics of Six Sigma People tended to think that Six Sigma was a panacea for any possible problem that a business could have, and They tended to regard all other previous process improvement methodologies as obsolete and no longer relevant While Agile has huge potential advantages for a business, I think it's important not to get lost in some of the hype that exists about Agile and objectively understand the differences between an Agile approach and a traditionalproject management approach and the benefits and limitations of each Agile will have a major impact on the project management profession It \"raises the bar\" significantly for project managers This training will help you understand the impact of Agile on the project management profession and adapt your career as necessary to take advantage of the new opportunities it presents","title":"Why is this training important?"},{"location":"pluralsight/paths/pmiAcpExam/introductionToAgileProjectMgt/#learning-path-and-course-overview","text":"This course is not just a PMI-ACP \"exam prep\" course There are a lot of PMI-ACP \"exam prep\" courses out there and simply preparing for the exam has limited value Developing a course that helps you prepare for a real-world role in addition to preparing for the exam has a lot more value Putting the information in a real-world context will not only help you prepare for a real-world role, it will also make the information more meaningful and easier to retain A Big Challenge The role of an \"Agile Project Manager\" is somewhat undefined and is even somewhat controversial We need to better define and understand what that role is and it isn't limited to project managers Agile is changing the very nature of \"Project Management\". You typically won't find anyone with the title of \"Project Manager\" at the team level in an Agile project, but there is a lot of \"Project Management going on\"","title":"Learning Path and Course Overview"},{"location":"pluralsight/paths/pmiAcpExam/introductionToAgileProjectMgt/#what-is-agile-project-management","text":"Is \"Agile Project Management\" an Oxymoron? There has been a lot of polarization between the Agile community and the project management community for a number of years Many people have the opinion that Agile and traditional project management principles and practices are mutually-exclusive of each other and in conflict with each other Agile and traditional project management principles and practices have been treated as separate and independent domains of knowledge with little or no integration between the two The roots of how we do project management today go back to the 1950's and 1960's and haven't changed significantly since that time The pace of new technology has increased dramatically and calls for a new project management approach Getting a PMP and PMI-ACP are going in the right direction but much more needs to be done The agile movement forces project managers to consider a much broader range of \"recipes\" and \"ingredients to cook with\" and requires a much more customized and tailored approach The challenge for Project Managers In the not-too-distant future, a Project Manager who only knows how to do plan-driven project management will be like a carpenter who only knows how to use a hammer This course will help you reshape your career direction as needed to take advantages of some of the new opportunities in this area Summary : What is an Agile Project Manager? An Agile Project Manager is not someone who only knows how to practice Agile An Agile Project Manager understands both traditional plan-driven project management and Agile principles and practices And he/she knows how to blend them together in the right proportions to fit a given situation You have to fit the right approach to the project rather than force-fitting a project to a single approach","title":"What is Agile Project Management"},{"location":"pluralsight/soloCourses/java/streamsLambdaExpressions/","text":"From Collections to Streams using Lambda Expressions Lambda Expressions and Functional Interfaces What we normally do in Java We wrote code in an anonymous class And we passed it to another piece of code That executed it later And in another context (thread) We passed code as a parameter And we used anonymous class, because it is the only way to do it in Java Converting legacy code to lambda Example 1: Comparator in legacy code Comparator<String> comparator = new Comparator<String> { public int compare(String s1, String s2){ return Integer.compare(s1.length(), s2.length()); } } * In Lambda expressions Comparator<String> comparator = (String s1, String s2) -> Integer.compare(s1.length(), s2.length()); Some remarks One can put modifiers on the parameters of a lambda expressions The final keyword Annotations It is not possible to specify the returned type of a lambda expression The types of the parameters can also be omitted Method references Alternate syntax for lambda expressions Example 1 Function f = person -> person.getAge(); Function f = Person::getAge ; Example 2 BinaryOperator sum = (i1,i2) -> Integer.sum(i1,i2); BinaryOperator sum = Integer::sum; Example 3 Consumer printer = s -> System.out.println(s); Consumer printer = System.out::println ; How to create new API Lambdas + default methods + static methods Writing data processing functions with lambda expressions Functional interface A lambda expression is an instance of a functional interface Example : public interface Predicate { boolean test(T t); } At this point, a functional interface is an interface with only one method. How does it work under the hood? The Java 8 compiler is smart! The interface is functional, so there is only one method to implement. The type of the variable gives the type of the lambda expression The parameters and return types must be compatible. The same for exceptions, if any. Functional interface : Definition A functional interface is an interface: With only one abstract method Default methods do not count Static methods do not count Methods from the Object class do not count A functional interface may be annotated with @FunctionalInterface It is not mandatory, for legacy reasons The compiler will tell us if an annotated interface is functional or not The java.util.function.Package The functional interface toolbox A new package from Java 8, with the most useful functional interfaces There are 43 fo them. Four categories: The Consumers The Supplier The Functions The Predicates The Consumers A consumer consumes an object, and does not return anything. The Supplier A supplier provides and object, takes no parameter The Functions A function takes an object and returns another object The Predicates A predicate takes an object ans returns a boolean Functional interfaces for Primitive types Other functional interfaces have been defined, for instance IntPredicate IntFunction IntToDoubleFunction Data Processing using Lambdas and the Collection Framework Iterable, Collection, List On iterable forEach On collection removeIf On List interface replaceAll sort Map interface forEach getOrDefault putIfAbsent replace replaceAll remove compute Computes a value from: the key passed as a parameter, that may not be in the map the value that may be associated with that key, or null the lambda that will compute the remapping computeIfAbsent computeIfPresent merge If the passed key is not in the map: adds the key/ value pair to the map If the passed key is in the map merge the existing value with the passed value using the lambda expression note that the remapping takes a pair of values and return a new value Implementing Map Filter Reduce using Lambdas and Collections Contains 3 parts: Map Filter Reduce Parallelization The algorithm for sum of array of integers can be easily computed in parallel But there is a condition: Red(a,Red(b,c)) = Red(Red(a,b),c) It is called associativity If a lambda is passed as a parameter is not associative, then the following is going to happen? The code will compile properly It will execute properly A result will be returned But it will be false Reduction of singletons The reduction should have an identity element Not all operations have one (max) Conclusion on the Reduction step The reduction is critical It is very easy to write a non-associative reduction It is very easy to write a reduction with no identity element The Stream API Stream - definitions A stream does not hold any data It pulls the data it processes from a source A stream does not modify the data it processes Because we want to process the data in parallel with no visibility issues The source may be unbounded But most of the time, it only means that the size of this source is not known at build time How to build streams There are many patterns for that Stream.empty() // an empty Stream Stream.of(\"one\") // a singleton Stream Stream.of(\"one\", \"two\", \"three\") // a Stream with several elements Stream.generate(() -> \"one\"); // a constant Stream Stream.iterate(\"+\", s -> s + \"+\"); // a growing Stream ThreadLocalRandom.current().ints(); // a random Stream IntStream stream = \"hello\".chars(); // a Stream on the letters of a String Stream words = Pattern.compile(\"[^\\p{javaLetter}]\").splitAsStream(book); // a Stream on a regular expression Stream lines = Files.lines(path); // a Stream of the lines of a text file The StreamBuilder patterns Stream.Builder builder = Stream.builder(); builder.add(\"one).add(\"two\").add(\"three\"); builder.accept(\"four\"); Stream stream = builder.build(); First patterns Map/filter/reduce on a stream of people // a first way of writing it persons.stream() // Stream<Person> .map(p -> p.getAge()) // Stream<Integer> .filter(age -> age > 20) // Stream<Integer> .forEach(System.out::println); * A map() call can change the type of a stream * A filter() call does not change the type of a stream Intermediate and Terminal calls The peek() call can be used for logging purposes peek() is an intermediate operation forEach() is a terminal operation A terminal operation must be called to trigger the processing of a Stream No terminal operation = no data is ever processed How to recognise a terminal call? A call that returns a Stream is an intermediate call A call that returns something else, or void is a terminal call that triggers the processing Select ranges of data in a Stream skip() limit() Reduction Match reduction Three types of matchers : anyMatch(), allMatch(), noneMatch() They are terminal operations that return a boolean These three matchers may not evaluate the predicate for all the elementa They are called short-circuiting terminal operations Find reduction There are two types of find reductions : findFirst(), findAny() They might have nothing to return: If the stream is empty Or if there is no value that matches the predicate So they both return an Optional, that can be empty Reduce reduction There are three types of reduce reduction If no identity element is provided, then an Optional is returned Associativity is assumed for the reduction function, but not enforced","title":"From Collections to Streams using Lambda Expressions"},{"location":"pluralsight/soloCourses/java/streamsLambdaExpressions/#from-collections-to-streams-using-lambda-expressions","text":"","title":"From Collections to Streams using Lambda Expressions"},{"location":"pluralsight/soloCourses/java/streamsLambdaExpressions/#lambda-expressions-and-functional-interfaces","text":"What we normally do in Java We wrote code in an anonymous class And we passed it to another piece of code That executed it later And in another context (thread) We passed code as a parameter And we used anonymous class, because it is the only way to do it in Java Converting legacy code to lambda Example 1: Comparator in legacy code Comparator<String> comparator = new Comparator<String> { public int compare(String s1, String s2){ return Integer.compare(s1.length(), s2.length()); } } * In Lambda expressions Comparator<String> comparator = (String s1, String s2) -> Integer.compare(s1.length(), s2.length()); Some remarks One can put modifiers on the parameters of a lambda expressions The final keyword Annotations It is not possible to specify the returned type of a lambda expression The types of the parameters can also be omitted Method references Alternate syntax for lambda expressions Example 1 Function f = person -> person.getAge(); Function f = Person::getAge ; Example 2 BinaryOperator sum = (i1,i2) -> Integer.sum(i1,i2); BinaryOperator sum = Integer::sum; Example 3 Consumer printer = s -> System.out.println(s); Consumer printer = System.out::println ; How to create new API Lambdas + default methods + static methods","title":"Lambda Expressions and Functional Interfaces"},{"location":"pluralsight/soloCourses/java/streamsLambdaExpressions/#writing-data-processing-functions-with-lambda-expressions","text":"Functional interface A lambda expression is an instance of a functional interface Example : public interface Predicate { boolean test(T t); } At this point, a functional interface is an interface with only one method. How does it work under the hood? The Java 8 compiler is smart! The interface is functional, so there is only one method to implement. The type of the variable gives the type of the lambda expression The parameters and return types must be compatible. The same for exceptions, if any. Functional interface : Definition A functional interface is an interface: With only one abstract method Default methods do not count Static methods do not count Methods from the Object class do not count A functional interface may be annotated with @FunctionalInterface It is not mandatory, for legacy reasons The compiler will tell us if an annotated interface is functional or not The java.util.function.Package The functional interface toolbox A new package from Java 8, with the most useful functional interfaces There are 43 fo them. Four categories: The Consumers The Supplier The Functions The Predicates The Consumers A consumer consumes an object, and does not return anything. The Supplier A supplier provides and object, takes no parameter The Functions A function takes an object and returns another object The Predicates A predicate takes an object ans returns a boolean Functional interfaces for Primitive types Other functional interfaces have been defined, for instance IntPredicate IntFunction IntToDoubleFunction","title":"Writing data processing functions with lambda expressions"},{"location":"pluralsight/soloCourses/java/streamsLambdaExpressions/#data-processing-using-lambdas-and-the-collection-framework","text":"Iterable, Collection, List On iterable forEach On collection removeIf On List interface replaceAll sort Map interface forEach getOrDefault putIfAbsent replace replaceAll remove compute Computes a value from: the key passed as a parameter, that may not be in the map the value that may be associated with that key, or null the lambda that will compute the remapping computeIfAbsent computeIfPresent merge If the passed key is not in the map: adds the key/ value pair to the map If the passed key is in the map merge the existing value with the passed value using the lambda expression note that the remapping takes a pair of values and return a new value","title":"Data Processing using Lambdas and the Collection Framework"},{"location":"pluralsight/soloCourses/java/streamsLambdaExpressions/#implementing-map-filter-reduce-using-lambdas-and-collections","text":"Contains 3 parts: Map Filter Reduce Parallelization The algorithm for sum of array of integers can be easily computed in parallel But there is a condition: Red(a,Red(b,c)) = Red(Red(a,b),c) It is called associativity If a lambda is passed as a parameter is not associative, then the following is going to happen? The code will compile properly It will execute properly A result will be returned But it will be false Reduction of singletons The reduction should have an identity element Not all operations have one (max) Conclusion on the Reduction step The reduction is critical It is very easy to write a non-associative reduction It is very easy to write a reduction with no identity element","title":"Implementing Map Filter Reduce using Lambdas and Collections"},{"location":"pluralsight/soloCourses/java/streamsLambdaExpressions/#the-stream-api","text":"Stream - definitions A stream does not hold any data It pulls the data it processes from a source A stream does not modify the data it processes Because we want to process the data in parallel with no visibility issues The source may be unbounded But most of the time, it only means that the size of this source is not known at build time How to build streams There are many patterns for that Stream.empty() // an empty Stream Stream.of(\"one\") // a singleton Stream Stream.of(\"one\", \"two\", \"three\") // a Stream with several elements Stream.generate(() -> \"one\"); // a constant Stream Stream.iterate(\"+\", s -> s + \"+\"); // a growing Stream ThreadLocalRandom.current().ints(); // a random Stream IntStream stream = \"hello\".chars(); // a Stream on the letters of a String Stream words = Pattern.compile(\"[^\\p{javaLetter}]\").splitAsStream(book); // a Stream on a regular expression Stream lines = Files.lines(path); // a Stream of the lines of a text file The StreamBuilder patterns Stream.Builder builder = Stream.builder(); builder.add(\"one).add(\"two\").add(\"three\"); builder.accept(\"four\"); Stream stream = builder.build(); First patterns Map/filter/reduce on a stream of people // a first way of writing it persons.stream() // Stream<Person> .map(p -> p.getAge()) // Stream<Integer> .filter(age -> age > 20) // Stream<Integer> .forEach(System.out::println); * A map() call can change the type of a stream * A filter() call does not change the type of a stream Intermediate and Terminal calls The peek() call can be used for logging purposes peek() is an intermediate operation forEach() is a terminal operation A terminal operation must be called to trigger the processing of a Stream No terminal operation = no data is ever processed How to recognise a terminal call? A call that returns a Stream is an intermediate call A call that returns something else, or void is a terminal call that triggers the processing Select ranges of data in a Stream skip() limit() Reduction Match reduction Three types of matchers : anyMatch(), allMatch(), noneMatch() They are terminal operations that return a boolean These three matchers may not evaluate the predicate for all the elementa They are called short-circuiting terminal operations Find reduction There are two types of find reductions : findFirst(), findAny() They might have nothing to return: If the stream is empty Or if there is no value that matches the predicate So they both return an Optional, that can be empty Reduce reduction There are three types of reduce reduction If no identity element is provided, then an Optional is returned Associativity is assumed for the reduction function, but not enforced","title":"The Stream API"}]}